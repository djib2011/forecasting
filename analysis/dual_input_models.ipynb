{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import metrics\n",
    "from data import decomposition\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = [x.name for x in Path('../results').glob('*dual*')]\n",
    "families = set([x.rstrip('1234567890_') for x in logs])\n",
    "family_dirs = [['../results/' + family + '__{}/best_weights.h5'.format(i) for i in range(30)]\n",
    "               for family in families]\n",
    "family_names = ['dual_{}'.format(f.split('_')[7]) for f in families]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path('../data/Yearly-train.csv')\n",
    "test_path = Path('../data/Yearly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path).drop('V1', axis=1)\n",
    "test = pd.read_csv(test_path).drop('V1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "\n",
    "def get_last_N(series, N=18):\n",
    "    ser_N = series.dropna().iloc[-N:].values\n",
    "    if len(ser_N) < N:\n",
    "        pad = [ser_N[0]] * (N - len(ser_N))\n",
    "        ser_N = np.r_[pad, ser_N]\n",
    "    return ser_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([get_last_N(ser[1], N=18) for ser in train.iterrows()])\n",
    "y_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = family_dirs[0][0]\n",
    "\n",
    "mape = metrics.build_mape(overlap=6)\n",
    "smape = metrics.build_smape(overlap=6)\n",
    "mase_estimate = metrics.build_mase(overlap=6)\n",
    "owa_estimate = metrics.build_owa(overlap=6)\n",
    "reconstruction_loss = metrics.build_reconstruction_loss(overlap=6)\n",
    "\n",
    "model = tf.keras.models.load_model(model_dir, custom_objects={'SMAPE': smape,\n",
    "                                                              'MASE_estimate': mase_estimate,\n",
    "                                                              'OWA_estimate': owa_estimate,\n",
    "                                                              'reconstruction_loss': reconstruction_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data):\n",
    "        \n",
    "    x = data[..., np.newaxis]\n",
    "    \n",
    "    mn, mx = x.min(axis=1), x.max(axis=1)\n",
    "    x_sc = (x[..., 0] - mn) / (mx - mn)\n",
    "\n",
    "    lines, remainders = [], []\n",
    "    for x in x_sc:\n",
    "        l, r = decomposition.decompose(x)\n",
    "        lines.append(l)\n",
    "        remainders.append(r)\n",
    "    \n",
    "    x1 = np.array(lines)[..., np.newaxis]\n",
    "    x2 = np.array(remainders)[..., np.newaxis]\n",
    "    \n",
    "    pred = model((x1, x2))\n",
    "\n",
    "    return pred[..., 0] * (mx - mn) + mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ensemble_preds(model_family, data):\n",
    "\n",
    "    preds = []\n",
    "    \n",
    "    for model_dir in tqdm(model_family):\n",
    "\n",
    "        mape = metrics.build_mape(overlap=6)\n",
    "        smape = metrics.build_smape(overlap=6)\n",
    "        mase_estimate = metrics.build_mase(overlap=6)\n",
    "        owa_estimate = metrics.build_owa(overlap=6)\n",
    "        reconstruction_loss = metrics.build_reconstruction_loss(overlap=6)\n",
    "\n",
    "        model = tf.keras.models.load_model(model_dir, custom_objects={'SMAPE': smape,\n",
    "                                                                      'MASE_estimate': mase_estimate,\n",
    "                                                                      'OWA_estimate': owa_estimate,\n",
    "                                                                      'reconstruction_loss': reconstruction_loss})\n",
    "        preds.append(get_predictions(model, data))\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    return np.stack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(preds, y_test):\n",
    "    ensemble_preds = np.median(preds, axis=0)[:, -6:]\n",
    "    return np.nanmean(metrics.SMAPE(y_test, ensemble_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:57<00:00,  9.93s/it]\n",
      "100%|██████████| 30/30 [04:56<00:00,  9.87s/it]\n",
      "100%|██████████| 30/30 [04:56<00:00,  9.88s/it]\n",
      "100%|██████████| 30/30 [04:57<00:00,  9.92s/it]\n",
      "100%|██████████| 30/30 [04:55<00:00,  9.84s/it]\n",
      "100%|██████████| 30/30 [04:57<00:00,  9.91s/it]\n",
      "100%|██████████| 30/30 [05:07<00:00, 10.26s/it]\n"
     ]
    }
   ],
   "source": [
    "model_preds = []\n",
    "\n",
    "for family in family_dirs:\n",
    "    model_preds.append(ensemble_preds(family, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dual_0.75: 13.0806\n",
      "       dual_0.5: 13.0555\n",
      "       dual_0.8: 13.0724\n",
      "      dual_0.95: 13.0568\n",
      "       dual_0.9: 13.0562\n",
      "      dual_0.67: 13.0736\n",
      "       dual_0.0: 13.0709\n"
     ]
    }
   ],
   "source": [
    "for name, pred in zip(family_names, model_preds):\n",
    "    print('{:>15}: {:.4f}'.format(name, evaluate_ensemble(pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
