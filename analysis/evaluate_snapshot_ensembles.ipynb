{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import metrics\n",
    "import datasets\n",
    "import networks\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_length = 18\n",
    "overlap = 8\n",
    "aug = 0.5\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.seq2seq_generator('../data/yearly_{}_train.pkl'.format(inp_length + 6), overlap=overlap,\n",
    "                                       batch_size=batch_size, augmentation=0.5)\n",
    "\n",
    "test_set = datasets.seq2seq_generator('../data/yearly_{}_validation.pkl'.format(inp_length + 6), overlap=overlap,\n",
    "                                      batch_size=batch_size, augmentation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'bottleneck_size': 700,\n",
    "           'bottleneck_activation': 'relu',\n",
    "           'input_seq_length': inp_length,\n",
    "           'output_seq_length': overlap + 6,\n",
    "           'loss_function': 'mae',\n",
    "           'kernel_size': 3,\n",
    "           'stride': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4675 - mse: 25050365952.0000 - mae: 290.4675 - val_loss: 0.3725 - val_mse: 1259.2612 - val_mae: 0.3725\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3936 - mse: 1141.8003 - mae: 0.3936 - val_loss: 0.3694 - val_mse: 1259.2671 - val_mae: 0.3694\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3817 - mse: 1086.5132 - mae: 0.3817 - val_loss: 0.3726 - val_mse: 1259.2633 - val_mae: 0.3726\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4448 - mse: 25050363904.0000 - mae: 290.4445 - val_loss: 0.3648 - val_mse: 1259.2646 - val_mae: 0.3648\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3182 - mse: 930.5543 - mae: 0.3182 - val_loss: 0.3650 - val_mse: 1259.2659 - val_mae: 0.3650\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5342 - mse: 40080580608.0000 - mae: 580.5354 - val_loss: 0.3716 - val_mse: 1259.2666 - val_mae: 0.3716\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5309 - mse: 25050365952.0000 - mae: 290.5308 - val_loss: 0.3710 - val_mse: 1259.2628 - val_mae: 0.3710\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2575 - mse: 514.1390 - mae: 0.2575 - val_loss: 0.3658 - val_mse: 1259.2671 - val_mae: 0.3658\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2555 - mse: 45090652160.0000 - mae: 677.2563 - val_loss: 0.3644 - val_mse: 1259.2656 - val_mae: 0.3644\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4130 - mse: 1321.5150 - mae: 0.4130 - val_loss: 0.3653 - val_mse: 1259.2693 - val_mae: 0.3653\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9783 - mse: 35070513152.0000 - mae: 483.9782 - val_loss: 0.3755 - val_mse: 1259.2688 - val_mae: 0.3755\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3477 - mse: 851.2098 - mae: 0.3477 - val_loss: 0.3737 - val_mse: 1259.2667 - val_mae: 0.3737\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8863 - mse: 35070509056.0000 - mae: 483.8864 - val_loss: 0.3650 - val_mse: 1259.2639 - val_mae: 0.3650\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4001 - mse: 1089.3419 - mae: 0.4001 - val_loss: 0.3741 - val_mse: 1259.2561 - val_mae: 0.3741\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5309 - mse: 1772.5565 - mae: 0.5309 - val_loss: 0.3681 - val_mse: 1259.2631 - val_mae: 0.3681\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3560 - mse: 25050365952.0000 - mae: 290.3559 - val_loss: 0.3628 - val_mse: 1259.2583 - val_mae: 0.3628\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5019 - mse: 25050365952.0000 - mae: 290.5018 - val_loss: 0.3746 - val_mse: 1259.2681 - val_mae: 0.3746\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3423 - mse: 945.8408 - mae: 0.3423 - val_loss: 0.3648 - val_mse: 1259.2529 - val_mae: 0.3648\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1466 - mse: 30060435456.0000 - mae: 387.1466 - val_loss: 0.3629 - val_mse: 1259.2565 - val_mae: 0.3629\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4018 - mse: 1300.3649 - mae: 0.4018 - val_loss: 0.3628 - val_mse: 1259.2682 - val_mae: 0.3628\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3145 - mse: 697.2643 - mae: 0.3145 - val_loss: 0.3718 - val_mse: 1259.2672 - val_mae: 0.3718\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.9117 - mse: 20040290304.0000 - mae: 193.9116 - val_loss: 0.3768 - val_mse: 1259.2688 - val_mae: 0.3768\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4687 - mse: 1426.2013 - mae: 0.4687 - val_loss: 0.3641 - val_mse: 1259.2719 - val_mae: 0.3641\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4248 - mse: 25050363904.0000 - mae: 290.4250 - val_loss: 0.3701 - val_mse: 1259.2679 - val_mae: 0.3701\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1679 - mse: 30060435456.0000 - mae: 387.1679 - val_loss: 0.3671 - val_mse: 1259.2629 - val_mae: 0.3671\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4005 - mse: 1189.0653 - mae: 0.4005 - val_loss: 0.3879 - val_mse: 1321.4159 - val_mae: 0.3879\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6764 - mse: 40080580608.0000 - mae: 580.6769 - val_loss: 0.3703 - val_mse: 1259.2738 - val_mae: 0.3703\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3433 - mse: 963.7419 - mae: 0.3433 - val_loss: 0.3679 - val_mse: 1259.2595 - val_mae: 0.3679\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7670 - mse: 20040292352.0000 - mae: 193.7671 - val_loss: 0.3644 - val_mse: 1259.2678 - val_mae: 0.3644\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3392 - mse: 963.2913 - mae: 0.3392 - val_loss: 0.3631 - val_mse: 1259.2618 - val_mae: 0.3631\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4436 - mse: 25050363904.0000 - mae: 290.4437 - val_loss: 0.3761 - val_mse: 1259.2806 - val_mae: 0.3761\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4481 - mse: 1341.3400 - mae: 0.4481 - val_loss: 0.3786 - val_mse: 1259.2648 - val_mae: 0.3786\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3253 - mse: 673.1054 - mae: 0.3253 - val_loss: 0.3679 - val_mse: 1259.2712 - val_mae: 0.3679\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9711 - mse: 35070509056.0000 - mae: 483.9720 - val_loss: 0.3671 - val_mse: 1259.2695 - val_mae: 0.3671\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.4983 - mse: 40080580608.0000 - mae: 580.4991 - val_loss: 0.3645 - val_mse: 1259.2654 - val_mae: 0.3645\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4663 - mse: 1479.4767 - mae: 0.4663 - val_loss: 0.3653 - val_mse: 1259.2668 - val_mae: 0.3653\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.4751 - mse: 40080584704.0000 - mae: 580.4753 - val_loss: 0.3785 - val_mse: 1259.2592 - val_mae: 0.3785\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4359 - mse: 1347.4650 - mae: 0.4359 - val_loss: 0.3656 - val_mse: 1259.2543 - val_mae: 0.3656\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1777 - mse: 30060435456.0000 - mae: 387.1776 - val_loss: 0.3617 - val_mse: 1259.2695 - val_mae: 0.3617\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2974 - mse: 551.5864 - mae: 0.2974 - val_loss: 0.3640 - val_mse: 1259.2676 - val_mae: 0.3640\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3219 - mse: 749.7026 - mae: 0.3219 - val_loss: 0.3736 - val_mse: 1259.2699 - val_mae: 0.3736\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7992 - mse: 20040292352.0000 - mae: 193.7992 - val_loss: 0.3701 - val_mse: 1259.2676 - val_mae: 0.3701\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4079 - mse: 1160.8848 - mae: 0.4079 - val_loss: 0.3671 - val_mse: 1259.2695 - val_mae: 0.3671\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4433 - mse: 25050363904.0000 - mae: 290.4433 - val_loss: 0.3638 - val_mse: 1259.2651 - val_mae: 0.3638\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2855 - mse: 612.4700 - mae: 0.2855 - val_loss: 0.3649 - val_mse: 1259.2598 - val_mae: 0.3649\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.7624 - mse: 40080580608.0000 - mae: 580.7624 - val_loss: 0.3667 - val_mse: 1259.2672 - val_mae: 0.3667\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4090 - mse: 1287.1378 - mae: 0.4090 - val_loss: 0.3664 - val_mse: 1259.2646 - val_mae: 0.3664\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1086 - mse: 30060435456.0000 - mae: 387.1088 - val_loss: 0.3657 - val_mse: 1259.2695 - val_mae: 0.3657\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2041 - mse: 30060439552.0000 - mae: 387.2037 - val_loss: 0.3639 - val_mse: 1259.2592 - val_mae: 0.3639\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3013 - mse: 770.2158 - mae: 0.3013 - val_loss: 0.3628 - val_mse: 1259.2667 - val_mae: 0.3628\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4851 - mse: 1395.6089 - mae: 0.4851 - val_loss: 0.3825 - val_mse: 1259.2704 - val_mae: 0.3825\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1053 - mse: 30060435456.0000 - mae: 387.1054 - val_loss: 0.3776 - val_mse: 1259.2620 - val_mae: 0.3776\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3453 - mse: 800.0341 - mae: 0.3453 - val_loss: 0.3790 - val_mse: 1259.2634 - val_mae: 0.3790\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9167 - mse: 35070509056.0000 - mae: 483.9178 - val_loss: 0.3684 - val_mse: 1259.2699 - val_mae: 0.3684\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3755 - mse: 906.6582 - mae: 0.3755 - val_loss: 0.3632 - val_mse: 1259.2437 - val_mae: 0.3632\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4919 - mse: 25050365952.0000 - mae: 290.4920 - val_loss: 0.3620 - val_mse: 1259.2655 - val_mae: 0.3620\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3839 - mse: 25050365952.0000 - mae: 290.3839 - val_loss: 0.3641 - val_mse: 1259.2499 - val_mae: 0.3641\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4687 - mse: 1557.9526 - mae: 0.4687 - val_loss: 0.3663 - val_mse: 1259.2838 - val_mae: 0.3663\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6320 - mse: 40080580608.0000 - mae: 580.6324 - val_loss: 0.3611 - val_mse: 1259.2681 - val_mae: 0.3611\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3409 - mse: 723.8588 - mae: 0.3409 - val_loss: 0.3642 - val_mse: 1259.2604 - val_mae: 0.3642\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9382 - mse: 35070509056.0000 - mae: 483.9383 - val_loss: 0.3712 - val_mse: 1259.2740 - val_mae: 0.3712\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3476 - mse: 730.6551 - mae: 0.3476 - val_loss: 0.3697 - val_mse: 1259.2542 - val_mae: 0.3697\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2616 - mse: 45090652160.0000 - mae: 677.2625 - val_loss: 0.3695 - val_mse: 1259.2639 - val_mae: 0.3695\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3978 - mse: 1101.0031 - mae: 0.3978 - val_loss: 0.3726 - val_mse: 1259.2710 - val_mae: 0.3726\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2308 - mse: 415.4294 - mae: 0.2308 - val_loss: 0.3712 - val_mse: 1259.2736 - val_mae: 0.3712\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9687 - mse: 35070509056.0000 - mae: 483.9688 - val_loss: 0.3790 - val_mse: 1259.2618 - val_mae: 0.3790\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8725 - mse: 35070509056.0000 - mae: 483.8730 - val_loss: 0.3615 - val_mse: 1259.2614 - val_mae: 0.3615\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3635 - mse: 1030.1685 - mae: 0.3635 - val_loss: 0.3665 - val_mse: 1259.2655 - val_mae: 0.3665\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4831 - mse: 25050363904.0000 - mae: 290.4830 - val_loss: 0.3636 - val_mse: 1259.2643 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3466 - mse: 826.6800 - mae: 0.3466 - val_loss: 0.3698 - val_mse: 1259.2581 - val_mae: 0.3698\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3463 - mse: 845.1407 - mae: 0.3463 - val_loss: 0.3776 - val_mse: 1259.2684 - val_mae: 0.3776\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1805 - mse: 30060435456.0000 - mae: 387.1804 - val_loss: 0.3698 - val_mse: 1259.2678 - val_mae: 0.3698\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2721 - mse: 684.2613 - mae: 0.2721 - val_loss: 0.3658 - val_mse: 1259.2655 - val_mae: 0.3658\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2894 - mse: 30060435456.0000 - mae: 387.2892 - val_loss: 0.3730 - val_mse: 1259.2665 - val_mae: 0.3730\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8847 - mse: 35070509056.0000 - mae: 483.8857 - val_loss: 0.3631 - val_mse: 1259.2703 - val_mae: 0.3631\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3328 - mse: 812.9933 - mae: 0.3328 - val_loss: 0.3649 - val_mse: 1259.2633 - val_mae: 0.3649\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5254 - mse: 25050365952.0000 - mae: 290.5256 - val_loss: 0.3657 - val_mse: 1259.2657 - val_mae: 0.3657\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3613 - mse: 947.6729 - mae: 0.3613 - val_loss: 0.3651 - val_mse: 1259.2673 - val_mae: 0.3651\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4245 - mse: 25050363904.0000 - mae: 290.4245 - val_loss: 0.3626 - val_mse: 1259.2587 - val_mae: 0.3626\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4246 - mse: 1186.1458 - mae: 0.4246 - val_loss: 0.3634 - val_mse: 1259.2585 - val_mae: 0.3634\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3930 - mse: 1045.1530 - mae: 0.3930 - val_loss: 0.3689 - val_mse: 1259.2762 - val_mae: 0.3689\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8814 - mse: 35070509056.0000 - mae: 483.8824 - val_loss: 0.3853 - val_mse: 1259.2679 - val_mae: 0.3853\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5076 - mse: 25050363904.0000 - mae: 290.5075 - val_loss: 0.3708 - val_mse: 1259.2561 - val_mae: 0.3708\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3605 - mse: 1020.9186 - mae: 0.3605 - val_loss: 0.3706 - val_mse: 1259.2766 - val_mae: 0.3706\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3763 - mse: 975.5978 - mae: 0.3763 - val_loss: 0.3650 - val_mse: 1259.2581 - val_mae: 0.3650\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1503 - mse: 30060435456.0000 - mae: 387.1501 - val_loss: 0.3681 - val_mse: 1259.2642 - val_mae: 0.3681\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4769 - mse: 25050365952.0000 - mae: 290.4770 - val_loss: 0.3622 - val_mse: 1259.2593 - val_mae: 0.3622\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3491 - mse: 949.0192 - mae: 0.3491 - val_loss: 0.3701 - val_mse: 1259.2589 - val_mae: 0.3701\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8583 - mse: 20040290304.0000 - mae: 193.8584 - val_loss: 0.3629 - val_mse: 1259.2484 - val_mae: 0.3629\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3144 - mse: 833.5823 - mae: 0.3144 - val_loss: 0.3639 - val_mse: 1259.2638 - val_mae: 0.3639\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3551 - mse: 798.9556 - mae: 0.3551 - val_loss: 0.3770 - val_mse: 1259.2750 - val_mae: 0.3770\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2384 - mse: 30060435456.0000 - mae: 387.2383 - val_loss: 0.3721 - val_mse: 1259.2683 - val_mae: 0.3721\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3621 - mse: 994.3102 - mae: 0.3621 - val_loss: 0.3692 - val_mse: 1259.2744 - val_mae: 0.3692\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9001 - mse: 35070509056.0000 - mae: 483.9001 - val_loss: 0.3739 - val_mse: 1259.2655 - val_mae: 0.3739\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5037 - mse: 25050365952.0000 - mae: 290.5036 - val_loss: 0.3664 - val_mse: 1259.2607 - val_mae: 0.3664\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2773 - mse: 618.2144 - mae: 0.2773 - val_loss: 0.3668 - val_mse: 1259.2688 - val_mae: 0.3668\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9065 - mse: 35070509056.0000 - mae: 483.9067 - val_loss: 0.3685 - val_mse: 1259.2612 - val_mae: 0.3685\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3554 - mse: 944.4655 - mae: 0.3554 - val_loss: 0.3670 - val_mse: 1259.2683 - val_mae: 0.3670\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3859 - mse: 1249.9792 - mae: 0.3859 - val_loss: 0.3671 - val_mse: 1259.2643 - val_mae: 0.3671\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8656 - mse: 35070517248.0000 - mae: 483.8664 - val_loss: 0.3651 - val_mse: 1259.2599 - val_mae: 0.3651\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.8450 - mse: 20040292352.0000 - mae: 193.8451 - val_loss: 0.3722 - val_mse: 1259.2684 - val_mae: 0.3722\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2850 - mse: 682.9429 - mae: 0.2850 - val_loss: 0.4037 - val_mse: 1259.2729 - val_mae: 0.4037\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2511 - mse: 30060435456.0000 - mae: 387.2509 - val_loss: 0.3738 - val_mse: 1259.2589 - val_mae: 0.3738\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3670 - mse: 945.3350 - mae: 0.3670 - val_loss: 0.3660 - val_mse: 1259.2687 - val_mae: 0.3660\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0958 - mse: 30060435456.0000 - mae: 387.0960 - val_loss: 0.3644 - val_mse: 1259.2623 - val_mae: 0.3644\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4035 - mse: 1193.5081 - mae: 0.4035 - val_loss: 0.3686 - val_mse: 1259.2559 - val_mae: 0.3686\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3550 - mse: 1001.4987 - mae: 0.3550 - val_loss: 0.3709 - val_mse: 1259.2637 - val_mae: 0.3709\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7825 - mse: 20040292352.0000 - mae: 193.7826 - val_loss: 0.3695 - val_mse: 1259.2590 - val_mae: 0.3695\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5189 - mse: 40080584704.0000 - mae: 580.5202 - val_loss: 0.3650 - val_mse: 1259.2629 - val_mae: 0.3650\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4361 - mse: 1414.4459 - mae: 0.4361 - val_loss: 0.3618 - val_mse: 1259.2643 - val_mae: 0.3618\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4529 - mse: 25050363904.0000 - mae: 290.4529 - val_loss: 0.3754 - val_mse: 1259.2677 - val_mae: 0.3754\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4115 - mse: 1168.3839 - mae: 0.4115 - val_loss: 0.3664 - val_mse: 1259.2617 - val_mae: 0.3664\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3227 - mse: 45090652160.0000 - mae: 677.3235 - val_loss: 0.3668 - val_mse: 1259.2671 - val_mae: 0.3668\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2617 - mse: 558.0720 - mae: 0.2617 - val_loss: 0.3680 - val_mse: 1259.2710 - val_mae: 0.3680\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3054 - mse: 776.1798 - mae: 0.3054 - val_loss: 0.3633 - val_mse: 1259.2694 - val_mae: 0.3633\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2314 - mse: 30060435456.0000 - mae: 387.2312 - val_loss: 0.3659 - val_mse: 1259.2633 - val_mae: 0.3659\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2789 - mse: 618.3878 - mae: 0.2789 - val_loss: 0.3636 - val_mse: 1259.2573 - val_mae: 0.3636\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2457 - mse: 30060439552.0000 - mae: 387.2457 - val_loss: 0.3634 - val_mse: 1259.2827 - val_mae: 0.3634\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4242 - mse: 25050363904.0000 - mae: 290.4242 - val_loss: 0.3636 - val_mse: 1259.2616 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3425 - mse: 959.4824 - mae: 0.3425 - val_loss: 0.3615 - val_mse: 1259.2616 - val_mae: 0.3615\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7621 - mse: 20040292352.0000 - mae: 193.7621 - val_loss: 0.3743 - val_mse: 1259.2749 - val_mae: 0.3743\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3450 - mse: 928.6231 - mae: 0.3450 - val_loss: 0.3698 - val_mse: 1259.2654 - val_mae: 0.3698\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4618 - mse: 25050363904.0000 - mae: 290.4619 - val_loss: 0.3645 - val_mse: 1259.2628 - val_mae: 0.3645\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4243 - mse: 1228.2808 - mae: 0.4243 - val_loss: 0.3707 - val_mse: 1259.2659 - val_mae: 0.3707\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3819 - mse: 1075.0746 - mae: 0.3819 - val_loss: 0.3643 - val_mse: 1259.2615 - val_mae: 0.3643\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8691 - mse: 35070509056.0000 - mae: 483.8696 - val_loss: 0.3634 - val_mse: 1259.2635 - val_mae: 0.3634\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2938 - mse: 45090652160.0000 - mae: 677.2952 - val_loss: 0.3831 - val_mse: 1259.2634 - val_mae: 0.3831\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.2950 - mse: 709.1141 - mae: 0.2950 - val_loss: 0.3699 - val_mse: 1259.2661 - val_mae: 0.3699\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7674 - mse: 20040292352.0000 - mae: 193.7673 - val_loss: 0.3687 - val_mse: 1259.2631 - val_mae: 0.3687\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3417 - mse: 930.9799 - mae: 0.3417 - val_loss: 0.3621 - val_mse: 1259.2662 - val_mae: 0.3621\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3704 - mse: 899.3829 - mae: 0.3704 - val_loss: 0.3874 - val_mse: 1259.2688 - val_mae: 0.3874\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7817 - mse: 20040292352.0000 - mae: 193.7819 - val_loss: 0.3764 - val_mse: 1259.2723 - val_mae: 0.3764\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4587 - mse: 25050365952.0000 - mae: 290.4587 - val_loss: 0.3663 - val_mse: 1259.2625 - val_mae: 0.3663\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3987 - mse: 1208.0753 - mae: 0.3987 - val_loss: 0.3756 - val_mse: 1259.2695 - val_mae: 0.3756\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3864 - mse: 1196.3260 - mae: 0.3864 - val_loss: 0.3799 - val_mse: 1259.2657 - val_mae: 0.3799\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1497 - mse: 30060435456.0000 - mae: 387.1498 - val_loss: 0.3714 - val_mse: 1259.2699 - val_mae: 0.3714\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8725 - mse: 35070509056.0000 - mae: 483.8726 - val_loss: 0.3649 - val_mse: 1259.2610 - val_mae: 0.3649\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2794 - mse: 683.5565 - mae: 0.2794 - val_loss: 0.3797 - val_mse: 1259.2706 - val_mae: 0.3797\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2864 - mse: 592.9106 - mae: 0.2864 - val_loss: 0.3777 - val_mse: 1259.2639 - val_mae: 0.3777\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8340 - mse: 20040292352.0000 - mae: 193.8341 - val_loss: 0.3656 - val_mse: 1259.2576 - val_mae: 0.3656\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5278 - mse: 25050365952.0000 - mae: 290.5278 - val_loss: 0.3720 - val_mse: 1259.2705 - val_mae: 0.3720\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3038 - mse: 705.3677 - mae: 0.3038 - val_loss: 0.3829 - val_mse: 1259.2701 - val_mae: 0.3829\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3550 - mse: 869.8825 - mae: 0.3550 - val_loss: 0.3657 - val_mse: 1259.2585 - val_mae: 0.3657\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2110 - mse: 30060439552.0000 - mae: 387.2109 - val_loss: 0.3656 - val_mse: 1259.2600 - val_mae: 0.3656\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4256 - mse: 1221.5121 - mae: 0.4256 - val_loss: 0.3736 - val_mse: 1259.2504 - val_mae: 0.3736\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8177 - mse: 35070509056.0000 - mae: 483.8179 - val_loss: 0.3663 - val_mse: 1259.2709 - val_mae: 0.3663\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1591 - mse: 30060435456.0000 - mae: 387.1592 - val_loss: 0.3687 - val_mse: 1259.2627 - val_mae: 0.3687\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4006 - mse: 1239.1163 - mae: 0.4006 - val_loss: 0.3622 - val_mse: 1259.2642 - val_mae: 0.3622\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3380 - mse: 911.1437 - mae: 0.3380 - val_loss: 0.3681 - val_mse: 1259.2664 - val_mae: 0.3681\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1645 - mse: 30060435456.0000 - mae: 387.1647 - val_loss: 0.3635 - val_mse: 1259.2705 - val_mae: 0.3635\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1972 - mse: 30060435456.0000 - mae: 387.1971 - val_loss: 0.3794 - val_mse: 1259.2772 - val_mae: 0.3794\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3618 - mse: 987.2815 - mae: 0.3618 - val_loss: 0.3786 - val_mse: 1259.2676 - val_mae: 0.3786\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3647 - mse: 25050363904.0000 - mae: 290.3647 - val_loss: 0.3667 - val_mse: 1259.2664 - val_mae: 0.3667\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4573 - mse: 1476.0635 - mae: 0.4573 - val_loss: 0.3643 - val_mse: 1259.2655 - val_mae: 0.3643\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2696 - mse: 30060435456.0000 - mae: 387.2695 - val_loss: 0.3676 - val_mse: 1259.2621 - val_mae: 0.3676\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3276 - mse: 835.7683 - mae: 0.3276 - val_loss: 0.3735 - val_mse: 1259.2659 - val_mae: 0.3735\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3974 - mse: 1277.1326 - mae: 0.3974 - val_loss: 0.3699 - val_mse: 1259.2620 - val_mae: 0.3699\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1465 - mse: 30060435456.0000 - mae: 387.1464 - val_loss: 0.3700 - val_mse: 1259.2625 - val_mae: 0.3700\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3806 - mse: 1166.6659 - mae: 0.3806 - val_loss: 0.3636 - val_mse: 1259.2667 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0943 - mse: 30060435456.0000 - mae: 387.0942 - val_loss: 0.3684 - val_mse: 1259.2572 - val_mae: 0.3684\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3173 - mse: 648.7740 - mae: 0.3173 - val_loss: 0.3833 - val_mse: 1259.2855 - val_mae: 0.3833\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1993 - mse: 30060435456.0000 - mae: 387.1994 - val_loss: 0.3651 - val_mse: 1259.2740 - val_mae: 0.3651\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1760 - mse: 30060435456.0000 - mae: 387.1761 - val_loss: 0.3900 - val_mse: 1259.2688 - val_mae: 0.3900\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3451 - mse: 930.0989 - mae: 0.3451 - val_loss: 0.3695 - val_mse: 1259.2616 - val_mae: 0.3695\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4157 - mse: 1210.7026 - mae: 0.4157 - val_loss: 0.3715 - val_mse: 1259.2622 - val_mae: 0.3715\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4281 - mse: 25050363904.0000 - mae: 290.4281 - val_loss: 0.3638 - val_mse: 1259.2664 - val_mae: 0.3638\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3140 - mse: 737.3538 - mae: 0.3140 - val_loss: 0.3648 - val_mse: 1259.2670 - val_mae: 0.3648\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7872 - mse: 20040290304.0000 - mae: 193.7872 - val_loss: 0.3680 - val_mse: 1259.2695 - val_mae: 0.3680\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8624 - mse: 35070509056.0000 - mae: 483.8626 - val_loss: 0.3661 - val_mse: 1259.2593 - val_mae: 0.3661\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4365 - mse: 1325.6094 - mae: 0.4365 - val_loss: 0.3673 - val_mse: 1259.2694 - val_mae: 0.3673\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2041 - mse: 30060435456.0000 - mae: 387.2041 - val_loss: 0.3743 - val_mse: 1259.2584 - val_mae: 0.3743\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3986 - mse: 1075.0474 - mae: 0.3986 - val_loss: 0.3697 - val_mse: 1259.2595 - val_mae: 0.3697\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9498 - mse: 35070513152.0000 - mae: 483.9508 - val_loss: 0.3770 - val_mse: 1259.2687 - val_mae: 0.3770\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3340 - mse: 952.6478 - mae: 0.3340 - val_loss: 0.3649 - val_mse: 1259.2628 - val_mae: 0.3649\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4410 - mse: 25050365952.0000 - mae: 290.4409 - val_loss: 0.3651 - val_mse: 1259.2784 - val_mae: 0.3651\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4274 - mse: 1429.1029 - mae: 0.4274 - val_loss: 0.3659 - val_mse: 1259.2672 - val_mae: 0.3659\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4305 - mse: 25050365952.0000 - mae: 290.4304 - val_loss: 0.3672 - val_mse: 1259.2717 - val_mae: 0.3672\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4347 - mse: 1262.1644 - mae: 0.4347 - val_loss: 0.3679 - val_mse: 1259.2428 - val_mae: 0.3679\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4316 - mse: 25050365952.0000 - mae: 290.4319 - val_loss: 0.3643 - val_mse: 1259.2693 - val_mae: 0.3643\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4553 - mse: 1337.5358 - mae: 0.4553 - val_loss: 0.3628 - val_mse: 1259.2629 - val_mae: 0.3628\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3620 - mse: 965.9871 - mae: 0.3620 - val_loss: 0.3718 - val_mse: 1259.2657 - val_mae: 0.3718\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7865 - mse: 20040290304.0000 - mae: 193.7865 - val_loss: 0.3668 - val_mse: 1259.2603 - val_mae: 0.3668\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2552 - mse: 30060435456.0000 - mae: 387.2552 - val_loss: 0.3704 - val_mse: 1259.2684 - val_mae: 0.3704\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3551 - mse: 938.9386 - mae: 0.3551 - val_loss: 0.3650 - val_mse: 1259.2725 - val_mae: 0.3650\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5730 - mse: 40080584704.0000 - mae: 580.5735 - val_loss: 0.3652 - val_mse: 1259.2620 - val_mae: 0.3652\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3794 - mse: 1118.0510 - mae: 0.3794 - val_loss: 0.3648 - val_mse: 1259.2659 - val_mae: 0.3648\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2049 - mse: 30060435456.0000 - mae: 387.2051 - val_loss: 0.3675 - val_mse: 1259.2543 - val_mae: 0.3675\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2977 - mse: 695.0968 - mae: 0.2977 - val_loss: 0.3681 - val_mse: 1259.2640 - val_mae: 0.3681\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4641 - mse: 25050365952.0000 - mae: 290.4641 - val_loss: 0.3629 - val_mse: 1259.2687 - val_mae: 0.3629\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4538 - mse: 1497.6311 - mae: 0.4538 - val_loss: 0.3623 - val_mse: 1259.2570 - val_mae: 0.3623\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3694 - mse: 867.0451 - mae: 0.3694 - val_loss: 0.3700 - val_mse: 1259.2644 - val_mae: 0.3700\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8017 - mse: 20040292352.0000 - mae: 193.8017 - val_loss: 0.3707 - val_mse: 1259.2621 - val_mae: 0.3707\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 193.7222 - mse: 20040290304.0000 - mae: 193.7221 - val_loss: 0.3740 - val_mse: 1259.2675 - val_mae: 0.3740\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4267 - mse: 1220.2412 - mae: 0.4267 - val_loss: 0.3686 - val_mse: 1259.2721 - val_mae: 0.3686\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7080 - mse: 20040290304.0000 - mae: 193.7080 - val_loss: 0.3843 - val_mse: 1259.2745 - val_mae: 0.3843\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4198 - mse: 1228.6395 - mae: 0.4198 - val_loss: 0.3711 - val_mse: 1259.2657 - val_mae: 0.3711\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7891 - mse: 20040292352.0000 - mae: 193.7891 - val_loss: 0.3691 - val_mse: 1259.2672 - val_mae: 0.3691\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3991 - mse: 1259.5820 - mae: 0.3991 - val_loss: 0.3647 - val_mse: 1259.2649 - val_mae: 0.3647\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3128 - mse: 665.2614 - mae: 0.3128 - val_loss: 0.3617 - val_mse: 1259.2618 - val_mae: 0.3617\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2566 - mse: 30060435456.0000 - mae: 387.2564 - val_loss: 0.3667 - val_mse: 1259.2670 - val_mae: 0.3667\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2137 - mse: 30060439552.0000 - mae: 387.2133 - val_loss: 0.3707 - val_mse: 1259.2670 - val_mae: 0.3707\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3662 - mse: 924.4385 - mae: 0.3662 - val_loss: 0.3687 - val_mse: 1259.2695 - val_mae: 0.3687\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8771 - mse: 35070509056.0000 - mae: 483.8773 - val_loss: 0.3647 - val_mse: 1259.2671 - val_mae: 0.3647\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3765 - mse: 1026.5432 - mae: 0.3765 - val_loss: 0.3639 - val_mse: 1259.2616 - val_mae: 0.3639\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3935 - mse: 1277.2150 - mae: 0.3935 - val_loss: 0.3985 - val_mse: 1259.2736 - val_mae: 0.3985\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4191 - mse: 25050363904.0000 - mae: 290.4195 - val_loss: 0.3646 - val_mse: 1259.2646 - val_mae: 0.3646\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5326 - mse: 25050363904.0000 - mae: 290.5325 - val_loss: 0.3630 - val_mse: 1259.2642 - val_mae: 0.3630\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3151 - mse: 849.7769 - mae: 0.3151 - val_loss: 0.3643 - val_mse: 1259.2657 - val_mae: 0.3643\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5355 - mse: 25050365952.0000 - mae: 290.5354 - val_loss: 0.3735 - val_mse: 1259.2587 - val_mae: 0.3735\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3446 - mse: 872.5491 - mae: 0.3446 - val_loss: 0.3632 - val_mse: 1259.2644 - val_mae: 0.3632\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3949 - mse: 1065.3230 - mae: 0.3949 - val_loss: 0.3890 - val_mse: 1259.2828 - val_mae: 0.3890\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4964 - mse: 25050363904.0000 - mae: 290.4963 - val_loss: 0.3846 - val_mse: 1259.2650 - val_mae: 0.3846\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4037 - mse: 1093.2578 - mae: 0.4037 - val_loss: 0.3680 - val_mse: 1259.2665 - val_mae: 0.3680\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8810 - mse: 35070509056.0000 - mae: 483.8811 - val_loss: 0.3675 - val_mse: 1259.2584 - val_mae: 0.3675\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5870 - mse: 40080580608.0000 - mae: 580.5878 - val_loss: 0.3646 - val_mse: 1259.2649 - val_mae: 0.3646\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3905 - mse: 1090.7585 - mae: 0.3905 - val_loss: 0.3656 - val_mse: 1259.2542 - val_mae: 0.3656\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3039 - mse: 803.7426 - mae: 0.3039 - val_loss: 0.3690 - val_mse: 1259.2676 - val_mae: 0.3690\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6554 - mse: 40080580608.0000 - mae: 580.6555 - val_loss: 0.3628 - val_mse: 1259.2632 - val_mae: 0.3628\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3314 - mse: 823.3410 - mae: 0.3314 - val_loss: 0.3650 - val_mse: 1259.2629 - val_mae: 0.3650\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4685 - mse: 25050365952.0000 - mae: 290.4684 - val_loss: 0.3610 - val_mse: 1259.2656 - val_mae: 0.3610\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3706 - mse: 810.7411 - mae: 0.3706 - val_loss: 0.3816 - val_mse: 1259.2800 - val_mae: 0.3816\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4844 - mse: 25050363904.0000 - mae: 290.4846 - val_loss: 0.3712 - val_mse: 1259.2766 - val_mae: 0.3712\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3420 - mse: 958.1840 - mae: 0.3420 - val_loss: 0.3672 - val_mse: 1259.2656 - val_mae: 0.3672\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8346 - mse: 35070509056.0000 - mae: 483.8354 - val_loss: 0.3799 - val_mse: 1259.2439 - val_mae: 0.3799\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2761 - mse: 30060435456.0000 - mae: 387.2763 - val_loss: 0.3629 - val_mse: 1259.2679 - val_mae: 0.3629\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3003 - mse: 688.9440 - mae: 0.3003 - val_loss: 0.3631 - val_mse: 1259.2642 - val_mae: 0.3631\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3714 - mse: 1018.2348 - mae: 0.3714 - val_loss: 0.3690 - val_mse: 1259.2659 - val_mae: 0.3690\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1725 - mse: 30060435456.0000 - mae: 387.1725 - val_loss: 0.3661 - val_mse: 1259.2535 - val_mae: 0.3661\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1401 - mse: 30060435456.0000 - mae: 387.1402 - val_loss: 0.3658 - val_mse: 1259.2560 - val_mae: 0.3658\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3925 - mse: 1070.6737 - mae: 0.3925 - val_loss: 0.3618 - val_mse: 1259.2593 - val_mae: 0.3618\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1225 - mse: 30060435456.0000 - mae: 387.1225 - val_loss: 0.3710 - val_mse: 1259.2640 - val_mae: 0.3710\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4719 - mse: 1518.3607 - mae: 0.4719 - val_loss: 0.3735 - val_mse: 1259.2628 - val_mae: 0.3735\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2788 - mse: 517.5903 - mae: 0.2788 - val_loss: 0.3659 - val_mse: 1259.2451 - val_mae: 0.3659\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8986 - mse: 35070509056.0000 - mae: 483.8995 - val_loss: 0.3706 - val_mse: 1259.2598 - val_mae: 0.3706\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3224 - mse: 752.3027 - mae: 0.3224 - val_loss: 0.3659 - val_mse: 1259.2661 - val_mae: 0.3659\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1986 - mse: 30060435456.0000 - mae: 387.1989 - val_loss: 0.3666 - val_mse: 1259.2584 - val_mae: 0.3666\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1759 - mse: 30060435456.0000 - mae: 387.1759 - val_loss: 0.3715 - val_mse: 1259.2679 - val_mae: 0.3715\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3357 - mse: 792.2289 - mae: 0.3357 - val_loss: 0.3637 - val_mse: 1259.2576 - val_mae: 0.3637\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5219 - mse: 40080580608.0000 - mae: 580.5228 - val_loss: 0.3661 - val_mse: 1259.2579 - val_mae: 0.3661\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4071 - mse: 1272.7111 - mae: 0.4071 - val_loss: 0.3654 - val_mse: 1259.2621 - val_mae: 0.3654\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9950 - mse: 35070509056.0000 - mae: 483.9948 - val_loss: 0.3826 - val_mse: 1259.2870 - val_mae: 0.3826\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3043 - mse: 744.3864 - mae: 0.3043 - val_loss: 0.3668 - val_mse: 1259.2618 - val_mae: 0.3668\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3791 - mse: 25050365952.0000 - mae: 290.3792 - val_loss: 0.3658 - val_mse: 1259.2646 - val_mae: 0.3658\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4674 - mse: 1390.1636 - mae: 0.4674 - val_loss: 0.3689 - val_mse: 1259.2605 - val_mae: 0.3689\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4487 - mse: 25050365952.0000 - mae: 290.4487 - val_loss: 0.3657 - val_mse: 1259.2653 - val_mae: 0.3657\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3427 - mse: 911.2048 - mae: 0.3427 - val_loss: 0.3635 - val_mse: 1259.2581 - val_mae: 0.3635\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3432 - mse: 922.4324 - mae: 0.3432 - val_loss: 0.3821 - val_mse: 1259.2772 - val_mae: 0.3821\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8318 - mse: 20040292352.0000 - mae: 193.8318 - val_loss: 0.3658 - val_mse: 1259.2603 - val_mae: 0.3658\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3932 - mse: 1218.0891 - mae: 0.3932 - val_loss: 0.3627 - val_mse: 1259.2644 - val_mae: 0.3627\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7338 - mse: 20040290304.0000 - mae: 193.7337 - val_loss: 0.3645 - val_mse: 1259.2684 - val_mae: 0.3645\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3712 - mse: 882.3489 - mae: 0.3712 - val_loss: 0.3730 - val_mse: 1259.2675 - val_mae: 0.3730\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4959 - mse: 25050365952.0000 - mae: 290.4960 - val_loss: 0.3658 - val_mse: 1259.2682 - val_mae: 0.3658\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4517 - mse: 1337.7863 - mae: 0.4517 - val_loss: 0.3753 - val_mse: 1259.2648 - val_mae: 0.3753\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5589 - mse: 40080580608.0000 - mae: 580.5598 - val_loss: 0.3652 - val_mse: 1259.2607 - val_mae: 0.3652\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2205 - mse: 30060435456.0000 - mae: 387.2206 - val_loss: 0.3649 - val_mse: 1259.2697 - val_mae: 0.3649\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3669 - mse: 1049.5200 - mae: 0.3669 - val_loss: 0.3630 - val_mse: 1259.2694 - val_mae: 0.3630\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2408 - mse: 45090652160.0000 - mae: 677.2408 - val_loss: 0.3619 - val_mse: 1259.2598 - val_mae: 0.3619\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3580 - mse: 1026.4622 - mae: 0.3580 - val_loss: 0.3664 - val_mse: 1259.2755 - val_mae: 0.3664\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4056 - mse: 1141.0944 - mae: 0.4056 - val_loss: 0.3636 - val_mse: 1259.2633 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4568 - mse: 25050365952.0000 - mae: 290.4568 - val_loss: 0.3622 - val_mse: 1259.2649 - val_mae: 0.3622\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9538 - mse: 35070513152.0000 - mae: 483.9539 - val_loss: 0.3781 - val_mse: 1259.2723 - val_mae: 0.3781\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3893 - mse: 972.3552 - mae: 0.3893 - val_loss: 0.3664 - val_mse: 1259.2697 - val_mae: 0.3664\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4179 - mse: 1181.1932 - mae: 0.4179 - val_loss: 0.3697 - val_mse: 1259.2704 - val_mae: 0.3697\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1391 - mse: 30060435456.0000 - mae: 387.1389 - val_loss: 0.3675 - val_mse: 1259.2646 - val_mae: 0.3675\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3184 - mse: 783.1597 - mae: 0.3184 - val_loss: 0.3630 - val_mse: 1259.2727 - val_mae: 0.3630\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3808 - mse: 45090660352.0000 - mae: 677.3810 - val_loss: 0.3643 - val_mse: 1259.2573 - val_mae: 0.3643\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8032 - mse: 20040290304.0000 - mae: 193.8030 - val_loss: 0.3657 - val_mse: 1259.2687 - val_mae: 0.3657\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2745 - mse: 598.7151 - mae: 0.2745 - val_loss: 0.3670 - val_mse: 1259.2668 - val_mae: 0.3670\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3961 - mse: 1158.6837 - mae: 0.3961 - val_loss: 0.3676 - val_mse: 1259.2667 - val_mae: 0.3676\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8897 - mse: 35070509056.0000 - mae: 483.8903 - val_loss: 0.3625 - val_mse: 1259.2656 - val_mae: 0.3625\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3866 - mse: 987.5536 - mae: 0.3866 - val_loss: 0.3684 - val_mse: 1259.2734 - val_mae: 0.3684\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5643 - mse: 40080580608.0000 - mae: 580.5652 - val_loss: 0.3743 - val_mse: 1259.2736 - val_mae: 0.3743\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1897 - mse: 30060435456.0000 - mae: 387.1897 - val_loss: 0.3646 - val_mse: 1259.2561 - val_mae: 0.3646\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3386 - mse: 777.1046 - mae: 0.3386 - val_loss: 0.3811 - val_mse: 1259.2681 - val_mae: 0.3811\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3206 - mse: 719.4739 - mae: 0.3206 - val_loss: 0.3633 - val_mse: 1259.2655 - val_mae: 0.3633\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7857 - mse: 20040292352.0000 - mae: 193.7856 - val_loss: 0.3661 - val_mse: 1259.2667 - val_mae: 0.3661\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1028 - mse: 30060435456.0000 - mae: 387.1028 - val_loss: 0.3620 - val_mse: 1259.2593 - val_mae: 0.3620\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4567 - mse: 1490.8444 - mae: 0.4567 - val_loss: 0.3662 - val_mse: 1259.2622 - val_mae: 0.3662\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3158 - mse: 713.4546 - mae: 0.3158 - val_loss: 0.3633 - val_mse: 1259.2635 - val_mae: 0.3633\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0387 - mse: 50100727808.0000 - mae: 774.0392 - val_loss: 0.3633 - val_mse: 1259.2653 - val_mae: 0.3633\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5701 - mse: 25050365952.0000 - mae: 290.5702 - val_loss: 0.3820 - val_mse: 1259.2719 - val_mae: 0.3820\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3164 - mse: 702.7407 - mae: 0.3164 - val_loss: 0.3775 - val_mse: 1259.2588 - val_mae: 0.3775\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4086 - mse: 25050363904.0000 - mae: 290.4087 - val_loss: 0.3650 - val_mse: 1259.2628 - val_mae: 0.3650\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3973 - mse: 1111.1841 - mae: 0.3973 - val_loss: 0.3662 - val_mse: 1259.2593 - val_mae: 0.3662\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3173 - mse: 820.0385 - mae: 0.3173 - val_loss: 0.3759 - val_mse: 1259.2588 - val_mae: 0.3759\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8648 - mse: 20040292352.0000 - mae: 193.8647 - val_loss: 0.3690 - val_mse: 1259.2719 - val_mae: 0.3690\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4286 - mse: 1309.2292 - mae: 0.4286 - val_loss: 0.3648 - val_mse: 1259.2659 - val_mae: 0.3648\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3873 - mse: 25050365952.0000 - mae: 290.3872 - val_loss: 0.3663 - val_mse: 1259.2733 - val_mae: 0.3663\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3411 - mse: 1024.3832 - mae: 0.3411 - val_loss: 0.3628 - val_mse: 1259.2689 - val_mae: 0.3628\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4734 - mse: 25050363904.0000 - mae: 290.4734 - val_loss: 0.3809 - val_mse: 1259.2618 - val_mae: 0.3809\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4288 - mse: 1175.2373 - mae: 0.4288 - val_loss: 0.3720 - val_mse: 1259.2819 - val_mae: 0.3720\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4412 - mse: 25050365952.0000 - mae: 290.4413 - val_loss: 0.3732 - val_mse: 1259.2825 - val_mae: 0.3732\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3824 - mse: 1082.9434 - mae: 0.3824 - val_loss: 0.3632 - val_mse: 1259.2499 - val_mae: 0.3632\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4617 - mse: 25050365952.0000 - mae: 290.4617 - val_loss: 0.3667 - val_mse: 1259.2646 - val_mae: 0.3667\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3091 - mse: 799.0392 - mae: 0.3091 - val_loss: 0.3678 - val_mse: 1259.2639 - val_mae: 0.3678\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9360 - mse: 35070509056.0000 - mae: 483.9370 - val_loss: 0.3637 - val_mse: 1259.2623 - val_mae: 0.3637\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.3066 - mse: 30060439552.0000 - mae: 387.3064 - val_loss: 0.3647 - val_mse: 1259.2634 - val_mae: 0.3647\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3090 - mse: 731.8863 - mae: 0.3090 - val_loss: 0.3664 - val_mse: 1259.2605 - val_mae: 0.3664\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3047 - mse: 831.4590 - mae: 0.3047 - val_loss: 0.3626 - val_mse: 1259.2584 - val_mae: 0.3626\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9596 - mse: 35070509056.0000 - mae: 483.9606 - val_loss: 0.3631 - val_mse: 1259.2612 - val_mae: 0.3631\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2263 - mse: 30060435456.0000 - mae: 387.2264 - val_loss: 0.3678 - val_mse: 1259.2656 - val_mae: 0.3678\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3859 - mse: 1102.2767 - mae: 0.3859 - val_loss: 0.3691 - val_mse: 1259.2590 - val_mae: 0.3691\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2957 - mse: 667.9780 - mae: 0.2957 - val_loss: 0.3673 - val_mse: 1259.2631 - val_mae: 0.3673\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5100 - mse: 25050365952.0000 - mae: 290.5098 - val_loss: 0.3791 - val_mse: 1259.2677 - val_mae: 0.3791\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4249 - mse: 1395.3811 - mae: 0.4249 - val_loss: 0.3705 - val_mse: 1259.2750 - val_mae: 0.3705\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7292 - mse: 20040292352.0000 - mae: 193.7292 - val_loss: 0.3757 - val_mse: 1259.2499 - val_mae: 0.3757\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1892 - mse: 30060435456.0000 - mae: 387.1892 - val_loss: 0.3644 - val_mse: 1259.2672 - val_mae: 0.3644\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3667 - mse: 1053.2292 - mae: 0.3667 - val_loss: 0.3643 - val_mse: 1259.2617 - val_mae: 0.3643\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1948 - mse: 30060435456.0000 - mae: 387.1946 - val_loss: 0.3753 - val_mse: 1259.2593 - val_mae: 0.3753\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3863 - mse: 1170.5930 - mae: 0.3863 - val_loss: 0.3613 - val_mse: 1259.2606 - val_mae: 0.3613\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5949 - mse: 40080580608.0000 - mae: 580.5954 - val_loss: 0.3733 - val_mse: 1259.2625 - val_mae: 0.3733\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4099 - mse: 1127.1107 - mae: 0.4099 - val_loss: 0.3736 - val_mse: 1259.2704 - val_mae: 0.3736\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2405 - mse: 30060439552.0000 - mae: 387.2405 - val_loss: 0.3650 - val_mse: 1259.2601 - val_mae: 0.3650\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3399 - mse: 906.7755 - mae: 0.3399 - val_loss: 0.3669 - val_mse: 1259.2588 - val_mae: 0.3669\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2623 - mse: 30060435456.0000 - mae: 387.2622 - val_loss: 0.3707 - val_mse: 1259.2661 - val_mae: 0.3707\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3084 - mse: 828.5937 - mae: 0.3084 - val_loss: 0.3635 - val_mse: 1259.2656 - val_mae: 0.3635\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0651 - mse: 30060435456.0000 - mae: 387.0649 - val_loss: 0.3629 - val_mse: 1259.2651 - val_mae: 0.3629\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4353 - mse: 1360.2191 - mae: 0.4353 - val_loss: 0.3646 - val_mse: 1259.2510 - val_mae: 0.3646\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1556 - mse: 30060435456.0000 - mae: 387.1561 - val_loss: 0.3657 - val_mse: 1259.2463 - val_mae: 0.3657\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3941 - mse: 1229.6038 - mae: 0.3941 - val_loss: 0.3605 - val_mse: 1259.2645 - val_mae: 0.3605\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9858 - mse: 35070509056.0000 - mae: 483.9856 - val_loss: 0.3736 - val_mse: 1259.2667 - val_mae: 0.3736\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3442 - mse: 885.9064 - mae: 0.3442 - val_loss: 0.3788 - val_mse: 1259.2676 - val_mae: 0.3788\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3513 - mse: 915.9003 - mae: 0.3513 - val_loss: 0.3666 - val_mse: 1259.2606 - val_mae: 0.3666\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8447 - mse: 35070509056.0000 - mae: 483.8447 - val_loss: 0.3722 - val_mse: 1259.2649 - val_mae: 0.3722\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3103 - mse: 45090652160.0000 - mae: 677.3109 - val_loss: 0.3735 - val_mse: 1259.2660 - val_mae: 0.3735\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3556 - mse: 946.1331 - mae: 0.3556 - val_loss: 0.3673 - val_mse: 1259.2739 - val_mae: 0.3673\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0779 - mse: 30060439552.0000 - mae: 387.0778 - val_loss: 0.3654 - val_mse: 1259.2688 - val_mae: 0.3654\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4761 - mse: 1543.9500 - mae: 0.4761 - val_loss: 0.3647 - val_mse: 1259.2618 - val_mae: 0.3647\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6010 - mse: 40080580608.0000 - mae: 580.6011 - val_loss: 0.3664 - val_mse: 1259.2654 - val_mae: 0.3664\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3057 - mse: 767.9907 - mae: 0.3057 - val_loss: 0.3657 - val_mse: 1259.2590 - val_mae: 0.3657\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.3127 - mse: 30060435456.0000 - mae: 387.3125 - val_loss: 0.3972 - val_mse: 1259.2731 - val_mae: 0.3972\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2791 - mse: 556.7454 - mae: 0.2791 - val_loss: 0.3711 - val_mse: 1259.2748 - val_mae: 0.3711\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4787 - mse: 1609.5037 - mae: 0.4787 - val_loss: 0.3646 - val_mse: 1259.2570 - val_mae: 0.3646\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0342 - mse: 30060435456.0000 - mae: 387.0341 - val_loss: 0.3756 - val_mse: 1259.2637 - val_mae: 0.3756\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3817 - mse: 1078.1919 - mae: 0.3817 - val_loss: 0.3657 - val_mse: 1259.2676 - val_mae: 0.3657\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3021 - mse: 45090652160.0000 - mae: 677.3027 - val_loss: 0.3832 - val_mse: 1259.2633 - val_mae: 0.3832\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3162 - mse: 839.4900 - mae: 0.3162 - val_loss: 0.3640 - val_mse: 1259.2643 - val_mae: 0.3640\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9044 - mse: 35070509056.0000 - mae: 483.9050 - val_loss: 0.3618 - val_mse: 1259.2614 - val_mae: 0.3618\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4279 - mse: 1306.0697 - mae: 0.4279 - val_loss: 0.3639 - val_mse: 1259.2653 - val_mae: 0.3639\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7926 - mse: 35070509056.0000 - mae: 483.7935 - val_loss: 0.3617 - val_mse: 1259.2639 - val_mae: 0.3617\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1544 - mse: 30060435456.0000 - mae: 387.1542 - val_loss: 0.3877 - val_mse: 1259.2742 - val_mae: 0.3877\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3566 - mse: 946.9800 - mae: 0.3566 - val_loss: 0.3696 - val_mse: 1259.2681 - val_mae: 0.3696\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4062 - mse: 1041.4465 - mae: 0.4062 - val_loss: 0.3775 - val_mse: 1259.2695 - val_mae: 0.3775\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4569 - mse: 25050363904.0000 - mae: 290.4568 - val_loss: 0.3661 - val_mse: 1259.2614 - val_mae: 0.3661\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3124 - mse: 45090652160.0000 - mae: 677.3137 - val_loss: 0.3656 - val_mse: 1259.2671 - val_mae: 0.3656\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3489 - mse: 899.3521 - mae: 0.3489 - val_loss: 0.3657 - val_mse: 1259.2596 - val_mae: 0.3657\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3124 - mse: 776.1643 - mae: 0.3124 - val_loss: 0.3660 - val_mse: 1259.2709 - val_mae: 0.3660\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1937 - mse: 30060435456.0000 - mae: 387.1935 - val_loss: 0.3710 - val_mse: 1259.2655 - val_mae: 0.3710\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1929 - mse: 30060435456.0000 - mae: 387.1928 - val_loss: 0.3623 - val_mse: 1259.2698 - val_mae: 0.3623\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4028 - mse: 1127.8191 - mae: 0.4028 - val_loss: 0.3619 - val_mse: 1259.2719 - val_mae: 0.3619\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4109 - mse: 25050363904.0000 - mae: 290.4109 - val_loss: 0.3846 - val_mse: 1259.2762 - val_mae: 0.3846\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4827 - mse: 1537.8578 - mae: 0.4827 - val_loss: 0.3700 - val_mse: 1259.2687 - val_mae: 0.3700\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4678 - mse: 1448.3615 - mae: 0.4678 - val_loss: 0.3682 - val_mse: 1259.2595 - val_mae: 0.3682\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7103 - mse: 20040292352.0000 - mae: 193.7103 - val_loss: 0.3714 - val_mse: 1259.2653 - val_mae: 0.3714\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3756 - mse: 1070.1552 - mae: 0.3756 - val_loss: 0.3648 - val_mse: 1259.2648 - val_mae: 0.3648\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1873 - mse: 30060439552.0000 - mae: 387.1874 - val_loss: 0.3638 - val_mse: 1259.2655 - val_mae: 0.3638\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3946 - mse: 1197.0508 - mae: 0.3946 - val_loss: 0.3666 - val_mse: 1259.2679 - val_mae: 0.3666\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1490 - mse: 30060439552.0000 - mae: 387.1489 - val_loss: 0.3649 - val_mse: 1259.2676 - val_mae: 0.3649\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4801 - mse: 25050363904.0000 - mae: 290.4799 - val_loss: 0.3621 - val_mse: 1259.2618 - val_mae: 0.3621\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4276 - mse: 1257.0044 - mae: 0.4276 - val_loss: 0.3696 - val_mse: 1259.2604 - val_mae: 0.3696\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 387.3177 - mse: 30060435456.0000 - mae: 387.3177 - val_loss: 0.3744 - val_mse: 1259.2635 - val_mae: 0.3744\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2159 - mse: 367.4144 - mae: 0.2159 - val_loss: 0.3665 - val_mse: 1259.2648 - val_mae: 0.3665\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3948 - mse: 1225.0045 - mae: 0.3948 - val_loss: 0.3734 - val_mse: 1259.2673 - val_mae: 0.3734\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5352 - mse: 40080584704.0000 - mae: 580.5352 - val_loss: 0.3736 - val_mse: 1259.2598 - val_mae: 0.3736\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3243 - mse: 736.7578 - mae: 0.3243 - val_loss: 0.3690 - val_mse: 1259.2644 - val_mae: 0.3690\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3404 - mse: 45090652160.0000 - mae: 677.3404 - val_loss: 0.3670 - val_mse: 1259.2625 - val_mae: 0.3670\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2645 - mse: 376.9199 - mae: 0.2645 - val_loss: 0.3644 - val_mse: 1259.2642 - val_mae: 0.3644\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8935 - mse: 20040294400.0000 - mae: 193.8934 - val_loss: 0.3640 - val_mse: 1259.2588 - val_mae: 0.3640\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1563 - mse: 30060435456.0000 - mae: 387.1564 - val_loss: 0.3650 - val_mse: 1259.2559 - val_mae: 0.3650\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3906 - mse: 1236.2498 - mae: 0.3906 - val_loss: 0.3677 - val_mse: 1259.2627 - val_mae: 0.3677\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2862 - mse: 504.5361 - mae: 0.2862 - val_loss: 0.3685 - val_mse: 1259.2758 - val_mae: 0.3685\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.6673 - mse: 25050365952.0000 - mae: 290.6671 - val_loss: 0.3697 - val_mse: 1259.2649 - val_mae: 0.3697\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9262 - mse: 35070509056.0000 - mae: 483.9263 - val_loss: 0.3736 - val_mse: 1259.2607 - val_mae: 0.3736\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3421 - mse: 908.8365 - mae: 0.3421 - val_loss: 0.3646 - val_mse: 1259.2632 - val_mae: 0.3646\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4121 - mse: 1217.7793 - mae: 0.4121 - val_loss: 0.3712 - val_mse: 1259.2672 - val_mae: 0.3712\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4129 - mse: 25050363904.0000 - mae: 290.4129 - val_loss: 0.3651 - val_mse: 1259.2626 - val_mae: 0.3651\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4945 - mse: 25050365952.0000 - mae: 290.4946 - val_loss: 0.3620 - val_mse: 1259.2615 - val_mae: 0.3620\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3684 - mse: 1049.0347 - mae: 0.3684 - val_loss: 0.3623 - val_mse: 1259.2653 - val_mae: 0.3623\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4404 - mse: 25050365952.0000 - mae: 290.4404 - val_loss: 0.3624 - val_mse: 1259.2589 - val_mae: 0.3624\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3780 - mse: 970.6987 - mae: 0.3780 - val_loss: 0.3648 - val_mse: 1259.2544 - val_mae: 0.3648\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7534 - mse: 20040290304.0000 - mae: 193.7534 - val_loss: 0.3700 - val_mse: 1259.2655 - val_mae: 0.3700\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3979 - mse: 1174.1989 - mae: 0.3979 - val_loss: 0.3736 - val_mse: 1259.2667 - val_mae: 0.3736\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1479 - mse: 30060439552.0000 - mae: 387.1478 - val_loss: 0.3669 - val_mse: 1259.2706 - val_mae: 0.3669\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4186 - mse: 1195.2878 - mae: 0.4186 - val_loss: 0.3690 - val_mse: 1259.2607 - val_mae: 0.3690\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5040 - mse: 25050365952.0000 - mae: 290.5041 - val_loss: 0.3631 - val_mse: 1259.2660 - val_mae: 0.3631\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3894 - mse: 1119.9625 - mae: 0.3894 - val_loss: 0.3742 - val_mse: 1259.2552 - val_mae: 0.3742\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3327 - mse: 857.0742 - mae: 0.3327 - val_loss: 0.3646 - val_mse: 1259.2645 - val_mae: 0.3646\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7464 - mse: 20040292352.0000 - mae: 193.7463 - val_loss: 0.3728 - val_mse: 1259.2673 - val_mae: 0.3728\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3493 - mse: 898.0794 - mae: 0.3493 - val_loss: 0.3631 - val_mse: 1259.2638 - val_mae: 0.3631\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8337 - mse: 20040292352.0000 - mae: 193.8338 - val_loss: 0.3749 - val_mse: 1259.2673 - val_mae: 0.3749\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3351 - mse: 742.3148 - mae: 0.3351 - val_loss: 0.3725 - val_mse: 1259.2722 - val_mae: 0.3725\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9114 - mse: 35070509056.0000 - mae: 483.9124 - val_loss: 0.3754 - val_mse: 1259.2789 - val_mae: 0.3754\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6402 - mse: 40080584704.0000 - mae: 580.6402 - val_loss: 0.3664 - val_mse: 1259.2609 - val_mae: 0.3664\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3141 - mse: 756.1866 - mae: 0.3141 - val_loss: 0.3641 - val_mse: 1259.2687 - val_mae: 0.3641\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8210 - mse: 35070509056.0000 - mae: 483.8212 - val_loss: 0.3734 - val_mse: 1259.2679 - val_mae: 0.3734\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4118 - mse: 1187.1812 - mae: 0.4118 - val_loss: 0.3928 - val_mse: 1259.2687 - val_mae: 0.3928\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4922 - mse: 25050365952.0000 - mae: 290.4923 - val_loss: 0.3678 - val_mse: 1259.2631 - val_mae: 0.3678\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3280 - mse: 932.1141 - mae: 0.3280 - val_loss: 0.3618 - val_mse: 1259.2690 - val_mae: 0.3618\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3480 - mse: 1060.8757 - mae: 0.3480 - val_loss: 0.3624 - val_mse: 1259.2533 - val_mae: 0.3624\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5707 - mse: 40080580608.0000 - mae: 580.5708 - val_loss: 0.3682 - val_mse: 1259.2664 - val_mae: 0.3682\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5835 - mse: 40080580608.0000 - mae: 580.5836 - val_loss: 0.3696 - val_mse: 1259.2706 - val_mae: 0.3696\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3778 - mse: 1097.8499 - mae: 0.3778 - val_loss: 0.3692 - val_mse: 1259.2616 - val_mae: 0.3692\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1225 - mse: 30060435456.0000 - mae: 387.1224 - val_loss: 0.3817 - val_mse: 1259.2667 - val_mae: 0.3817\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4132 - mse: 1141.0033 - mae: 0.4132 - val_loss: 0.3694 - val_mse: 1259.2655 - val_mae: 0.3694\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2936 - mse: 45090652160.0000 - mae: 677.2944 - val_loss: 0.3648 - val_mse: 1259.2709 - val_mae: 0.3648\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3696 - mse: 979.9139 - mae: 0.3696 - val_loss: 0.3670 - val_mse: 1259.2592 - val_mae: 0.3670\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8659 - mse: 20040290304.0000 - mae: 193.8659 - val_loss: 0.3758 - val_mse: 1259.2650 - val_mae: 0.3758\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3181 - mse: 909.2084 - mae: 0.3181 - val_loss: 0.3656 - val_mse: 1259.2715 - val_mae: 0.3656\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1689 - mse: 30060439552.0000 - mae: 387.1686 - val_loss: 0.3666 - val_mse: 1259.2593 - val_mae: 0.3666\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3564 - mse: 857.9573 - mae: 0.3564 - val_loss: 0.3673 - val_mse: 1259.2638 - val_mae: 0.3673\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3601 - mse: 876.8011 - mae: 0.3601 - val_loss: 0.3927 - val_mse: 1259.2783 - val_mae: 0.3927\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5537 - mse: 25050365952.0000 - mae: 290.5537 - val_loss: 0.3787 - val_mse: 1259.2668 - val_mae: 0.3787\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6113 - mse: 40080580608.0000 - mae: 580.6117 - val_loss: 0.3659 - val_mse: 1259.2585 - val_mae: 0.3659\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3102 - mse: 736.1192 - mae: 0.3102 - val_loss: 0.3712 - val_mse: 1259.2676 - val_mae: 0.3712\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4023 - mse: 1073.4343 - mae: 0.4023 - val_loss: 0.3733 - val_mse: 1259.2595 - val_mae: 0.3733\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5767 - mse: 40080580608.0000 - mae: 580.5770 - val_loss: 0.3678 - val_mse: 1259.2687 - val_mae: 0.3678\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5535 - mse: 40080580608.0000 - mae: 580.5536 - val_loss: 0.3643 - val_mse: 1259.2648 - val_mae: 0.3643\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4263 - mse: 1339.7826 - mae: 0.4263 - val_loss: 0.3642 - val_mse: 1259.2572 - val_mae: 0.3642\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3747 - mse: 1042.9866 - mae: 0.3747 - val_loss: 0.3732 - val_mse: 1259.2621 - val_mae: 0.3732\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1505 - mse: 30060435456.0000 - mae: 387.1505 - val_loss: 0.3632 - val_mse: 1259.2560 - val_mae: 0.3632\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2507 - mse: 30060435456.0000 - mae: 387.2507 - val_loss: 0.3762 - val_mse: 1259.2659 - val_mae: 0.3762\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3332 - mse: 789.6773 - mae: 0.3332 - val_loss: 0.3737 - val_mse: 1259.2653 - val_mae: 0.3737\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8060 - mse: 20040292352.0000 - mae: 193.8060 - val_loss: 0.3639 - val_mse: 1259.2661 - val_mae: 0.3639\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3727 - mse: 1052.5271 - mae: 0.3727 - val_loss: 0.3679 - val_mse: 1259.2719 - val_mae: 0.3679\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2940 - mse: 45090652160.0000 - mae: 677.2948 - val_loss: 0.3666 - val_mse: 1259.2667 - val_mae: 0.3666\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3227 - mse: 955.2869 - mae: 0.3227 - val_loss: 0.3681 - val_mse: 1259.2686 - val_mae: 0.3681\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4466 - mse: 1275.9363 - mae: 0.4466 - val_loss: 0.3662 - val_mse: 1259.2601 - val_mae: 0.3662\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5456 - mse: 40080584704.0000 - mae: 580.5458 - val_loss: 0.3628 - val_mse: 1259.2670 - val_mae: 0.3628\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2432 - mse: 30060435456.0000 - mae: 387.2433 - val_loss: 0.3720 - val_mse: 1259.2573 - val_mae: 0.3720\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3283 - mse: 799.7529 - mae: 0.3283 - val_loss: 0.3731 - val_mse: 1259.2666 - val_mae: 0.3731\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.5175 - mse: 1463.4817 - mae: 0.5175 - val_loss: 0.3735 - val_mse: 1259.2737 - val_mae: 0.3735\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0792 - mse: 30060439552.0000 - mae: 387.0792 - val_loss: 0.3639 - val_mse: 1259.2614 - val_mae: 0.3639\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3331 - mse: 45090652160.0000 - mae: 677.3334 - val_loss: 0.3734 - val_mse: 1259.2618 - val_mae: 0.3734\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3285 - mse: 934.1924 - mae: 0.3285 - val_loss: 0.3681 - val_mse: 1259.2664 - val_mae: 0.3681\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3845 - mse: 1066.9778 - mae: 0.3845 - val_loss: 0.3646 - val_mse: 1259.2660 - val_mae: 0.3646\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8722 - mse: 35070513152.0000 - mae: 483.8724 - val_loss: 0.3638 - val_mse: 1259.2712 - val_mae: 0.3638\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6163 - mse: 40080580608.0000 - mae: 580.6170 - val_loss: 0.3670 - val_mse: 1259.2618 - val_mae: 0.3670\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3542 - mse: 979.5607 - mae: 0.3542 - val_loss: 0.3628 - val_mse: 1259.2648 - val_mae: 0.3628\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4766 - mse: 25050365952.0000 - mae: 290.4766 - val_loss: 0.3656 - val_mse: 1259.2612 - val_mae: 0.3656\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3801 - mse: 1120.6042 - mae: 0.3801 - val_loss: 0.3657 - val_mse: 1259.2535 - val_mae: 0.3657\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3539 - mse: 853.7662 - mae: 0.3539 - val_loss: 0.3748 - val_mse: 1259.2653 - val_mae: 0.3748\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4428 - mse: 25050363904.0000 - mae: 290.4427 - val_loss: 0.3809 - val_mse: 1259.2700 - val_mae: 0.3809\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4348 - mse: 1309.6012 - mae: 0.4348 - val_loss: 0.3663 - val_mse: 1259.2649 - val_mae: 0.3663\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5811 - mse: 40080580608.0000 - mae: 580.5820 - val_loss: 0.3675 - val_mse: 1259.2648 - val_mae: 0.3675\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8226 - mse: 35070509056.0000 - mae: 483.8227 - val_loss: 0.3678 - val_mse: 1259.2510 - val_mae: 0.3678\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4257 - mse: 1302.9697 - mae: 0.4257 - val_loss: 0.3661 - val_mse: 1259.2721 - val_mae: 0.3661\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4139 - mse: 25050365952.0000 - mae: 290.4140 - val_loss: 0.3653 - val_mse: 1259.2651 - val_mae: 0.3653\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3970 - mse: 1092.6620 - mae: 0.3970 - val_loss: 0.3665 - val_mse: 1259.2623 - val_mae: 0.3665\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3588 - mse: 994.5153 - mae: 0.3588 - val_loss: 0.3678 - val_mse: 1259.2678 - val_mae: 0.3678\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5693 - mse: 40080580608.0000 - mae: 580.5699 - val_loss: 0.3726 - val_mse: 1259.2626 - val_mae: 0.3726\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4682 - mse: 25050365952.0000 - mae: 290.4681 - val_loss: 0.4062 - val_mse: 1259.2871 - val_mae: 0.4062\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3888 - mse: 1147.6821 - mae: 0.3888 - val_loss: 0.3721 - val_mse: 1259.2679 - val_mae: 0.3721\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4192 - mse: 1192.3267 - mae: 0.4192 - val_loss: 0.3648 - val_mse: 1259.2638 - val_mae: 0.3648\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4558 - mse: 25050363904.0000 - mae: 290.4557 - val_loss: 0.3670 - val_mse: 1259.2576 - val_mae: 0.3670\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1254 - mse: 30060435456.0000 - mae: 387.1254 - val_loss: 0.3671 - val_mse: 1259.2549 - val_mae: 0.3671\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4128 - mse: 1179.8695 - mae: 0.4128 - val_loss: 0.3686 - val_mse: 1259.2727 - val_mae: 0.3686\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2532 - mse: 573.1794 - mae: 0.2532 - val_loss: 0.3633 - val_mse: 1259.2653 - val_mae: 0.3633\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9897 - mse: 35070509056.0000 - mae: 483.9908 - val_loss: 0.3651 - val_mse: 1259.2542 - val_mae: 0.3651\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2986 - mse: 732.1633 - mae: 0.2986 - val_loss: 0.3669 - val_mse: 1259.2599 - val_mae: 0.3669\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5613 - mse: 25050363904.0000 - mae: 290.5614 - val_loss: 0.3627 - val_mse: 1259.2644 - val_mae: 0.3627\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2110 - mse: 30060439552.0000 - mae: 387.2110 - val_loss: 0.3678 - val_mse: 1259.2684 - val_mae: 0.3678\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3622 - mse: 953.4072 - mae: 0.3622 - val_loss: 0.3675 - val_mse: 1259.2629 - val_mae: 0.3675\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4005 - mse: 1249.9406 - mae: 0.4005 - val_loss: 0.3658 - val_mse: 1259.2664 - val_mae: 0.3658\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8130 - mse: 35070509056.0000 - mae: 483.8133 - val_loss: 0.3658 - val_mse: 1259.2644 - val_mae: 0.3658\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2796 - mse: 45090652160.0000 - mae: 677.2802 - val_loss: 0.3657 - val_mse: 1259.2642 - val_mae: 0.3657\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3874 - mse: 1126.3248 - mae: 0.3874 - val_loss: 0.3632 - val_mse: 1259.2614 - val_mae: 0.3632\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4315 - mse: 1189.3883 - mae: 0.4315 - val_loss: 0.3634 - val_mse: 1259.2653 - val_mae: 0.3634\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6977 - mse: 20040292352.0000 - mae: 193.6978 - val_loss: 0.3626 - val_mse: 1259.2544 - val_mae: 0.3626\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3301 - mse: 836.7752 - mae: 0.3301 - val_loss: 0.3625 - val_mse: 1259.2581 - val_mae: 0.3625\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3297 - mse: 45090652160.0000 - mae: 677.3299 - val_loss: 0.3688 - val_mse: 1259.2708 - val_mae: 0.3688\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1838 - mse: 30060435456.0000 - mae: 387.1838 - val_loss: 0.3797 - val_mse: 1259.2684 - val_mae: 0.3797\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3537 - mse: 940.1876 - mae: 0.3537 - val_loss: 0.3748 - val_mse: 1259.2625 - val_mae: 0.3748\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6595 - mse: 20040290304.0000 - mae: 193.6595 - val_loss: 0.3772 - val_mse: 1259.2650 - val_mae: 0.3772\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4533 - mse: 1317.6395 - mae: 0.4533 - val_loss: 0.3635 - val_mse: 1259.2594 - val_mae: 0.3635\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3272 - mse: 825.2331 - mae: 0.3272 - val_loss: 0.3711 - val_mse: 1259.2697 - val_mae: 0.3711\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6198 - mse: 40080580608.0000 - mae: 580.6207 - val_loss: 0.4010 - val_mse: 1259.2725 - val_mae: 0.4010\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8034 - mse: 35070509056.0000 - mae: 483.8038 - val_loss: 0.3637 - val_mse: 1259.2625 - val_mae: 0.3637\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4972 - mse: 1584.1200 - mae: 0.4972 - val_loss: 0.3640 - val_mse: 1259.2587 - val_mae: 0.3640\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 484.0928 - mse: 35070509056.0000 - mae: 484.0936 - val_loss: 0.3667 - val_mse: 1259.2662 - val_mae: 0.3667\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2524 - mse: 489.0741 - mae: 0.2524 - val_loss: 0.3687 - val_mse: 1259.2573 - val_mae: 0.3687\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 0.4402 - mse: 1060.1444 - mae: 0.4402 - val_loss: 0.3958 - val_mse: 1259.2775 - val_mae: 0.3958\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2703 - mse: 45090652160.0000 - mae: 677.2707 - val_loss: 0.3688 - val_mse: 1259.2726 - val_mae: 0.3688\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8616 - mse: 35070513152.0000 - mae: 483.8617 - val_loss: 0.3738 - val_mse: 1259.2798 - val_mae: 0.3738\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4181 - mse: 1163.2040 - mae: 0.4181 - val_loss: 0.3637 - val_mse: 1259.2664 - val_mae: 0.3637\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6318 - mse: 40080580608.0000 - mae: 580.6323 - val_loss: 0.3970 - val_mse: 1259.2808 - val_mae: 0.3970\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3278 - mse: 731.1075 - mae: 0.3278 - val_loss: 0.3699 - val_mse: 1259.2622 - val_mae: 0.3699\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3611 - mse: 943.1908 - mae: 0.3611 - val_loss: 0.3640 - val_mse: 1259.2634 - val_mae: 0.3640\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1834 - mse: 30060435456.0000 - mae: 387.1835 - val_loss: 0.3633 - val_mse: 1259.2626 - val_mae: 0.3633\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3644 - mse: 998.7383 - mae: 0.3644 - val_loss: 0.3858 - val_mse: 1407.5852 - val_mae: 0.3858\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1994 - mse: 30060439552.0000 - mae: 387.1996 - val_loss: 0.3626 - val_mse: 1259.2626 - val_mae: 0.3626\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1758 - mse: 30060439552.0000 - mae: 387.1758 - val_loss: 0.3703 - val_mse: 1259.2595 - val_mae: 0.3703\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4146 - mse: 1151.9922 - mae: 0.4146 - val_loss: 0.3680 - val_mse: 1259.2646 - val_mae: 0.3680\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3367 - mse: 880.5367 - mae: 0.3367 - val_loss: 0.3705 - val_mse: 1259.2657 - val_mae: 0.3705\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5171 - mse: 25050363904.0000 - mae: 290.5173 - val_loss: 0.3638 - val_mse: 1259.2576 - val_mae: 0.3638\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2749 - mse: 45090652160.0000 - mae: 677.2753 - val_loss: 0.3616 - val_mse: 1259.2670 - val_mae: 0.3616\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4125 - mse: 1171.5968 - mae: 0.4125 - val_loss: 0.3731 - val_mse: 1259.2603 - val_mae: 0.3731\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3943 - mse: 1121.9360 - mae: 0.3943 - val_loss: 0.3638 - val_mse: 1259.2540 - val_mae: 0.3638\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4373 - mse: 25050363904.0000 - mae: 290.4373 - val_loss: 0.3624 - val_mse: 1259.2592 - val_mae: 0.3624\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7547 - mse: 20040292352.0000 - mae: 193.7547 - val_loss: 0.3633 - val_mse: 1259.2673 - val_mae: 0.3633\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3930 - mse: 1185.5872 - mae: 0.3930 - val_loss: 0.3643 - val_mse: 1259.2638 - val_mae: 0.3643\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9644 - mse: 35070509056.0000 - mae: 483.9642 - val_loss: 0.3808 - val_mse: 1259.2625 - val_mae: 0.3808\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2734 - mse: 633.7914 - mae: 0.2734 - val_loss: 0.3699 - val_mse: 1259.2659 - val_mae: 0.3699\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7262 - mse: 20040292352.0000 - mae: 193.7262 - val_loss: 0.3662 - val_mse: 1259.2638 - val_mae: 0.3662\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3672 - mse: 1045.9574 - mae: 0.3672 - val_loss: 0.3647 - val_mse: 1259.2666 - val_mae: 0.3647\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2699 - mse: 492.3097 - mae: 0.2699 - val_loss: 0.3802 - val_mse: 1259.2750 - val_mae: 0.3802\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2665 - mse: 30060439552.0000 - mae: 387.2665 - val_loss: 0.3623 - val_mse: 1259.2570 - val_mae: 0.3623\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3600 - mse: 950.6841 - mae: 0.3600 - val_loss: 0.3630 - val_mse: 1259.2627 - val_mae: 0.3630\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8979 - mse: 35070509056.0000 - mae: 483.8979 - val_loss: 0.3845 - val_mse: 1259.2770 - val_mae: 0.3845\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2805 - mse: 45090652160.0000 - mae: 677.2805 - val_loss: 0.3629 - val_mse: 1259.2621 - val_mae: 0.3629\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3598 - mse: 1018.1379 - mae: 0.3598 - val_loss: 0.3695 - val_mse: 1259.2549 - val_mae: 0.3695\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4125 - mse: 1162.9838 - mae: 0.4125 - val_loss: 0.3747 - val_mse: 1259.2616 - val_mae: 0.3747\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1987 - mse: 30060439552.0000 - mae: 387.1986 - val_loss: 0.3780 - val_mse: 1259.2639 - val_mae: 0.3780\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2883 - mse: 572.6375 - mae: 0.2883 - val_loss: 0.3742 - val_mse: 1259.2625 - val_mae: 0.3742\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.6214 - mse: 25050365952.0000 - mae: 290.6214 - val_loss: 0.3631 - val_mse: 1259.2712 - val_mae: 0.3631\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3992 - mse: 1236.3751 - mae: 0.3992 - val_loss: 0.3617 - val_mse: 1259.2546 - val_mae: 0.3617\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1484 - mse: 30060439552.0000 - mae: 387.1483 - val_loss: 0.3658 - val_mse: 1259.2644 - val_mae: 0.3658\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5203 - mse: 40080580608.0000 - mae: 580.5214 - val_loss: 0.3625 - val_mse: 1259.2728 - val_mae: 0.3625\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4324 - mse: 1254.4667 - mae: 0.4324 - val_loss: 0.3663 - val_mse: 1259.2662 - val_mae: 0.3663\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3834 - mse: 1043.1237 - mae: 0.3834 - val_loss: 0.3693 - val_mse: 1259.2612 - val_mae: 0.3693\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1706 - mse: 30060439552.0000 - mae: 387.1704 - val_loss: 0.3622 - val_mse: 1259.2567 - val_mae: 0.3622\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1748 - mse: 30060439552.0000 - mae: 387.1748 - val_loss: 0.3719 - val_mse: 1259.2699 - val_mae: 0.3719\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4056 - mse: 1049.2705 - mae: 0.4056 - val_loss: 0.3734 - val_mse: 1259.2687 - val_mae: 0.3734\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5305 - mse: 25050365952.0000 - mae: 290.5305 - val_loss: 0.3683 - val_mse: 1259.2631 - val_mae: 0.3683\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3343 - mse: 820.9352 - mae: 0.3343 - val_loss: 0.3632 - val_mse: 1259.2655 - val_mae: 0.3632\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3004 - mse: 743.7047 - mae: 0.3004 - val_loss: 0.3637 - val_mse: 1259.2672 - val_mae: 0.3637\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8164 - mse: 20040292352.0000 - mae: 193.8164 - val_loss: 0.3670 - val_mse: 1259.2605 - val_mae: 0.3670\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5123 - mse: 25050365952.0000 - mae: 290.5125 - val_loss: 0.3626 - val_mse: 1259.2621 - val_mae: 0.3626\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3241 - mse: 781.5146 - mae: 0.3241 - val_loss: 0.3670 - val_mse: 1259.2609 - val_mae: 0.3670\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3744 - mse: 1087.3896 - mae: 0.3744 - val_loss: 0.3639 - val_mse: 1259.2581 - val_mae: 0.3639\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1644 - mse: 30060435456.0000 - mae: 387.1642 - val_loss: 0.3697 - val_mse: 1259.2596 - val_mae: 0.3697\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5366 - mse: 25050363904.0000 - mae: 290.5364 - val_loss: 0.3782 - val_mse: 1259.2762 - val_mae: 0.3782\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3588 - mse: 997.9138 - mae: 0.3588 - val_loss: 0.4052 - val_mse: 1259.2780 - val_mae: 0.4052\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3048 - mse: 723.5960 - mae: 0.3048 - val_loss: 0.3675 - val_mse: 1259.2778 - val_mae: 0.3675\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9273 - mse: 35070509056.0000 - mae: 483.9286 - val_loss: 0.3651 - val_mse: 1259.2629 - val_mae: 0.3651\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5685 - mse: 40080580608.0000 - mae: 580.5692 - val_loss: 0.3659 - val_mse: 1259.2640 - val_mae: 0.3659\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3400 - mse: 931.1631 - mae: 0.3400 - val_loss: 0.3618 - val_mse: 1259.2590 - val_mae: 0.3618\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3188 - mse: 890.3419 - mae: 0.3188 - val_loss: 0.3692 - val_mse: 1259.2595 - val_mae: 0.3692\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9519 - mse: 35070509056.0000 - mae: 483.9526 - val_loss: 0.3624 - val_mse: 1259.2601 - val_mae: 0.3624\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3807 - mse: 1129.5331 - mae: 0.3807 - val_loss: 0.3623 - val_mse: 1259.2643 - val_mae: 0.3623\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4128 - mse: 25050365952.0000 - mae: 290.4127 - val_loss: 0.3637 - val_mse: 1259.2649 - val_mae: 0.3637\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2790 - mse: 30060435456.0000 - mae: 387.2790 - val_loss: 0.3737 - val_mse: 1259.2653 - val_mae: 0.3737\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3564 - mse: 848.9446 - mae: 0.3564 - val_loss: 0.3719 - val_mse: 1259.2648 - val_mae: 0.3719\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4143 - mse: 1170.0544 - mae: 0.4143 - val_loss: 0.3781 - val_mse: 1259.2646 - val_mae: 0.3781\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1751 - mse: 30060439552.0000 - mae: 387.1752 - val_loss: 0.3750 - val_mse: 1259.2622 - val_mae: 0.3750\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6641 - mse: 20040292352.0000 - mae: 193.6640 - val_loss: 0.3667 - val_mse: 1259.2655 - val_mae: 0.3667\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4260 - mse: 1257.1864 - mae: 0.4260 - val_loss: 0.3665 - val_mse: 1259.2695 - val_mae: 0.3665\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7734 - mse: 20040292352.0000 - mae: 193.7734 - val_loss: 0.3645 - val_mse: 1259.2623 - val_mae: 0.3645\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3497 - mse: 1039.2479 - mae: 0.3497 - val_loss: 0.3645 - val_mse: 1259.2729 - val_mae: 0.3645\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6108 - mse: 40080584704.0000 - mae: 580.6114 - val_loss: 0.3621 - val_mse: 1259.2649 - val_mae: 0.3621\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3773 - mse: 1047.2506 - mae: 0.3773 - val_loss: 0.3615 - val_mse: 1259.2687 - val_mae: 0.3615\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4563 - mse: 1189.0420 - mae: 0.4563 - val_loss: 0.3684 - val_mse: 1259.2727 - val_mae: 0.3684\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5683 - mse: 40080580608.0000 - mae: 580.5697 - val_loss: 0.3675 - val_mse: 1259.2662 - val_mae: 0.3675\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4864 - mse: 1554.4332 - mae: 0.4864 - val_loss: 0.3709 - val_mse: 1259.2695 - val_mae: 0.3709\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4001 - mse: 25050363904.0000 - mae: 290.4000 - val_loss: 0.3650 - val_mse: 1259.2672 - val_mae: 0.3650\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9164 - mse: 35070509056.0000 - mae: 483.9166 - val_loss: 0.3631 - val_mse: 1259.2615 - val_mae: 0.3631\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3444 - mse: 958.5696 - mae: 0.3444 - val_loss: 0.3640 - val_mse: 1259.2675 - val_mae: 0.3640\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1441 - mse: 30060439552.0000 - mae: 387.1438 - val_loss: 0.3649 - val_mse: 1259.2673 - val_mae: 0.3649\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3779 - mse: 1100.0751 - mae: 0.3779 - val_loss: 0.3657 - val_mse: 1259.2633 - val_mae: 0.3657\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3666 - mse: 1027.6609 - mae: 0.3666 - val_loss: 0.3740 - val_mse: 1259.2637 - val_mae: 0.3740\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1891 - mse: 30060435456.0000 - mae: 387.1891 - val_loss: 0.3707 - val_mse: 1259.2639 - val_mae: 0.3707\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4294 - mse: 1227.5276 - mae: 0.4294 - val_loss: 0.3712 - val_mse: 1259.2729 - val_mae: 0.3712\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5857 - mse: 40080580608.0000 - mae: 580.5863 - val_loss: 0.3775 - val_mse: 1259.2704 - val_mae: 0.3775\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4047 - mse: 1275.7839 - mae: 0.4047 - val_loss: 0.3929 - val_mse: 1259.2737 - val_mae: 0.3929\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.1970 - mse: 45090652160.0000 - mae: 677.1981 - val_loss: 0.3666 - val_mse: 1259.2651 - val_mae: 0.3666\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3562 - mse: 1040.3906 - mae: 0.3562 - val_loss: 0.3683 - val_mse: 1259.2576 - val_mae: 0.3683\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8803 - mse: 35070509056.0000 - mae: 483.8807 - val_loss: 0.3632 - val_mse: 1259.2710 - val_mae: 0.3632\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2332 - mse: 30060435456.0000 - mae: 387.2333 - val_loss: 0.3716 - val_mse: 1259.2539 - val_mae: 0.3716\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3244 - mse: 819.9540 - mae: 0.3244 - val_loss: 0.3648 - val_mse: 1259.2532 - val_mae: 0.3648\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4375 - mse: 1350.0171 - mae: 0.4375 - val_loss: 0.3658 - val_mse: 1259.2618 - val_mae: 0.3658\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0624 - mse: 30060435456.0000 - mae: 387.0626 - val_loss: 0.3633 - val_mse: 1259.2704 - val_mae: 0.3633\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8696 - mse: 35070509056.0000 - mae: 483.8702 - val_loss: 0.3789 - val_mse: 1259.2706 - val_mae: 0.3789\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4458 - mse: 1213.1582 - mae: 0.4458 - val_loss: 0.3783 - val_mse: 1259.2430 - val_mae: 0.3783\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4018 - mse: 1085.6035 - mae: 0.4018 - val_loss: 0.3721 - val_mse: 1259.2642 - val_mae: 0.3721\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4545 - mse: 25050363904.0000 - mae: 290.4545 - val_loss: 0.3631 - val_mse: 1259.2639 - val_mae: 0.3631\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3960 - mse: 997.8433 - mae: 0.3960 - val_loss: 0.3630 - val_mse: 1259.2681 - val_mae: 0.3630\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5683 - mse: 40080580608.0000 - mae: 580.5698 - val_loss: 0.3658 - val_mse: 1259.2627 - val_mae: 0.3658\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3200 - mse: 694.9581 - mae: 0.3200 - val_loss: 0.3695 - val_mse: 1259.2670 - val_mae: 0.3695\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7965 - mse: 20040290304.0000 - mae: 193.7964 - val_loss: 0.3644 - val_mse: 1259.2533 - val_mae: 0.3644\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4693 - mse: 1618.1696 - mae: 0.4693 - val_loss: 0.3631 - val_mse: 1259.2701 - val_mae: 0.3631\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.3814 - mse: 25050365952.0000 - mae: 290.3813 - val_loss: 0.3637 - val_mse: 1259.2653 - val_mae: 0.3637\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3690 - mse: 966.5625 - mae: 0.3690 - val_loss: 0.3714 - val_mse: 1259.2676 - val_mae: 0.3714\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1566 - mse: 30060435456.0000 - mae: 387.1565 - val_loss: 0.3768 - val_mse: 1259.2552 - val_mae: 0.3768\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9100 - mse: 35070509056.0000 - mae: 483.9102 - val_loss: 0.3654 - val_mse: 1259.2701 - val_mae: 0.3654\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3100 - mse: 720.9775 - mae: 0.3100 - val_loss: 0.3672 - val_mse: 1259.2689 - val_mae: 0.3672\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3221 - mse: 842.4669 - mae: 0.3221 - val_loss: 0.3743 - val_mse: 1259.2703 - val_mae: 0.3743\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7949 - mse: 20040292352.0000 - mae: 193.7949 - val_loss: 0.3730 - val_mse: 1259.2687 - val_mae: 0.3730\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1645 - mse: 30060435456.0000 - mae: 387.1644 - val_loss: 0.3630 - val_mse: 1259.2607 - val_mae: 0.3630\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3418 - mse: 808.9476 - mae: 0.3418 - val_loss: 0.3642 - val_mse: 1259.2584 - val_mae: 0.3642\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7147 - mse: 20040290304.0000 - mae: 193.7146 - val_loss: 0.3625 - val_mse: 1259.2626 - val_mae: 0.3625\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4201 - mse: 1155.8822 - mae: 0.4201 - val_loss: 0.3732 - val_mse: 1259.2687 - val_mae: 0.3732\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3110 - mse: 629.3495 - mae: 0.3110 - val_loss: 0.3691 - val_mse: 1259.2751 - val_mae: 0.3691\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5858 - mse: 25050365952.0000 - mae: 290.5858 - val_loss: 0.3744 - val_mse: 1259.2628 - val_mae: 0.3744\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1905 - mse: 30060439552.0000 - mae: 387.1904 - val_loss: 0.3653 - val_mse: 1259.2664 - val_mae: 0.3653\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3741 - mse: 942.4739 - mae: 0.3741 - val_loss: 0.3656 - val_mse: 1259.2622 - val_mae: 0.3656\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9126 - mse: 35070509056.0000 - mae: 483.9137 - val_loss: 0.3666 - val_mse: 1259.2694 - val_mae: 0.3666\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3940 - mse: 1180.5294 - mae: 0.3940 - val_loss: 0.3655 - val_mse: 1259.2638 - val_mae: 0.3655\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3082 - mse: 795.0950 - mae: 0.3082 - val_loss: 0.3615 - val_mse: 1259.2571 - val_mae: 0.3615\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5155 - mse: 25050365952.0000 - mae: 290.5155 - val_loss: 0.3763 - val_mse: 1259.2620 - val_mae: 0.3763\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0716 - mse: 30060435456.0000 - mae: 387.0716 - val_loss: 0.3617 - val_mse: 1259.2579 - val_mae: 0.3617\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4704 - mse: 1446.4974 - mae: 0.4704 - val_loss: 0.3681 - val_mse: 1259.2672 - val_mae: 0.3681\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4952 - mse: 1474.7238 - mae: 0.4952 - val_loss: 0.3699 - val_mse: 1259.2759 - val_mae: 0.3699\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3649 - mse: 25050365952.0000 - mae: 290.3649 - val_loss: 0.3694 - val_mse: 1259.2627 - val_mae: 0.3694\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4786 - mse: 25050365952.0000 - mae: 290.4789 - val_loss: 0.3670 - val_mse: 1259.2605 - val_mae: 0.3670\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3494 - mse: 945.4328 - mae: 0.3494 - val_loss: 0.3670 - val_mse: 1259.2661 - val_mae: 0.3670\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2743 - mse: 643.7072 - mae: 0.2743 - val_loss: 0.3677 - val_mse: 1259.2697 - val_mae: 0.3677\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8277 - mse: 20040292352.0000 - mae: 193.8277 - val_loss: 0.3618 - val_mse: 1259.2719 - val_mae: 0.3618\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8288 - mse: 35070509056.0000 - mae: 483.8293 - val_loss: 0.3639 - val_mse: 1259.2589 - val_mae: 0.3639\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4630 - mse: 1375.1333 - mae: 0.4630 - val_loss: 0.3619 - val_mse: 1259.2659 - val_mae: 0.3619\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4137 - mse: 1324.1260 - mae: 0.4137 - val_loss: 0.3630 - val_mse: 1259.2620 - val_mae: 0.3630\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8476 - mse: 35070509056.0000 - mae: 483.8478 - val_loss: 0.3667 - val_mse: 1259.2618 - val_mae: 0.3667\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3814 - mse: 933.1403 - mae: 0.3814 - val_loss: 0.3825 - val_mse: 1259.2704 - val_mae: 0.3825\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4462 - mse: 25050363904.0000 - mae: 290.4461 - val_loss: 0.3813 - val_mse: 1259.2570 - val_mae: 0.3813\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9948 - mse: 50100727808.0000 - mae: 773.9949 - val_loss: 0.3798 - val_mse: 1259.2677 - val_mae: 0.3798\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3303 - mse: 888.5189 - mae: 0.3303 - val_loss: 0.3747 - val_mse: 1259.2721 - val_mae: 0.3747\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 483.8888 - mse: 35070513152.0000 - mae: 483.8898 - val_loss: 0.3944 - val_mse: 1259.2739 - val_mae: 0.3944\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3796 - mse: 984.5339 - mae: 0.3796 - val_loss: 0.3636 - val_mse: 1259.2670 - val_mae: 0.3636\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3507 - mse: 923.7029 - mae: 0.3507 - val_loss: 0.3769 - val_mse: 1259.2644 - val_mae: 0.3769\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5939 - mse: 40080580608.0000 - mae: 580.5946 - val_loss: 0.3627 - val_mse: 1259.2612 - val_mae: 0.3627\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3568 - mse: 45090652160.0000 - mae: 677.3579 - val_loss: 0.3682 - val_mse: 1259.2605 - val_mae: 0.3682\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2725 - mse: 510.6854 - mae: 0.2725 - val_loss: 0.3647 - val_mse: 1259.2695 - val_mae: 0.3647\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4704 - mse: 1137.4473 - mae: 0.4704 - val_loss: 0.3717 - val_mse: 1259.2808 - val_mae: 0.3717\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4286 - mse: 25050363904.0000 - mae: 290.4288 - val_loss: 0.3706 - val_mse: 1259.2738 - val_mae: 0.3706\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5373 - mse: 1696.2496 - mae: 0.5373 - val_loss: 0.3720 - val_mse: 1259.2610 - val_mae: 0.3720\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0521 - mse: 30060435456.0000 - mae: 387.0521 - val_loss: 0.3964 - val_mse: 1259.2665 - val_mae: 0.3964\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1080 - mse: 30060435456.0000 - mae: 387.1080 - val_loss: 0.3653 - val_mse: 1259.2659 - val_mae: 0.3653\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4406 - mse: 1296.0762 - mae: 0.4406 - val_loss: 0.3636 - val_mse: 1259.2682 - val_mae: 0.3636\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1893 - mse: 30060435456.0000 - mae: 387.1894 - val_loss: 0.3623 - val_mse: 1259.2642 - val_mae: 0.3623\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3165 - mse: 693.0146 - mae: 0.3165 - val_loss: 0.3652 - val_mse: 1259.2649 - val_mae: 0.3652\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2822 - mse: 559.5889 - mae: 0.2822 - val_loss: 0.3694 - val_mse: 1259.2621 - val_mae: 0.3694\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5894 - mse: 25050365952.0000 - mae: 290.5892 - val_loss: 0.3655 - val_mse: 1259.2570 - val_mae: 0.3655\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4785 - mse: 25050365952.0000 - mae: 290.4784 - val_loss: 0.3700 - val_mse: 1259.2670 - val_mae: 0.3700\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4225 - mse: 1246.8710 - mae: 0.4225 - val_loss: 0.3677 - val_mse: 1259.2687 - val_mae: 0.3677\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3696 - mse: 1043.2661 - mae: 0.3696 - val_loss: 0.3662 - val_mse: 1259.2594 - val_mae: 0.3662\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8918 - mse: 35070509056.0000 - mae: 483.8919 - val_loss: 0.3679 - val_mse: 1259.2634 - val_mae: 0.3679\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2967 - mse: 749.3703 - mae: 0.2967 - val_loss: 0.3635 - val_mse: 1259.2706 - val_mae: 0.3635\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6120 - mse: 40080580608.0000 - mae: 580.6132 - val_loss: 0.3749 - val_mse: 1259.2666 - val_mae: 0.3749\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4329 - mse: 1301.3083 - mae: 0.4329 - val_loss: 0.3650 - val_mse: 1259.2600 - val_mae: 0.3650\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2136 - mse: 45090652160.0000 - mae: 677.2139 - val_loss: 0.3630 - val_mse: 1259.2683 - val_mae: 0.3630\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6106 - mse: 40080580608.0000 - mae: 580.6107 - val_loss: 0.3617 - val_mse: 1259.2607 - val_mae: 0.3617\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3371 - mse: 881.6050 - mae: 0.3371 - val_loss: 0.3663 - val_mse: 1259.2668 - val_mae: 0.3663\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.6093 - mse: 25050363904.0000 - mae: 290.6093 - val_loss: 0.3783 - val_mse: 1259.2616 - val_mae: 0.3783\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2238 - mse: 412.9164 - mae: 0.2238 - val_loss: 0.3716 - val_mse: 1259.2653 - val_mae: 0.3716\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3610 - mse: 917.4578 - mae: 0.3610 - val_loss: 0.3773 - val_mse: 1259.2661 - val_mae: 0.3773\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4577 - mse: 25050363904.0000 - mae: 290.4577 - val_loss: 0.3678 - val_mse: 1259.2635 - val_mae: 0.3678\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7900 - mse: 20040294400.0000 - mae: 193.7900 - val_loss: 0.3677 - val_mse: 1259.2676 - val_mae: 0.3677\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3541 - mse: 941.6719 - mae: 0.3541 - val_loss: 0.3665 - val_mse: 1259.2609 - val_mae: 0.3665\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3188 - mse: 718.2042 - mae: 0.3188 - val_loss: 0.3644 - val_mse: 1259.2639 - val_mae: 0.3644\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6397 - mse: 40080580608.0000 - mae: 580.6411 - val_loss: 0.3649 - val_mse: 1259.2709 - val_mae: 0.3649\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.4731 - mse: 25050363904.0000 - mae: 290.4730 - val_loss: 0.3644 - val_mse: 1259.2622 - val_mae: 0.3644\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3310 - mse: 802.8877 - mae: 0.3310 - val_loss: 0.3642 - val_mse: 1259.2684 - val_mae: 0.3642\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4033 - mse: 25050365952.0000 - mae: 290.4032 - val_loss: 0.3722 - val_mse: 1259.2736 - val_mae: 0.3722\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5021 - mse: 1605.7125 - mae: 0.5021 - val_loss: 0.3754 - val_mse: 1259.2599 - val_mae: 0.3754\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4027 - mse: 1051.9752 - mae: 0.4027 - val_loss: 0.3697 - val_mse: 1259.2732 - val_mae: 0.3697\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1915 - mse: 30060435456.0000 - mae: 387.1917 - val_loss: 0.3634 - val_mse: 1259.2684 - val_mae: 0.3634\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2425 - mse: 520.6394 - mae: 0.2425 - val_loss: 0.3684 - val_mse: 1259.2712 - val_mae: 0.3684\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5925 - mse: 25050365952.0000 - mae: 290.5925 - val_loss: 0.3635 - val_mse: 1259.2703 - val_mae: 0.3635\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3688 - mse: 1054.9540 - mae: 0.3688 - val_loss: 0.3654 - val_mse: 1259.2755 - val_mae: 0.3654\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9238 - mse: 35070509056.0000 - mae: 483.9241 - val_loss: 0.3669 - val_mse: 1259.2507 - val_mae: 0.3669\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2698 - mse: 623.0576 - mae: 0.2698 - val_loss: 0.3631 - val_mse: 1259.2639 - val_mae: 0.3631\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2454 - mse: 30060435456.0000 - mae: 387.2453 - val_loss: 0.3636 - val_mse: 1259.2629 - val_mae: 0.3636\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2375 - mse: 30060435456.0000 - mae: 387.2375 - val_loss: 0.3715 - val_mse: 1259.2661 - val_mae: 0.3715\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3573 - mse: 1019.9395 - mae: 0.3573 - val_loss: 0.3664 - val_mse: 1259.2628 - val_mae: 0.3664\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1724 - mse: 30060435456.0000 - mae: 387.1724 - val_loss: 0.3752 - val_mse: 1259.2656 - val_mae: 0.3752\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3393 - mse: 997.4160 - mae: 0.3393 - val_loss: 0.3712 - val_mse: 1259.2646 - val_mae: 0.3712\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3166 - mse: 862.0239 - mae: 0.3166 - val_loss: 0.3687 - val_mse: 1259.2648 - val_mae: 0.3687\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2037 - mse: 30060435456.0000 - mae: 387.2037 - val_loss: 0.3679 - val_mse: 1259.2676 - val_mae: 0.3679\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3349 - mse: 930.1923 - mae: 0.3349 - val_loss: 0.3646 - val_mse: 1259.2607 - val_mae: 0.3646\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4851 - mse: 25050363904.0000 - mae: 290.4854 - val_loss: 0.3676 - val_mse: 1259.2612 - val_mae: 0.3676\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3197 - mse: 921.0538 - mae: 0.3197 - val_loss: 0.3628 - val_mse: 1259.2677 - val_mae: 0.3628\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2148 - mse: 30060439552.0000 - mae: 387.2148 - val_loss: 0.3674 - val_mse: 1259.2720 - val_mae: 0.3674\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3331 - mse: 761.6611 - mae: 0.3331 - val_loss: 0.3703 - val_mse: 1259.2683 - val_mae: 0.3703\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4904 - mse: 25050365952.0000 - mae: 290.4903 - val_loss: 0.3697 - val_mse: 1259.2661 - val_mae: 0.3697\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5435 - mse: 25050365952.0000 - mae: 290.5435 - val_loss: 0.3634 - val_mse: 1259.2605 - val_mae: 0.3634\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2645 - mse: 543.1639 - mae: 0.2645 - val_loss: 0.3717 - val_mse: 1259.2755 - val_mae: 0.3717\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2467 - mse: 392.2155 - mae: 0.2467 - val_loss: 0.3642 - val_mse: 1259.2612 - val_mae: 0.3642\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8302 - mse: 20040290304.0000 - mae: 193.8303 - val_loss: 0.3672 - val_mse: 1259.2612 - val_mae: 0.3672\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4759 - mse: 25050363904.0000 - mae: 290.4757 - val_loss: 0.3761 - val_mse: 1259.2706 - val_mae: 0.3761\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3828 - mse: 1001.1449 - mae: 0.3828 - val_loss: 0.3672 - val_mse: 1259.2637 - val_mae: 0.3672\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3492 - mse: 993.1572 - mae: 0.3492 - val_loss: 0.3649 - val_mse: 1259.2628 - val_mae: 0.3649\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4887 - mse: 25050365952.0000 - mae: 290.4887 - val_loss: 0.3654 - val_mse: 1259.2684 - val_mae: 0.3654\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7962 - mse: 20040290304.0000 - mae: 193.7963 - val_loss: 0.3768 - val_mse: 1259.2712 - val_mae: 0.3768\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3497 - mse: 988.9982 - mae: 0.3497 - val_loss: 0.3649 - val_mse: 1259.2643 - val_mae: 0.3649\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9488 - mse: 35070509056.0000 - mae: 483.9499 - val_loss: 0.3684 - val_mse: 1259.2646 - val_mae: 0.3684\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3061 - mse: 718.7637 - mae: 0.3061 - val_loss: 0.3718 - val_mse: 1259.2733 - val_mae: 0.3718\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4165 - mse: 1259.2590 - mae: 0.4165 - val_loss: 0.3686 - val_mse: 1259.2640 - val_mae: 0.3686\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8446 - mse: 35070509056.0000 - mae: 483.8459 - val_loss: 0.3660 - val_mse: 1259.2649 - val_mae: 0.3660\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2831 - mse: 30060435456.0000 - mae: 387.2830 - val_loss: 0.3677 - val_mse: 1259.2593 - val_mae: 0.3677\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2637 - mse: 606.2960 - mae: 0.2637 - val_loss: 0.3674 - val_mse: 1259.2719 - val_mae: 0.3674\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5617 - mse: 40080580608.0000 - mae: 580.5621 - val_loss: 0.3626 - val_mse: 1259.2665 - val_mae: 0.3626\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3590 - mse: 926.8409 - mae: 0.3590 - val_loss: 0.3649 - val_mse: 1259.2604 - val_mae: 0.3649\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4785 - mse: 1348.6702 - mae: 0.4785 - val_loss: 0.3716 - val_mse: 1259.2590 - val_mae: 0.3716\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4073 - mse: 25050363904.0000 - mae: 290.4073 - val_loss: 0.3775 - val_mse: 1259.2664 - val_mae: 0.3775\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1521 - mse: 30060435456.0000 - mae: 387.1522 - val_loss: 0.3666 - val_mse: 1259.2812 - val_mae: 0.3666\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4226 - mse: 1120.9202 - mae: 0.4226 - val_loss: 0.3751 - val_mse: 1259.2665 - val_mae: 0.3751\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5454 - mse: 25050363904.0000 - mae: 290.5454 - val_loss: 0.3657 - val_mse: 1259.2572 - val_mae: 0.3657\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3128 - mse: 702.8941 - mae: 0.3128 - val_loss: 0.3685 - val_mse: 1259.2704 - val_mae: 0.3685\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4001 - mse: 1121.4913 - mae: 0.4001 - val_loss: 0.3668 - val_mse: 1259.2577 - val_mae: 0.3668\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4122 - mse: 25050365952.0000 - mae: 290.4122 - val_loss: 0.3645 - val_mse: 1259.2712 - val_mae: 0.3645\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2223 - mse: 45090652160.0000 - mae: 677.2234 - val_loss: 0.3637 - val_mse: 1259.2606 - val_mae: 0.3637\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4159 - mse: 1265.6227 - mae: 0.4159 - val_loss: 0.3630 - val_mse: 1259.2627 - val_mae: 0.3630\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3213 - mse: 603.3959 - mae: 0.3213 - val_loss: 0.3678 - val_mse: 1259.2767 - val_mae: 0.3678\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5774 - mse: 25050365952.0000 - mae: 290.5773 - val_loss: 0.3780 - val_mse: 1259.2660 - val_mae: 0.3780\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5408 - mse: 25050365952.0000 - mae: 290.5408 - val_loss: 0.3682 - val_mse: 1259.2639 - val_mae: 0.3682\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3142 - mse: 764.9656 - mae: 0.3142 - val_loss: 0.3651 - val_mse: 1259.2581 - val_mae: 0.3651\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4779 - mse: 25050365952.0000 - mae: 290.4777 - val_loss: 0.3675 - val_mse: 1259.2725 - val_mae: 0.3675\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3430 - mse: 919.5030 - mae: 0.3430 - val_loss: 0.3622 - val_mse: 1259.2604 - val_mae: 0.3622\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3934 - mse: 1153.0635 - mae: 0.3934 - val_loss: 0.3678 - val_mse: 1259.2656 - val_mae: 0.3678\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7531 - mse: 20040292352.0000 - mae: 193.7530 - val_loss: 0.3660 - val_mse: 1259.2616 - val_mae: 0.3660\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7445 - mse: 20040290304.0000 - mae: 193.7446 - val_loss: 0.3617 - val_mse: 1259.2699 - val_mae: 0.3617\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3404 - mse: 982.5806 - mae: 0.3404 - val_loss: 0.3615 - val_mse: 1259.2665 - val_mae: 0.3615\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3905 - mse: 986.8709 - mae: 0.3905 - val_loss: 0.3746 - val_mse: 1259.2698 - val_mae: 0.3746\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8923 - mse: 35070509056.0000 - mae: 483.8928 - val_loss: 0.3700 - val_mse: 1259.2627 - val_mae: 0.3700\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3528 - mse: 874.5223 - mae: 0.3528 - val_loss: 0.3680 - val_mse: 1259.2618 - val_mae: 0.3680\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4962 - mse: 25050363904.0000 - mae: 290.4964 - val_loss: 0.3640 - val_mse: 1259.2640 - val_mae: 0.3640\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2753 - mse: 687.2631 - mae: 0.2753 - val_loss: 0.3701 - val_mse: 1259.2744 - val_mae: 0.3701\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9292 - mse: 35070509056.0000 - mae: 483.9294 - val_loss: 0.3631 - val_mse: 1259.2511 - val_mae: 0.3631\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6160 - mse: 40080580608.0000 - mae: 580.6166 - val_loss: 0.3634 - val_mse: 1259.2504 - val_mae: 0.3634\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3052 - mse: 852.2632 - mae: 0.3052 - val_loss: 0.3716 - val_mse: 1259.2682 - val_mae: 0.3716\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3838 - mse: 1082.6073 - mae: 0.3838 - val_loss: 0.3636 - val_mse: 1259.2512 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7387 - mse: 20040290304.0000 - mae: 193.7386 - val_loss: 0.3713 - val_mse: 1259.2496 - val_mae: 0.3713\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3496 - mse: 818.2049 - mae: 0.3496 - val_loss: 0.3754 - val_mse: 1259.2590 - val_mae: 0.3754\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4891 - mse: 25050365952.0000 - mae: 290.4892 - val_loss: 0.3883 - val_mse: 1259.2743 - val_mae: 0.3883\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3322 - mse: 828.8103 - mae: 0.3322 - val_loss: 0.3652 - val_mse: 1259.2559 - val_mae: 0.3652\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1392 - mse: 30060439552.0000 - mae: 387.1393 - val_loss: 0.3643 - val_mse: 1259.2638 - val_mae: 0.3643\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2653 - mse: 511.2315 - mae: 0.2653 - val_loss: 0.3670 - val_mse: 1259.2722 - val_mae: 0.3670\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9343 - mse: 35070509056.0000 - mae: 483.9345 - val_loss: 0.3690 - val_mse: 1259.2561 - val_mae: 0.3690\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3584 - mse: 893.8614 - mae: 0.3584 - val_loss: 0.3627 - val_mse: 1259.2604 - val_mae: 0.3627\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9050 - mse: 35070509056.0000 - mae: 483.9050 - val_loss: 0.3646 - val_mse: 1259.2687 - val_mae: 0.3646\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2608 - mse: 476.0438 - mae: 0.2608 - val_loss: 0.3771 - val_mse: 1259.2709 - val_mae: 0.3771\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2610 - mse: 30060439552.0000 - mae: 387.2611 - val_loss: 0.3654 - val_mse: 1259.2614 - val_mae: 0.3654\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3719 - mse: 791.8416 - mae: 0.3719 - val_loss: 0.3727 - val_mse: 1259.2743 - val_mae: 0.3727\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3052 - mse: 45090652160.0000 - mae: 677.3053 - val_loss: 0.3687 - val_mse: 1259.2719 - val_mae: 0.3687\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3842 - mse: 947.2677 - mae: 0.3842 - val_loss: 0.3649 - val_mse: 1259.2672 - val_mae: 0.3649\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7820 - mse: 20040290304.0000 - mae: 193.7821 - val_loss: 0.3695 - val_mse: 1259.2628 - val_mae: 0.3695\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0497 - mse: 50100727808.0000 - mae: 774.0505 - val_loss: 0.3644 - val_mse: 1259.2633 - val_mae: 0.3644\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3565 - mse: 898.8091 - mae: 0.3565 - val_loss: 0.3646 - val_mse: 1259.2607 - val_mae: 0.3646\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4106 - mse: 25050363904.0000 - mae: 290.4106 - val_loss: 0.3639 - val_mse: 1259.2605 - val_mae: 0.3639\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4072 - mse: 1218.5869 - mae: 0.4072 - val_loss: 0.3644 - val_mse: 1259.2661 - val_mae: 0.3644\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3551 - mse: 943.8132 - mae: 0.3551 - val_loss: 0.3721 - val_mse: 1259.2595 - val_mae: 0.3721\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4642 - mse: 25050365952.0000 - mae: 290.4642 - val_loss: 0.3636 - val_mse: 1259.2532 - val_mae: 0.3636\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9316 - mse: 35070509056.0000 - mae: 483.9319 - val_loss: 0.3974 - val_mse: 1259.2650 - val_mae: 0.3974\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3194 - mse: 879.4756 - mae: 0.3194 - val_loss: 0.3653 - val_mse: 1259.2653 - val_mae: 0.3653\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5244 - mse: 25050363904.0000 - mae: 290.5241 - val_loss: 0.3649 - val_mse: 1259.2651 - val_mae: 0.3649\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3273 - mse: 803.5458 - mae: 0.3273 - val_loss: 0.3665 - val_mse: 1259.2622 - val_mae: 0.3665\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1483 - mse: 30060439552.0000 - mae: 387.1483 - val_loss: 0.3663 - val_mse: 1259.2593 - val_mae: 0.3663\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3718 - mse: 992.2097 - mae: 0.3718 - val_loss: 0.3635 - val_mse: 1259.2653 - val_mae: 0.3635\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3911 - mse: 1077.6526 - mae: 0.3911 - val_loss: 0.3648 - val_mse: 1259.2670 - val_mae: 0.3648\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1949 - mse: 30060435456.0000 - mae: 387.1950 - val_loss: 0.3630 - val_mse: 1259.2625 - val_mae: 0.3630\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3442 - mse: 930.1105 - mae: 0.3442 - val_loss: 0.3625 - val_mse: 1259.2592 - val_mae: 0.3625\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5868 - mse: 40080584704.0000 - mae: 580.5878 - val_loss: 0.3631 - val_mse: 1259.2625 - val_mae: 0.3631\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3687 - mse: 895.4592 - mae: 0.3687 - val_loss: 0.3682 - val_mse: 1259.2714 - val_mae: 0.3682\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2101 - mse: 30060435456.0000 - mae: 387.2101 - val_loss: 0.3663 - val_mse: 1259.2667 - val_mae: 0.3663\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3786 - mse: 1088.9540 - mae: 0.3786 - val_loss: 0.3661 - val_mse: 1259.2665 - val_mae: 0.3661\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1947 - mse: 30060435456.0000 - mae: 387.1948 - val_loss: 0.3641 - val_mse: 1259.2593 - val_mae: 0.3641\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2372 - mse: 30060435456.0000 - mae: 387.2373 - val_loss: 0.3680 - val_mse: 1259.2656 - val_mae: 0.3680\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3675 - mse: 992.7946 - mae: 0.3675 - val_loss: 0.3677 - val_mse: 1259.2643 - val_mae: 0.3677\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2834 - mse: 479.3035 - mae: 0.2834 - val_loss: 0.3652 - val_mse: 1259.2639 - val_mae: 0.3652\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.9319 - mse: 20040294400.0000 - mae: 193.9320 - val_loss: 0.3643 - val_mse: 1259.2642 - val_mae: 0.3643\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2577 - mse: 45090652160.0000 - mae: 677.2578 - val_loss: 0.3747 - val_mse: 1259.2659 - val_mae: 0.3747\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3455 - mse: 985.5402 - mae: 0.3455 - val_loss: 0.3636 - val_mse: 1259.2644 - val_mae: 0.3636\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3452 - mse: 880.3874 - mae: 0.3452 - val_loss: 0.3757 - val_mse: 1259.2706 - val_mae: 0.3757\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5156 - mse: 25050365952.0000 - mae: 290.5154 - val_loss: 0.3676 - val_mse: 1259.2633 - val_mae: 0.3676\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4095 - mse: 1187.5514 - mae: 0.4095 - val_loss: 0.3701 - val_mse: 1259.2570 - val_mae: 0.3701\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5204 - mse: 40080580608.0000 - mae: 580.5219 - val_loss: 0.3792 - val_mse: 1259.2616 - val_mae: 0.3792\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8672 - mse: 35070509056.0000 - mae: 483.8678 - val_loss: 0.3685 - val_mse: 1259.2708 - val_mae: 0.3685\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4086 - mse: 1150.8259 - mae: 0.4086 - val_loss: 0.3694 - val_mse: 1259.2625 - val_mae: 0.3694\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2967 - mse: 712.2526 - mae: 0.2967 - val_loss: 0.3701 - val_mse: 1259.2677 - val_mae: 0.3701\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6017 - mse: 40080580608.0000 - mae: 580.6030 - val_loss: 0.3653 - val_mse: 1259.2672 - val_mae: 0.3653\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5541 - mse: 40080580608.0000 - mae: 580.5549 - val_loss: 0.3635 - val_mse: 1259.2538 - val_mae: 0.3635\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3869 - mse: 1156.3883 - mae: 0.3869 - val_loss: 0.3650 - val_mse: 1259.2705 - val_mae: 0.3650\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3954 - mse: 1032.4644 - mae: 0.3954 - val_loss: 0.3852 - val_mse: 1259.2653 - val_mae: 0.3852\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7119 - mse: 20040290304.0000 - mae: 193.7119 - val_loss: 0.3650 - val_mse: 1259.2704 - val_mae: 0.3650\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3938 - mse: 1154.9764 - mae: 0.3938 - val_loss: 0.3655 - val_mse: 1259.2640 - val_mae: 0.3655\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1338 - mse: 30060435456.0000 - mae: 387.1339 - val_loss: 0.3769 - val_mse: 1259.2650 - val_mae: 0.3769\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1472 - mse: 30060435456.0000 - mae: 387.1472 - val_loss: 0.3725 - val_mse: 1259.2753 - val_mae: 0.3725\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3584 - mse: 983.2467 - mae: 0.3584 - val_loss: 0.3736 - val_mse: 1259.2758 - val_mae: 0.3736\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1718 - mse: 30060439552.0000 - mae: 387.1719 - val_loss: 0.3639 - val_mse: 1259.2677 - val_mae: 0.3639\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3428 - mse: 1003.9172 - mae: 0.3428 - val_loss: 0.3693 - val_mse: 1259.2622 - val_mae: 0.3693\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4379 - mse: 25050365952.0000 - mae: 290.4379 - val_loss: 0.3778 - val_mse: 1259.2610 - val_mae: 0.3778\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4054 - mse: 1119.4929 - mae: 0.4054 - val_loss: 0.3655 - val_mse: 1259.2640 - val_mae: 0.3655\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 483.9855 - mse: 35070509056.0000 - mae: 483.9856 - val_loss: 0.3757 - val_mse: 1259.2610 - val_mae: 0.3757\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3196 - mse: 795.0211 - mae: 0.3196 - val_loss: 0.3742 - val_mse: 1259.2736 - val_mae: 0.3742\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1750 - mse: 30060435456.0000 - mae: 387.1750 - val_loss: 0.3921 - val_mse: 1259.2570 - val_mae: 0.3921\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3130 - mse: 842.2842 - mae: 0.3130 - val_loss: 0.3695 - val_mse: 1259.2589 - val_mae: 0.3695\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3460 - mse: 905.4606 - mae: 0.3460 - val_loss: 0.3648 - val_mse: 1259.2621 - val_mae: 0.3648\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8618 - mse: 35070513152.0000 - mae: 483.8624 - val_loss: 0.3632 - val_mse: 1259.2672 - val_mae: 0.3632\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4185 - mse: 1212.6079 - mae: 0.4185 - val_loss: 0.3644 - val_mse: 1259.2653 - val_mae: 0.3644\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3973 - mse: 25050363904.0000 - mae: 290.3972 - val_loss: 0.3695 - val_mse: 1259.2583 - val_mae: 0.3695\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4012 - mse: 1087.7399 - mae: 0.4012 - val_loss: 0.3631 - val_mse: 1259.2607 - val_mae: 0.3631\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7597 - mse: 20040292352.0000 - mae: 193.7596 - val_loss: 0.3628 - val_mse: 1259.2627 - val_mae: 0.3628\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9064 - mse: 35070509056.0000 - mae: 483.9060 - val_loss: 0.3847 - val_mse: 1259.2734 - val_mae: 0.3847\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4092 - mse: 1194.7781 - mae: 0.4092 - val_loss: 0.3693 - val_mse: 1259.2721 - val_mae: 0.3693\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8130 - mse: 35070509056.0000 - mae: 483.8130 - val_loss: 0.3804 - val_mse: 1259.2756 - val_mae: 0.3804\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4028 - mse: 1183.4104 - mae: 0.4028 - val_loss: 0.3666 - val_mse: 1259.2708 - val_mae: 0.3666\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3112 - mse: 831.1871 - mae: 0.3112 - val_loss: 0.3643 - val_mse: 1259.2573 - val_mae: 0.3643\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1977 - mse: 30060439552.0000 - mae: 387.1977 - val_loss: 0.3731 - val_mse: 1259.2655 - val_mae: 0.3731\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3998 - mse: 1197.7563 - mae: 0.3998 - val_loss: 0.3639 - val_mse: 1259.2699 - val_mae: 0.3639\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1327 - mse: 30060435456.0000 - mae: 387.1328 - val_loss: 0.3634 - val_mse: 1259.2611 - val_mae: 0.3634\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2851 - mse: 45090652160.0000 - mae: 677.2854 - val_loss: 0.3640 - val_mse: 1259.2670 - val_mae: 0.3640\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3483 - mse: 883.3922 - mae: 0.3483 - val_loss: 0.3679 - val_mse: 1259.2599 - val_mae: 0.3679\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4445 - mse: 1325.7084 - mae: 0.4445 - val_loss: 0.3708 - val_mse: 1259.2688 - val_mae: 0.3708\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4257 - mse: 25050363904.0000 - mae: 290.4254 - val_loss: 0.3692 - val_mse: 1259.2655 - val_mae: 0.3692\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4528 - mse: 1367.2535 - mae: 0.4528 - val_loss: 0.3695 - val_mse: 1259.2761 - val_mae: 0.3695\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8198 - mse: 35070509056.0000 - mae: 483.8203 - val_loss: 0.3785 - val_mse: 1259.2742 - val_mae: 0.3785\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3789 - mse: 1089.9952 - mae: 0.3789 - val_loss: 0.3628 - val_mse: 1259.2665 - val_mae: 0.3628\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8845 - mse: 35070509056.0000 - mae: 483.8851 - val_loss: 0.3615 - val_mse: 1259.2676 - val_mae: 0.3615\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1032 - mse: 30060435456.0000 - mae: 387.1032 - val_loss: 0.3686 - val_mse: 1259.2638 - val_mae: 0.3686\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4236 - mse: 1273.0426 - mae: 0.4236 - val_loss: 0.3620 - val_mse: 1259.2543 - val_mae: 0.3620\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3774 - mse: 25050365952.0000 - mae: 290.3773 - val_loss: 0.3622 - val_mse: 1259.2659 - val_mae: 0.3622\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5151 - mse: 1671.9171 - mae: 0.5151 - val_loss: 0.3647 - val_mse: 1259.2684 - val_mae: 0.3647\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5239 - mse: 25050365952.0000 - mae: 290.5240 - val_loss: 0.3695 - val_mse: 1259.2710 - val_mae: 0.3695\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2787 - mse: 623.1164 - mae: 0.2787 - val_loss: 0.3661 - val_mse: 1259.2576 - val_mae: 0.3661\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2913 - mse: 550.8031 - mae: 0.2913 - val_loss: 0.3686 - val_mse: 1259.2607 - val_mae: 0.3686\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2135 - mse: 30060435456.0000 - mae: 387.2134 - val_loss: 0.3678 - val_mse: 1259.2665 - val_mae: 0.3678\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7876 - mse: 20040292352.0000 - mae: 193.7876 - val_loss: 0.3808 - val_mse: 1259.2750 - val_mae: 0.3808\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2838 - mse: 685.4022 - mae: 0.2838 - val_loss: 0.3643 - val_mse: 1259.2721 - val_mae: 0.3643\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3864 - mse: 1032.8988 - mae: 0.3864 - val_loss: 0.3631 - val_mse: 1259.2618 - val_mae: 0.3631\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7646 - mse: 20040292352.0000 - mae: 193.7647 - val_loss: 0.3624 - val_mse: 1259.2726 - val_mae: 0.3624\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5674 - mse: 40080580608.0000 - mae: 580.5682 - val_loss: 0.3743 - val_mse: 1259.2554 - val_mae: 0.3743\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3820 - mse: 1122.1202 - mae: 0.3820 - val_loss: 0.3627 - val_mse: 1259.2639 - val_mae: 0.3627\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3799 - mse: 1025.2726 - mae: 0.3799 - val_loss: 0.3701 - val_mse: 1259.2690 - val_mae: 0.3701\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4787 - mse: 25050365952.0000 - mae: 290.4791 - val_loss: 0.3755 - val_mse: 1259.2660 - val_mae: 0.3755\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4148 - mse: 1170.7430 - mae: 0.4148 - val_loss: 0.3656 - val_mse: 1259.2604 - val_mae: 0.3656\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8597 - mse: 35070509056.0000 - mae: 483.8598 - val_loss: 0.3653 - val_mse: 1259.2710 - val_mae: 0.3653\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7714 - mse: 20040292352.0000 - mae: 193.7713 - val_loss: 0.3713 - val_mse: 1259.2670 - val_mae: 0.3713\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3681 - mse: 1012.2836 - mae: 0.3681 - val_loss: 0.3650 - val_mse: 1259.2616 - val_mae: 0.3650\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3361 - mse: 773.0782 - mae: 0.3361 - val_loss: 0.3730 - val_mse: 1259.2574 - val_mae: 0.3730\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1748 - mse: 30060435456.0000 - mae: 387.1746 - val_loss: 0.3670 - val_mse: 1259.2656 - val_mae: 0.3670\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3462 - mse: 849.2772 - mae: 0.3462 - val_loss: 0.3763 - val_mse: 1283.5243 - val_mae: 0.3763\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6693 - mse: 40080584704.0000 - mae: 580.6700 - val_loss: 0.3667 - val_mse: 1259.2627 - val_mae: 0.3667\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 484.0127 - mse: 35070509056.0000 - mae: 484.0125 - val_loss: 0.3806 - val_mse: 1259.2708 - val_mae: 0.3806\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2735 - mse: 663.1887 - mae: 0.2735 - val_loss: 0.3734 - val_mse: 1259.2542 - val_mae: 0.3734\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3296 - mse: 45090652160.0000 - mae: 677.3302 - val_loss: 0.3649 - val_mse: 1259.2639 - val_mae: 0.3649\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3019 - mse: 648.4420 - mae: 0.3019 - val_loss: 0.3654 - val_mse: 1259.2637 - val_mae: 0.3654\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3632 - mse: 862.6718 - mae: 0.3632 - val_loss: 0.3670 - val_mse: 1259.2699 - val_mae: 0.3670\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6430 - mse: 40080580608.0000 - mae: 580.6440 - val_loss: 0.3711 - val_mse: 1259.2629 - val_mae: 0.3711\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4838 - mse: 25050365952.0000 - mae: 290.4839 - val_loss: 0.3651 - val_mse: 1259.2690 - val_mae: 0.3651\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3306 - mse: 717.8493 - mae: 0.3306 - val_loss: 0.3705 - val_mse: 1259.2614 - val_mae: 0.3705\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3293 - mse: 856.4324 - mae: 0.3293 - val_loss: 0.3732 - val_mse: 1259.2704 - val_mae: 0.3732\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9129 - mse: 35070509056.0000 - mae: 483.9137 - val_loss: 0.3627 - val_mse: 1259.2687 - val_mae: 0.3627\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5820 - mse: 40080580608.0000 - mae: 580.5820 - val_loss: 0.3710 - val_mse: 1259.2673 - val_mae: 0.3710\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4387 - mse: 1254.2981 - mae: 0.4387 - val_loss: 0.3653 - val_mse: 1259.2627 - val_mae: 0.3653\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9015 - mse: 35070509056.0000 - mae: 483.9030 - val_loss: 0.3889 - val_mse: 1259.2616 - val_mae: 0.3889\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3318 - mse: 813.9368 - mae: 0.3318 - val_loss: 0.3655 - val_mse: 1259.2584 - val_mae: 0.3655\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3943 - mse: 1109.7579 - mae: 0.3943 - val_loss: 0.3680 - val_mse: 1259.2659 - val_mae: 0.3680\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8918 - mse: 35070513152.0000 - mae: 483.8925 - val_loss: 0.3644 - val_mse: 1259.2643 - val_mae: 0.3644\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3494 - mse: 894.6437 - mae: 0.3494 - val_loss: 0.3638 - val_mse: 1259.2633 - val_mae: 0.3638\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8546 - mse: 35070509056.0000 - mae: 483.8550 - val_loss: 0.3629 - val_mse: 1259.2635 - val_mae: 0.3629\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8120 - mse: 20040292352.0000 - mae: 193.8121 - val_loss: 0.3691 - val_mse: 1259.2622 - val_mae: 0.3691\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2842 - mse: 669.4523 - mae: 0.2842 - val_loss: 0.3642 - val_mse: 1259.2686 - val_mae: 0.3642\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3492 - mse: 937.0436 - mae: 0.3492 - val_loss: 0.3710 - val_mse: 1259.2770 - val_mae: 0.3710\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8632 - mse: 35070509056.0000 - mae: 483.8632 - val_loss: 0.3668 - val_mse: 1259.2599 - val_mae: 0.3668\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2894 - mse: 532.8950 - mae: 0.2894 - val_loss: 0.3724 - val_mse: 1259.2616 - val_mae: 0.3724\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2978 - mse: 30060439552.0000 - mae: 387.2978 - val_loss: 0.3665 - val_mse: 1259.2681 - val_mae: 0.3665\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5072 - mse: 1692.8033 - mae: 0.5072 - val_loss: 0.3634 - val_mse: 1259.2665 - val_mae: 0.3634\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3444 - mse: 25050363904.0000 - mae: 290.3443 - val_loss: 0.3622 - val_mse: 1259.2622 - val_mae: 0.3622\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3508 - mse: 925.8093 - mae: 0.3508 - val_loss: 0.3714 - val_mse: 1259.2560 - val_mae: 0.3714\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1206 - mse: 30060435456.0000 - mae: 387.1205 - val_loss: 0.3662 - val_mse: 1259.2650 - val_mae: 0.3662\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2786 - mse: 715.7602 - mae: 0.2786 - val_loss: 0.3726 - val_mse: 1259.2661 - val_mae: 0.3726\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5129 - mse: 25050365952.0000 - mae: 290.5130 - val_loss: 0.3641 - val_mse: 1259.2632 - val_mae: 0.3641\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4195 - mse: 1064.9102 - mae: 0.4195 - val_loss: 0.3706 - val_mse: 1259.2775 - val_mae: 0.3706\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1900 - mse: 30060435456.0000 - mae: 387.1899 - val_loss: 0.3681 - val_mse: 1259.2550 - val_mae: 0.3681\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2119 - mse: 30060435456.0000 - mae: 387.2117 - val_loss: 0.3672 - val_mse: 1259.2833 - val_mae: 0.3672\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3769 - mse: 940.5768 - mae: 0.3769 - val_loss: 0.3627 - val_mse: 1259.2616 - val_mae: 0.3627\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4511 - mse: 25050365952.0000 - mae: 290.4510 - val_loss: 0.3636 - val_mse: 1259.2662 - val_mae: 0.3636\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3970 - mse: 1108.5208 - mae: 0.3970 - val_loss: 0.3639 - val_mse: 1259.2629 - val_mae: 0.3639\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1405 - mse: 30060435456.0000 - mae: 387.1405 - val_loss: 0.3624 - val_mse: 1259.2576 - val_mae: 0.3624\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3472 - mse: 887.1710 - mae: 0.3472 - val_loss: 0.3620 - val_mse: 1259.2551 - val_mae: 0.3620\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3830 - mse: 1121.1840 - mae: 0.3830 - val_loss: 0.3623 - val_mse: 1259.2665 - val_mae: 0.3623\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1629 - mse: 30060435456.0000 - mae: 387.1632 - val_loss: 0.3642 - val_mse: 1259.2572 - val_mae: 0.3642\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.3050 - mse: 30060435456.0000 - mae: 387.3050 - val_loss: 0.3675 - val_mse: 1259.2727 - val_mae: 0.3675\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2465 - mse: 492.2547 - mae: 0.2465 - val_loss: 0.3661 - val_mse: 1259.2646 - val_mae: 0.3661\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4071 - mse: 1193.6776 - mae: 0.4071 - val_loss: 0.3649 - val_mse: 1259.2612 - val_mae: 0.3649\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1039 - mse: 30060439552.0000 - mae: 387.1038 - val_loss: 0.3763 - val_mse: 1259.2628 - val_mae: 0.3763\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4646 - mse: 25050365952.0000 - mae: 290.4642 - val_loss: 0.3702 - val_mse: 1259.2603 - val_mae: 0.3702\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3763 - mse: 1043.2332 - mae: 0.3763 - val_loss: 0.3649 - val_mse: 1259.2637 - val_mae: 0.3649\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.6156 - mse: 25050365952.0000 - mae: 290.6158 - val_loss: 0.3645 - val_mse: 1259.2645 - val_mae: 0.3645\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2600 - mse: 538.8717 - mae: 0.2600 - val_loss: 0.3630 - val_mse: 1259.2649 - val_mae: 0.3630\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8429 - mse: 35070509056.0000 - mae: 483.8429 - val_loss: 0.3636 - val_mse: 1259.2646 - val_mae: 0.3636\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3623 - mse: 1031.5957 - mae: 0.3623 - val_loss: 0.3614 - val_mse: 1259.2792 - val_mae: 0.3614\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5940 - mse: 40080580608.0000 - mae: 580.5946 - val_loss: 0.3690 - val_mse: 1259.2686 - val_mae: 0.3690\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3647 - mse: 948.0884 - mae: 0.3647 - val_loss: 0.3661 - val_mse: 1259.2627 - val_mae: 0.3661\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5311 - mse: 25050365952.0000 - mae: 290.5311 - val_loss: 0.3708 - val_mse: 1259.2719 - val_mae: 0.3708\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3443 - mse: 859.0976 - mae: 0.3443 - val_loss: 0.3630 - val_mse: 1259.2699 - val_mae: 0.3630\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2185 - mse: 30060435456.0000 - mae: 387.2184 - val_loss: 0.3661 - val_mse: 1259.2684 - val_mae: 0.3661\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2953 - mse: 747.0596 - mae: 0.2953 - val_loss: 0.3650 - val_mse: 1259.2736 - val_mae: 0.3650\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4197 - mse: 1333.5774 - mae: 0.4197 - val_loss: 0.3656 - val_mse: 1259.2676 - val_mae: 0.3656\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4000 - mse: 25050363904.0000 - mae: 290.4001 - val_loss: 0.3620 - val_mse: 1259.2635 - val_mae: 0.3620\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3479 - mse: 956.8352 - mae: 0.3479 - val_loss: 0.3643 - val_mse: 1259.2570 - val_mae: 0.3643\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7329 - mse: 20040292352.0000 - mae: 193.7329 - val_loss: 0.3635 - val_mse: 1259.2640 - val_mae: 0.3635\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.2766 - mse: 30060439552.0000 - mae: 387.2766 - val_loss: 0.3715 - val_mse: 1259.2749 - val_mae: 0.3715\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3876 - mse: 950.0682 - mae: 0.3876 - val_loss: 0.3662 - val_mse: 1259.2578 - val_mae: 0.3662\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4965 - mse: 25050365952.0000 - mae: 290.4964 - val_loss: 0.3688 - val_mse: 1259.2629 - val_mae: 0.3688\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3360 - mse: 879.9997 - mae: 0.3360 - val_loss: 0.3777 - val_mse: 1259.2672 - val_mae: 0.3777\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2077 - mse: 30060439552.0000 - mae: 387.2075 - val_loss: 0.3649 - val_mse: 1259.2640 - val_mae: 0.3649\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3913 - mse: 1113.3383 - mae: 0.3913 - val_loss: 0.3679 - val_mse: 1259.2661 - val_mae: 0.3679\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1529 - mse: 30060435456.0000 - mae: 387.1530 - val_loss: 0.3641 - val_mse: 1259.2587 - val_mae: 0.3641\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3512 - mse: 947.0435 - mae: 0.3512 - val_loss: 0.3625 - val_mse: 1259.2551 - val_mae: 0.3625\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1327 - mse: 30060435456.0000 - mae: 387.1328 - val_loss: 0.3708 - val_mse: 1259.2646 - val_mae: 0.3708\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4080 - mse: 1088.5946 - mae: 0.4080 - val_loss: 0.3639 - val_mse: 1259.2633 - val_mae: 0.3639\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4122 - mse: 25050363904.0000 - mae: 290.4124 - val_loss: 0.3769 - val_mse: 1259.2692 - val_mae: 0.3769\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3809 - mse: 1037.9552 - mae: 0.3809 - val_loss: 0.3769 - val_mse: 1259.2677 - val_mae: 0.3769\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3034 - mse: 831.5937 - mae: 0.3034 - val_loss: 0.3717 - val_mse: 1259.2610 - val_mae: 0.3717\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8955 - mse: 35070517248.0000 - mae: 483.8954 - val_loss: 0.3633 - val_mse: 1259.2638 - val_mae: 0.3633\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1145 - mse: 30060435456.0000 - mae: 387.1144 - val_loss: 0.3637 - val_mse: 1259.2688 - val_mae: 0.3637\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4617 - mse: 1295.0344 - mae: 0.4617 - val_loss: 0.3628 - val_mse: 1259.2728 - val_mae: 0.3628\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9763 - mse: 35070509056.0000 - mae: 483.9763 - val_loss: 0.3636 - val_mse: 1259.2701 - val_mae: 0.3636\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2849 - mse: 551.5718 - mae: 0.2849 - val_loss: 0.3728 - val_mse: 1259.2712 - val_mae: 0.3728\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3275 - mse: 746.6227 - mae: 0.3275 - val_loss: 0.3658 - val_mse: 1259.2570 - val_mae: 0.3658\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6359 - mse: 50100727808.0000 - mae: 580.6363 - val_loss: 0.3659 - val_mse: 1259.2648 - val_mae: 0.3659\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4593 - mse: 1248.0702 - mae: 0.4593 - val_loss: 0.3741 - val_mse: 1259.2714 - val_mae: 0.3741\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1179 - mse: 30060435456.0000 - mae: 387.1180 - val_loss: 0.3688 - val_mse: 1259.2721 - val_mae: 0.3688\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4874 - mse: 25050365952.0000 - mae: 290.4876 - val_loss: 0.3683 - val_mse: 1259.2653 - val_mae: 0.3683\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4094 - mse: 1131.9606 - mae: 0.4094 - val_loss: 0.3646 - val_mse: 1259.2617 - val_mae: 0.3646\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4225 - mse: 25050363904.0000 - mae: 290.4225 - val_loss: 0.3665 - val_mse: 1259.2650 - val_mae: 0.3665\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4107 - mse: 1381.2728 - mae: 0.4107 - val_loss: 0.3672 - val_mse: 1259.2635 - val_mae: 0.3672\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1703 - mse: 30060435456.0000 - mae: 387.1702 - val_loss: 0.3639 - val_mse: 1259.2653 - val_mae: 0.3639\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4129 - mse: 1238.4070 - mae: 0.4129 - val_loss: 0.3622 - val_mse: 1259.2675 - val_mae: 0.3622\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1257 - mse: 30060435456.0000 - mae: 387.1256 - val_loss: 0.3621 - val_mse: 1259.2604 - val_mae: 0.3621\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3915 - mse: 1126.0583 - mae: 0.3915 - val_loss: 0.3646 - val_mse: 1259.2589 - val_mae: 0.3646\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1457 - mse: 30060435456.0000 - mae: 387.1461 - val_loss: 0.3695 - val_mse: 1259.2795 - val_mae: 0.3695\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3686 - mse: 950.7822 - mae: 0.3686 - val_loss: 0.3675 - val_mse: 1259.2537 - val_mae: 0.3675\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3967 - mse: 1248.5751 - mae: 0.3967 - val_loss: 0.3643 - val_mse: 1259.2616 - val_mae: 0.3643\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7043 - mse: 20040292352.0000 - mae: 193.7042 - val_loss: 0.3698 - val_mse: 1259.2599 - val_mae: 0.3698\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7983 - mse: 35070509056.0000 - mae: 483.7997 - val_loss: 0.3728 - val_mse: 1259.2671 - val_mae: 0.3728\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4399 - mse: 1209.6991 - mae: 0.4399 - val_loss: 0.3665 - val_mse: 1259.2637 - val_mae: 0.3665\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6324 - mse: 40080584704.0000 - mae: 580.6324 - val_loss: 0.3638 - val_mse: 1259.2604 - val_mae: 0.3638\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3340 - mse: 808.4750 - mae: 0.3340 - val_loss: 0.3635 - val_mse: 1259.2677 - val_mae: 0.3635\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3430 - mse: 918.5560 - mae: 0.3430 - val_loss: 0.3629 - val_mse: 1259.2592 - val_mae: 0.3629\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1910 - mse: 30060435456.0000 - mae: 387.1910 - val_loss: 0.3641 - val_mse: 1259.2659 - val_mae: 0.3641\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4710 - mse: 25050365952.0000 - mae: 290.4712 - val_loss: 0.3659 - val_mse: 1259.2660 - val_mae: 0.3659\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3939 - mse: 1107.1141 - mae: 0.3939 - val_loss: 0.3799 - val_mse: 1259.2695 - val_mae: 0.3799\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7612 - mse: 20040292352.0000 - mae: 193.7612 - val_loss: 0.3714 - val_mse: 1259.2617 - val_mae: 0.3714\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4002 - mse: 1019.6984 - mae: 0.4002 - val_loss: 0.3663 - val_mse: 1259.2617 - val_mae: 0.3663\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3488 - mse: 1051.9281 - mae: 0.3488 - val_loss: 0.3668 - val_mse: 1259.2621 - val_mae: 0.3668\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1803 - mse: 30060435456.0000 - mae: 387.1799 - val_loss: 0.3665 - val_mse: 1259.2668 - val_mae: 0.3665\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3940 - mse: 1174.0245 - mae: 0.3940 - val_loss: 0.3623 - val_mse: 1259.2604 - val_mae: 0.3623\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4233 - mse: 25050363904.0000 - mae: 290.4232 - val_loss: 0.3636 - val_mse: 1259.2651 - val_mae: 0.3636\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3299 - mse: 834.5574 - mae: 0.3299 - val_loss: 0.3688 - val_mse: 1259.2538 - val_mae: 0.3688\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2395 - mse: 30060439552.0000 - mae: 387.2394 - val_loss: 0.3772 - val_mse: 1259.2693 - val_mae: 0.3772\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 0.3521 - mse: 793.3479 - mae: 0.3521 - val_loss: 0.3721 - val_mse: 1259.2742 - val_mae: 0.3721\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5801 - mse: 25050365952.0000 - mae: 290.5801 - val_loss: 0.3697 - val_mse: 1259.2635 - val_mae: 0.3697\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1975 - mse: 30060439552.0000 - mae: 387.1974 - val_loss: 0.3855 - val_mse: 1259.2668 - val_mae: 0.3855\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4193 - mse: 1219.2703 - mae: 0.4193 - val_loss: 0.3634 - val_mse: 1259.2694 - val_mae: 0.3634\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8048 - mse: 35070509056.0000 - mae: 483.8050 - val_loss: 0.3671 - val_mse: 1259.2660 - val_mae: 0.3671\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3987 - mse: 1115.4512 - mae: 0.3987 - val_loss: 0.3679 - val_mse: 1259.2717 - val_mae: 0.3679\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3698 - mse: 1219.0024 - mae: 0.3698 - val_loss: 0.3617 - val_mse: 1259.2590 - val_mae: 0.3617\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4419 - mse: 25050363904.0000 - mae: 290.4418 - val_loss: 0.3632 - val_mse: 1259.2524 - val_mae: 0.3632\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4187 - mse: 1205.3372 - mae: 0.4187 - val_loss: 0.3623 - val_mse: 1259.2410 - val_mae: 0.3623\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8598 - mse: 35070509056.0000 - mae: 483.8606 - val_loss: 0.3631 - val_mse: 1259.2589 - val_mae: 0.3631\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1543 - mse: 30060435456.0000 - mae: 387.1543 - val_loss: 0.3861 - val_mse: 1259.2687 - val_mae: 0.3861\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4291 - mse: 1278.0599 - mae: 0.4291 - val_loss: 0.3693 - val_mse: 1259.2661 - val_mae: 0.3693\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3586 - mse: 783.6533 - mae: 0.3586 - val_loss: 0.3667 - val_mse: 1259.2709 - val_mae: 0.3667\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4547 - mse: 25050363904.0000 - mae: 290.4544 - val_loss: 0.3690 - val_mse: 1259.2610 - val_mae: 0.3690\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1445 - mse: 30060439552.0000 - mae: 387.1442 - val_loss: 0.3644 - val_mse: 1259.2664 - val_mae: 0.3644\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4116 - mse: 1264.7235 - mae: 0.4116 - val_loss: 0.3677 - val_mse: 1259.2616 - val_mae: 0.3677\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2463 - mse: 554.6270 - mae: 0.2463 - val_loss: 0.3638 - val_mse: 1259.2655 - val_mae: 0.3638\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8854 - mse: 20040292352.0000 - mae: 193.8854 - val_loss: 0.3658 - val_mse: 1259.2659 - val_mae: 0.3658\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2507 - mse: 589.0628 - mae: 0.2507 - val_loss: 0.3620 - val_mse: 1259.2542 - val_mae: 0.3620\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5338 - mse: 25050363904.0000 - mae: 290.5335 - val_loss: 0.3660 - val_mse: 1259.2601 - val_mae: 0.3660\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4674 - mse: 25050365952.0000 - mae: 290.4672 - val_loss: 0.3747 - val_mse: 1259.3102 - val_mae: 0.3747\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3735 - mse: 1065.6691 - mae: 0.3735 - val_loss: 0.3718 - val_mse: 1259.2646 - val_mae: 0.3718\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0922 - mse: 30060435456.0000 - mae: 387.0923 - val_loss: 0.3691 - val_mse: 1259.2677 - val_mae: 0.3691\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4751 - mse: 1462.8265 - mae: 0.4751 - val_loss: 0.3681 - val_mse: 1259.2675 - val_mae: 0.3681\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4078 - mse: 1212.3591 - mae: 0.4078 - val_loss: 0.3673 - val_mse: 1259.2699 - val_mae: 0.3673\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3912 - mse: 25050365952.0000 - mae: 290.3912 - val_loss: 0.3648 - val_mse: 1259.2665 - val_mae: 0.3648\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9136 - mse: 35070513152.0000 - mae: 483.9140 - val_loss: 0.3693 - val_mse: 1259.2661 - val_mae: 0.3693\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3324 - mse: 856.7933 - mae: 0.3324 - val_loss: 0.3622 - val_mse: 1259.2677 - val_mae: 0.3622\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7920 - mse: 20040292352.0000 - mae: 193.7920 - val_loss: 0.3618 - val_mse: 1259.2606 - val_mae: 0.3618\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4244 - mse: 1197.4292 - mae: 0.4244 - val_loss: 0.3646 - val_mse: 1259.2703 - val_mae: 0.3646\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5532 - mse: 25050365952.0000 - mae: 290.5534 - val_loss: 0.3721 - val_mse: 1259.2667 - val_mae: 0.3721\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3108 - mse: 775.4774 - mae: 0.3108 - val_loss: 0.3735 - val_mse: 1259.2683 - val_mae: 0.3735\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4477 - mse: 25050365952.0000 - mae: 290.4477 - val_loss: 0.3645 - val_mse: 1259.2650 - val_mae: 0.3645\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3790 - mse: 1038.0173 - mae: 0.3790 - val_loss: 0.3712 - val_mse: 1259.2618 - val_mae: 0.3712\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3361 - mse: 904.2833 - mae: 0.3361 - val_loss: 0.3680 - val_mse: 1259.2656 - val_mae: 0.3680\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5039 - mse: 25050363904.0000 - mae: 290.5039 - val_loss: 0.3702 - val_mse: 1259.2631 - val_mae: 0.3702\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1821 - mse: 30060435456.0000 - mae: 387.1820 - val_loss: 0.3675 - val_mse: 1259.2672 - val_mae: 0.3675\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3603 - mse: 942.2818 - mae: 0.3603 - val_loss: 0.3653 - val_mse: 1259.2667 - val_mae: 0.3653\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5743 - mse: 40080580608.0000 - mae: 580.5744 - val_loss: 0.3698 - val_mse: 1259.2682 - val_mae: 0.3698\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3641 - mse: 1043.1030 - mae: 0.3641 - val_loss: 0.3658 - val_mse: 1259.2670 - val_mae: 0.3658\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3923 - mse: 881.0320 - mae: 0.3923 - val_loss: 0.3689 - val_mse: 1259.2654 - val_mae: 0.3689\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1972 - mse: 30060439552.0000 - mae: 387.1973 - val_loss: 0.3691 - val_mse: 1259.2635 - val_mae: 0.3691\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3283 - mse: 971.2896 - mae: 0.3283 - val_loss: 0.3668 - val_mse: 1259.2665 - val_mae: 0.3668\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4172 - mse: 25050363904.0000 - mae: 290.4173 - val_loss: 0.3643 - val_mse: 1259.2604 - val_mae: 0.3643\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4767 - mse: 25050365952.0000 - mae: 290.4765 - val_loss: 0.3624 - val_mse: 1259.2589 - val_mae: 0.3624\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3518 - mse: 881.1904 - mae: 0.3518 - val_loss: 0.3646 - val_mse: 1259.2673 - val_mae: 0.3646\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5862 - mse: 25050363904.0000 - mae: 290.5859 - val_loss: 0.3668 - val_mse: 1259.2661 - val_mae: 0.3668\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3026 - mse: 637.3024 - mae: 0.3026 - val_loss: 0.3635 - val_mse: 1259.2678 - val_mae: 0.3635\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3508 - mse: 983.9228 - mae: 0.3508 - val_loss: 0.3624 - val_mse: 1259.2650 - val_mae: 0.3624\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4546 - mse: 25050363904.0000 - mae: 290.4546 - val_loss: 0.3887 - val_mse: 1321.4183 - val_mae: 0.3887\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5478 - mse: 40080580608.0000 - mae: 580.5479 - val_loss: 0.3790 - val_mse: 1259.2682 - val_mae: 0.3790\n",
      "Epoch 2/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4809 - mse: 1354.5964 - mae: 0.4809 - val_loss: 0.3699 - val_mse: 1259.2672 - val_mae: 0.3699\n",
      "Epoch 3/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4156 - mse: 25050363904.0000 - mae: 290.4156 - val_loss: 0.3675 - val_mse: 1259.2712 - val_mae: 0.3675\n",
      "Epoch 4/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4109 - mse: 1203.6012 - mae: 0.4109 - val_loss: 0.3787 - val_mse: 1259.2689 - val_mae: 0.3787\n",
      "Epoch 5/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9492 - mse: 35070509056.0000 - mae: 483.9495 - val_loss: 0.3649 - val_mse: 1259.2655 - val_mae: 0.3649\n",
      "Epoch 6/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2710 - mse: 572.0036 - mae: 0.2710 - val_loss: 0.3722 - val_mse: 1259.2646 - val_mae: 0.3722\n",
      "Epoch 7/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5048 - mse: 1531.4579 - mae: 0.5048 - val_loss: 0.3658 - val_mse: 1259.2682 - val_mae: 0.3658\n",
      "Epoch 8/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2044 - mse: 45090652160.0000 - mae: 677.2064 - val_loss: 0.3654 - val_mse: 1259.2653 - val_mae: 0.3654\n",
      "Epoch 9/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2698 - mse: 30060439552.0000 - mae: 387.2698 - val_loss: 0.3710 - val_mse: 1259.2563 - val_mae: 0.3710\n",
      "Epoch 10/10\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3509 - mse: 1085.2250 - mae: 0.3509 - val_loss: 0.3653 - val_mse: 1259.2625 - val_mae: 0.3653\n"
     ]
    }
   ],
   "source": [
    "def run_no_snap(i):\n",
    "    \n",
    "    model = networks.convolutional_ae_4_layer(hparams, ['mse', 'mae'])\n",
    "    \n",
    "    run_dir = '/tmp/snapshot/no_snap/' + str(i)\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(run_dir + '/best_weights.h5', \n",
    "                                                    save_best_only=True)]\n",
    "    \n",
    "    if not os.path.isdir(run_dir):\n",
    "        os.makedirs(run_dir)\n",
    "    \n",
    "    model.fit(train_set, epochs=10, steps_per_epoch=len(train_set)//batch_size+1,\n",
    "              validation_steps=len(test_set)//batch_size+1, validation_data=test_set,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    run_no_snap(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snapshot(snap_dir='/tmp/snapshot/snap/', num=100):\n",
    "    \n",
    "    for i in range(num):\n",
    "\n",
    "        run_dir = snap_dir + '__' + str(i)\n",
    "\n",
    "        if not os.path.isdir(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "\n",
    "        model = networks.convolutional_ae_4_layer(hparams, ['mse', 'mae'])\n",
    "\n",
    "    callbacks = [utils.callbacks.SnapshotEnsemble(snap_dir, num, num)]\n",
    "\n",
    "    model.fit(train_set, epochs=num, steps_per_epoch=len(train_set)//batch_size+1,\n",
    "          validation_steps=len(test_set)//batch_size+1, validation_data=test_set,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_snap_model_dirs = ['/tmp/snapshot/no_snap/{}/best_weights.h5'.format(i) for i in range(100)]\n",
    "snap_model_dirs = ['/tmp/snapshot/snap/__{}/best_weights.h5'.format(i) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/Yearly-train.csv'\n",
    "test_path = '../data/Yearly-test.csv'\n",
    "\n",
    "train = pd.read_csv(train_path).drop('V1', axis=1)\n",
    "test = pd.read_csv(test_path).drop('V1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "\n",
    "def get_last_N(series, N=18):\n",
    "    ser_N = series.dropna().iloc[-N:].values\n",
    "    if len(ser_N) < N:\n",
    "        pad = [ser_N[0]] * (N - len(ser_N))\n",
    "        ser_N = np.r_[pad, ser_N]\n",
    "    return ser_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([get_last_N(ser[1], N=18) for ser in train.iterrows()])\n",
    "y_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data):\n",
    "        \n",
    "    x = data[..., np.newaxis]\n",
    "    \n",
    "    mn, mx = x.min(axis=1), x.max(axis=1)\n",
    "    x_sc = (x[..., 0] - mn) / (mx - mn)\n",
    "\n",
    "    pred = model(x_sc[..., np.newaxis])\n",
    "\n",
    "    return pred[..., 0] * (mx - mn) + mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_preds(model_family, data):\n",
    "\n",
    "    preds = []\n",
    "    \n",
    "    for model_dir in tqdm(model_family):\n",
    "\n",
    "        model = tf.keras.models.load_model(model_dir)\n",
    "        preds.append(get_predictions(model, data))\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    return np.stack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single(preds, y_test):\n",
    "    return np.nanmean(metrics.SMAPE(y_test, preds[:, -6:]))\n",
    "\n",
    "def evaluate_ensemble(preds, y_test):\n",
    "    ensemble_preds = np.median(preds, axis=0)[:, -6:]\n",
    "    return np.nanmean(metrics.SMAPE(y_test, ensemble_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n",
      "100%|██████████| 100/100 [00:58<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_no = ensemble_preds(no_snap_model_dirs, X_test)\n",
    "preds_snap = ensemble_preds(snap_model_dirs, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 23000, 14)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 23000, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_snap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_no = [evaluate_single(p, y_test) for p in preds_no]\n",
    "single_snap = [evaluate_single(p, y_test) for p in preds_snap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2f870e5c0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(single_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2f8633470>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(single_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_no_snap = [evaluate_ensemble(preds_no[:i+1], y_test) for i in range(100)]\n",
    "add_snap = [evaluate_ensemble(preds_snap[:i+1], y_test) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2f8500710>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(add_no_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa2f823bcc0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(add_snap)\n",
    "plt.scatter([10], add_snap[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2f82201d0>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd3xc1Z338c+ZGY0kq1rFsiVZlo0Lrhgsg6k2LYApDiWbsCxlE8I6u2zY7KaQJQn7hCW7GzbJJk/yZEMSQgi9JkAIYBOICdjGveBeZUm2erfaaM7zxxlVy7Etyx7p6vt+vfSS5k7Rubqj75z7u+eea6y1iIiId/mi3QARETm1FPQiIh6noBcR8TgFvYiIxynoRUQ8LhDtBvSWkZFh8/Pzo90MEZEhZc2aNRXW2sy+7ht0QZ+fn8/q1auj3QwRkSHFGLP/aPepdCMi4nEKehERj1PQi4h4nIJeRMTjFPQiIh6noBcR8TgFvYiIx3km6BtbQnx/yQ7WH6iJdlNERAYVzwR9SyjMj97ZyQYFvYhID54J+mDArUpbezjKLRERGVw8E/QxfgNAq4JeRKQH7wS9L9KjD+nSiCIi3Xkm6H0+Q8BnVLoREenFM0EPEOP3KehFRHrxWNAbWkIKehGR7jwV9MGAevQiIr15KuhVuhEROZKngt716DXqRkSkO08FfYzfp3H0IiK9eC7o23QwVkSkB08FfdCvcfQiIr15KujdwVjV6EVEuvNc0LeqdCMi0oO3gj6gg7EiIr15KuhVoxcROZKngl4nTImIHMlTQa8TpkREjuSpoNfBWBGRI3ku6FW6ERHpyVNBr4OxIiJH8lTQq3QjInIkbwW9DsaKiBzBW0Efmb3SWoW9iEgHTwV90G8ACIUV9CIiHY4Z9MaYx4wxZcaYzd2WPWSM2WiMWW+MedsYk32U537XGPOxMWarMeZHxhgzkI3vLcbvVkcHZEVEuhxPj/5x4Opeyx6x1s6y1s4GXge+1ftJxpgLgAuBWcAMYC4w/6RaewzBQCToQ+rRi4h0OGbQW2uXAVW9ltV1u5kA9JWsFogDgkAsEAOU9rulx6GjR6+JzUREugT6+0RjzMPAHUAtcGnv+621y40x7wIHAQP82Fq79SivdQ9wD0BeXl5/m0RQpRsRkSP0+2CstfYBa+1Y4Cng3t73G2MmAlOBXCAHuMwYc/FRXutRa22BtbYgMzOzv00iJuAOAWgsvYhIl4EYdfMUcHMfy28EVlhrG6y1DcAfgPMH4PcdlQ7GiogcqV9Bb4yZ1O3mImBbHw8rBOYbYwLGmBjcgdg+SzcDRTV6EZEjHbNGb4x5BlgAZBhjioAHgYXGmClAGNgPLI48tgBYbK29G3gRuAzYhDsw+6a19rVTsRIdumr0GnUjItLhmEFvrb21j8W/PMpjVwN3R35uB/7upFp3glS6ERE5krfOjO0cR6+gFxHp4Kmgj4lMgaAavYhIF48FvWr0IiK9eSroO0o3GkcvItLFU0Gvg7EiIkfyWNCrRi8i0pungl5z3YiIHMlTQd9ZulGNXkSkk7eCPqBRNyIivXkq6IOa60ZE5AieCvqOg7Gq0YuIdPFU0BtjiPEbjaMXEenGU0EP7oCsevQiIl08GvQ6GCsi0sGTQa+DsSIiXTwX9EG/0Th6EZFuPBf0MQHV6EVEuvNe0KtGLyLSg+eCPqgavYhID54L+piAT+PoRUS68VzQB/1GNXoRkW48F/Q6YUpEpCdPBn2rDsaKiHTyZNBrHL2ISBfPBX0woBq9iEh3ngt61ehFRHryXNAHdcKUiEgPngv6mICPFtXoRUQ6eS7ogyrdiIj04Lmgj9EJUyIiPXgw6NWjFxHpzqNBb7FWB2RFRMCDQR8MuFXSyBsREcdzQR/jNwAq34iIRBwz6I0xjxljyowxm7ste8gYs9EYs94Y87YxJvsoz82L3L/VGLPFGJM/cE3vW4y/o0evoBcRgePr0T8OXN1r2SPW2lnW2tnA68C3jvLcJyKPnQqcC5T1t6HHq6N0oznpRUScYwa9tXYZUNVrWV23mwnAEQVxY8w0IGCtXRJ5ToO19vDJNffYOnr0usqUiIgT6O8TjTEPA3cAtcClfTxkMlBjjHkZGA8sBe631rb38Vr3APcA5OXl9bdJgDthCnQwVkSkQ78PxlprH7DWjgWeAu7t4yEB4GLgy8BcYAJw11Fe61FrbYG1tiAzM7O/TQJUoxcR6W0gRt08Bdzcx/IiYL21do+1NgT8FjhnAH7fX9Qx6kY1ehERp19Bb4yZ1O3mImBbHw9bBaQaYzq66JcBW/rz+05ETEA9ehGR7o5ZozfGPAMsADKMMUXAg8BCY8wUIAzsBxZHHlsALLbW3m2tbTfGfBl4xxhjgDXAz0/NanRRjV5EpKdjBr219tY+Fv/yKI9dDdzd7fYSYFa/W9cPqtGLiPTk2TNjVaMXEXE8F/SdJ0ypRy8iAngx6FW6ERHpwXNBrxq9iEhP3gv6juGVIY26EREBLwZ9x8FY9ehFRAAPBr1q9CIiPXku6FWjFxHpybNBr3H0IiKOB4O+o0avg7EiIuDBoDfGEPT7VLoREYnwXNCD69W3qXQjIgJ4NegD6tGLiHTwZtD7farRi4hEeDLoVaMXEeniyaCP8RsFvYhIhEeD3qdx9CIiEZ4NevXoRUQcTwZ9MKCDsSIiHbwZ9H6fxtGLiER4MuhjAjoYKyLSwZtBrxq9iEgnzwa9avQiIo4ng14nTImIdPFk0Mf4jcbRi4hEeDTo1aMXEengzaDX7JUiIp08GfRBTYEgItLJm0Ef8NGmUTciIoBHg16zV4qIdPFo0PsIhS3hsHr1IiKeDXqAtrB69SIingz6YCTodUBWRAQC0W7AqRDjNwA6ICsiQ8K+ikaWbi3FWvj8JRMG/PWPGfTGmMeA64Aya+2MyLKHgEVAGCgD7rLWlhzl+cnAFuC31tp7B6rhf0lMIFK60QFZERmEQu1h1hbW8MdtZSzdWsqusgYALpqYEZ2gBx4Hfgw80W3ZI9babwIYY74IfAtYfJTnPwQsO4k2njCVbkRkMLHWsqeikeW7K1m+p5I/76ygtqmNgM9w7vg0bjsvjyumZjE2bcQp+f3HDHpr7TJjTH6vZXXdbiYAfdZIjDFzgCzgTaCg3608QUH16EUkyprb2vlwdwVLt5bxx61lHKprBiArOZbLp47iiqlZXDQpg+S4mFPeln7X6I0xDwN3ALXApX3c7wO+B/wNcMUxXuse4B6AvLy8/japU+eoG9XoReQ0ag9bPtxdwSvrinlr8yEaW9tJCPq5ZHImF0/K5Pwz0slPH4Ex5rS2q99Bb619AHjAGPN14F7gwV4P+XvgDWtt0bFWylr7KPAoQEFBwUmnc1fQq0cvIqfW3opGPtxdwYo9VSzfXUFFQytJcQGuPyubhTPHcN6ENGID/qi2cSBG3TwFvMGRQX8+cLEx5u+BRCBojGmw1t4/AL/zL+oYddOqoBeRU2BPeQO/33iQ1zceZHtpPQCjkmK5cGIGV00fzWVnjiIuJrrh3l2/gt4YM8lauzNycxGwrfdjrLW3dXv8XUDB6Qh50MFYERl44bDl3e1lPPbBXj7YVQnA3PyR/Nv105g/ZVRUSjLH63iGVz4DLAAyjDFFuJ77QmPMFNzwyv1ERtwYYwqAxdbau09Zi4+DhleKyEA5VNvMb9cX8/yqA+ypaGR0chxfuWoKN52Tw5iU+Gg377gcz6ibW/tY/MujPHY1cETIW2sfxw3TPC1UoxeRk9ESauftj0t5fvUB/ryrAmvhnLxUfviZ2SycOaYzY4YKT58Z2xrSqBsROX77Kxt5amUhL64poqqxlZzUeP7x0onceE4u4zMSot28fvNk0MeqdCMix8lay593VfD4B/v44/YyfMZw5dQsbj0vj4snZuDzDc66+4nwZNCrdCMix7KjtJ7frS/md+tLKKpuIiMxyD9eOpHb5o0jKzku2s0bUAp6ERk2yutbeHVDCS+tKWLLwTp8Bi6cmMG/fGIyC2eOifp491PF00HfqjNjRQTYVdbAD5bu4M3Nh2gPW2blpvCt66Zx/VnZZCbFRrt5p5wng17j6EUEoLDyMD98ZyevrCsiPsbP3ReN55Y5uUzKSop2004rTwZ9TKBjPnoFvchwY61lbWE1v3h/L299fIgYv4/PXTSexfPPID3R+733vngz6NWjFxl2DreGeG1DCU+tLGRjUS0p8TEsnn8Gd16Q77mDqyfKs0EfH+Onrqkt2k0RkVOoPWxZta+K1zaU8Or6EupbQkzOSuShRdO5eU4uI4KejLgT5tm/QlpCkMrG1mg3Q0QGWGsozMq9lSzZUsofNh+ivL6FuBgfV08fzW3zxlEwbuSgnXMmWjwb9BmJCnoRr2gJtfPe9nJe21DCn7aXU98SIjbg49Ipo7h21hgunzpKvfe/wLN/mbSEIOUNLdFuhoj0k7WWdQdqeO6jA7yx+SD1zSHSEoJcO2sMV0zN4sKJGcQHvTnufaB5NujTE2PZdqg+2s0QkRNUVt/MGxsP8uyqA2w7VM+IoJ+rZ4xm0ewcLjwjncAQm1BsMPBu0Edq9NZa1etEBrmy+mZe33CQP2w+yOr91VgLM3NS+M6NM7lhdjaJsZ6NqtPCs3+99MQgraEwDS0hkk7DxXdF5MQ0tbazZGspL68tYtmOcsIWzhydxH2XT+LqGaM5c3RytJvoGZ4N+rQEd2JEVWOrgl5kkGgNhfnTDndQdenWUg63tpOdEscXFpzBjWfnMnFUYrSb6EmeDfr0xCAAFQ2tjEsfuvNIiwx11lo+LqnjxTVF/G59MdWH20gdEcOi2Tlcf9YY5o1P98RUwIOZd4M+wQV9lYZYikRFWZ27BN9La4rZXlpP0O/jyulZ3HxODhdPyhxyV2kayjwb9GmdQa8hliKn07rCah5dtoe3t5TSHracnZfKQ5+cwQ2zskkZoTJqNHg26NMjNfqKBvXoRU61llA7f9xaxq8+3MdHe6tIjgvw+Ysn8KmCXM7IVN092jwb9PFBPyOCfpVuRE6hTUW1PLOqkNc3lFDXHCI7JY5vXjeNz8wdS4KGRA4ant4S6YlBKnV2rMiA21hUww+X7uSdbWXEx/i5anoWN52Ty4UTM/DrwOqg4+mgT0uI1Xw3IgMk1B7m3e3l/GbFfpbtKCclPoYvf2Iyd1yQT7KGMA9qng76jIQgh+qao90MkSGtrrmN3yzfz5Mr9nOwtpms5Fi+/InJ3HlBvs5RGSI8HfRpCUE+LqmLdjNEhqS65jZ+/cE+fvHnvdQ2tXHRxAwevH46l08dpaGRQ4yngz49MZYqzXcjclw6Zot8f0cFy/dUsLawhtZQmCumZnHf5ZOYmZsS7SZKP3k76BOCtLaHqW8JqYYochQNLSFeWVfMk8v3s720HmNg6uhkbp83jk/OzlHAe4Cng77zpKmGVgW9SC87Sut5csV+Xl5bTENLiOnZyfznTTO5esZoUkcEo908GUCeDvqO+W4qG1vIz9B8NyLWWt7fWcH/e28XK/ZUEfT7uHbWGG4/fxxnj01VidOjvB30kbNjK3V2rAxz1lre21HOj97ZybrCGsakxHH/NWfyqTm5pCfGRrt5cop5O+gTNbGZDG/Vja28tLaIp1cWsqeikZzUeB6+cQa3zMklNqDL8A0Xng76jhq9TpqS4aJjSuA/76rgg10VrNxbRWsozJxxI/n+ZRO5blY2wYCGRg43ng76uBg/ibEBlW7E86oaW3lpTRHPrCpkT3kjAFOykrh93jhumZPL1DG6WtNw5umgB9err9RUxeJBofYwy3aW8+KaIpZuKaO1PUzBuJEsvvkMFkzJZFRyXLSbKIPEMYPeGPMYcB1QZq2dEVn2ELAICANlwF3W2pJez5sN/BRIBtqBh621zw1s848tPTGoGr14yv7KRp7+qJCX1hRT0dBCWkKQv5k3js+cO5bJWUnRbp4MQsfTo38c+DHwRLdlj1hrvwlgjPki8C1gca/nHQbusNbuNMZkA2uMMW9Za2tOvtnHLz0hSEmN5ruRoa09bHlnaym/WbGf93dW4PcZLjtzFJ+ak8uCKaNUd5e/6JhBb61dZozJ77Ws+wQyCYDt43k7uv1cYowpAzKB0xr0aQlBNhXXns5fKTJgapvaeGH1AX69fB8HqpoYkxLHl66YzKfnjmV0ikozcnz6XaM3xjwM3AHUApce47HnAkFgd39/X39pvhsZaqy1rNxbxfOrDvD7TQdpCYWZmz+Sr18zlU9MyyKgCcXkBPU76K21DwAPGGO+DtwLPNjX44wxY4DfAHdaa8NHecw9wD0AeXl5/W1Sn9ITgrS1W+qaQ6TEaxoEGZza2sOs2lvF21tKWbKllOKaJpJiA9wyJ5dbz81jRo7mm5H+G4hRN08Bb9BH0BtjkoHfAw9Ya1cc7QWstY8CjwIUFBQcUQY6Gd1PmlLQy2ASDltW7avi1Q0lvLHpINWH2wgGfFw8MYN/vnIyC2eOIT6ok5rk5PUr6I0xk6y1OyM3FwHb+nhMEHgFeMJa+2L/m3hy0jqnQWhhvOa7kShbW1jN8t2VrCusYf2BaioaWomP8XPFtCyunTmaSyZnMiLo+VHPcpodz/DKZ4AFQIYxpgjXc19ojJmCG165n8iIG2NMAbDYWns38FfAJUC6MeauyMvdZa1dP9Ar0SnUCoGes+6l6+xYGQSW767kf5buYOXeKgAmZCRwyaRMLpmcyZXTsnQhbTmljmfUza19LP7lUR67Grg78vOTwJMn1boTUVsETyyCyx+EaTd0LtZ8NxItB2ubWLKllNc2lLBqXzWjkmL5t+un8cmzczQNsJxW3ulGxI+E+DR46XMQ9wJMWAB0m++mQWfHyqnXHra8ufkQP39/D+sPuJHEEzIS+NZ10/jr8/KIi1HNXU4/7wR9MAFuex5+dS08exvc+SrkzCE24CcrOZbHPthHwO/j9nnjtJssA+5wa4g3Nx/iJ+/uYnd5IxMyE/jq1VP4xLTRTByVGO3myTBnrB3QQS4nraCgwK5evbr/L1B/CB67Cprr4HNLIGMim4tr+e5b21m2o5y0hCDfvXkWV0zLGrhGy7BUc7iV1zaUsHRrGcv3VNIaCnPm6CTuvWwi18wYg9+n8zbk9DHGrLHWFvR5n+eCHqBqL/z0Qjjr03DdDzoXry2s5isvbKA9bHn3ywt0ApWcMGstm4vreGL5Pl7dUEJLKEx++ggun5rF5VNHMW98Oj4FvETBXwp6b9Yw0sbD+Ithz3s9Fp+TN5LF88/gKy9uZPX+aubmp0WnfTJkWGvZX3mYNfur+XB3Jct3V1BS20x8jJ+bzsnl9nnjmJatKYBlcPNm0IM7GLvjTagphNSus20XzhzDg69+zIurixT00oO1ltK6FjYU1bCpqJYNRTVsLKqltqkNgJEjYjj/jHT+YWIG183K1gl4MmR4O+gB9vwJzrm9c3FCbIBrZ47h9Y0lPHjDNJ2cMoxZa9l6sJ73d5azrrCGdQeqKa1zo7P8PsPkrCQWzhzNWbmpnDU2lSlZSSrLyJDk3ZTLPBMSs1z5plvQA9wyJ5cX1hTxh02HuHlObnTaJ1HRHrbsq2xk6ZZSXllXzLZD9QCMSx/B+RPSOWtsKrNyU5menayhkOIZ3g16Y1yvftc7EA6Dr2vGv3PHpzEufQQvrDmgoB8GdpTW8+KaIlburWLHoXqa2toBmD02lW8vms41M8aQmRQb5VaKnDreDXpwQb/xOSjbAqNndC42xnDLObl8b8kOCisPk5c+ImpNlIEVDluKa5rYXd7AztIGfr/pIOsP1BDwGeaMG8lnzh3L1DHJzM1P09xHMmx4O+jHz3ff97zXI+gBbp6Ty/eX7uDFtUX885WTT3/bpN+stawtrGHLwTp2ldazq7yB8voWqhrbqDncSijcNWR4clYi37h2KjeenUN6onrtMjx5O+hTciBjsgv6C+7tcVd2ajzn5qexdEupgn6IaGsP8/rGEh5dtpetB91FzhJjA5wxKpHxGQnMGRckdUSQsSNHMHFUIhMyE8hQuIt4POjBlW/WPdnnzJbnTUjnx3/cSX1zG0lxGio3WFU1tvLsqkKeXL6fktpmJo1K5Ls3z+LiyRmMTo7TiW8ixzA8gv6jR6FoFeRf2OOuufkjCVtYV1jDJZMzo9I86RJqD7NybxUr91TS0h4mHHbj2t/8+BCtoTAXnJHOv984gwWTR2mYo8gJ8H7Qj7sQjA92vn1E0J+dNxK/z7B6X5WCPgqstRRVN7G2sJoPdlWwZEsp1YfbMAZi/D4CPkN8jJ/PzB3L7fPGMSkrKdpNFhmSvB/08akwZSGs+RVc9CV3OyIxNsC0Mcl8tK8qig0cPsrqm9l4oJZNxbVsLq5lQ1EtFZHpo5NiA1w2dRTXzBjN/MmjdAk9kQHk/aAHmP9V2PY6rPwZLPhaj7sK8kfyzEeFtIbCBAO+o7yAnKhw2LLtUD0f7a1k9f5q1hXWUFzTBIDPwBmZiVwyOYOz80YyJ28kU0YnabZHkVNkeAT9mLNcr37FT2DeYohL6bxrbn4av/pgHx+X1HJ23sgoNnJo2FvRyLId5azYU8lHe6toamsnPTFIekIssQEfbe1h2tot+ysbqWsOAZCdEsfZ40bytxfmM3tsKtOykzX1hMhpNHz+2+Z/DR6d73r187/aubhgnAv31fuq+xX0v11XzCNvbaekpons1Hi+ctUUPnl2zoA1e7BYva+K//3TbpZuLQMgJzWe+VMyGTkiSGVDC5WNrbSGwiTEBojx+5iRk8y549OYm59G7kidkCYSTcMn6LNnw+RrYPlP4LzFEOemlh2VHMe49BGs2lfF5y+Z0Plwa+0xh+39dl0xX395U+cp9cU1TXz95U0Angn7A1WH+cqLG1ixp4rUETHcd/kkbpmTy9g0hbfIUDG8itILvgbNNfDRz3osnpufxur91VhraQ9b7nt2HX/985Uc66Isj7y1vTPkOzS1tfPQ61uO+dyh4A+bDrLwR+/zcXEd37puGh/efxlfunKyQl5kiBleQZ99Nky8Elb8L7Q1dy6emz+SqsZWdpc38p03tvK79SUs31PJxyV1PZ4eDltqDrd23i6JHFzsrbKxlXufWUdzrw+BoaK2qY0HXtnEF55ay4TMRN6472I+e9F41dVFhqjhFfQAF34RDlfAxmc7FxVELkDyr69s4pd/3sun5uQS4zf8bn1xj6f+YOkO5j68lDc2HQTcNAp9SY4L8Mamg/zVz5ZTWtfc52MGo1B7mN8s38el//0eT39UyD2XTOCFvztfPXiRIW74BX3+xTB6lqvVh8MATMhIIC0hyEd7q7hiahb/efMs5k/O5NUNJbRHJshqaAnx+If7ALj36bU881Eh180ac8TLx8f4+faiGfz89gJ2lzVww4//zI7S+tO2ev3R3NbOc6sKuep/lvHN333M5KxEXrv3Iv514VQNORXxgOH3X2wMXPBFqNjhzpbFTVt81fTRnJOXyo9unY3fZ1g0O4fSuhZW7q0E4LlVB6hvDvHEZ8/jksmZfP3lTTy9spDRyXFkp8RhcCNR/uOmmXzyrNFcMS2LF79wAdbCbb9Yyb6KxiiudN92lzfwX29u4/z/eIevvbSJGL+Pn90+h2c+P48ZOSnHfgERGRLMYDtoWFBQYFevXn1qf0l7G/zwLEibAHe93rm4+0ibptZ2Cv59CdfNyubhG2cw/5H3yEmN5/nF59MaCvPlFzaw5ONinl98MTNzI6EYaoX3vgMrfuqGcF74JXaWN/LpR1cQH+Pn+cXnk3OUcs9As9ZSVt9CYmyAEZGzTMsbWthT3sjGohpe23CQTcW1+AxcOS2Luy4Yz7wJaYN3gjBrobURYhOj3RKRQckYs8ZaW9DXfcPz6Jo/BuZ9Ad7+Buxa6oK/aDWmphBaG6ClnviR47j5zJt5ZfNB5o5Po7imiQevnwZAsHYvPww9BDHvYt6/Gub8LYwcBy/fAwfXQ9ZMeOfbULSGSTf+lCc+ey63/nwFt/18BU9/ft5Ra/vghjMWVTcRH/QTH+MnOzXuhGfWXLGnku+8sZWNRbUABHyGGL+vxwihWbkpfOPaqVx/VjZZyXH9+COeQg1lULgc9n8IxWugrsQtC7dB5lQ481p3AlzWdIg5jrY310HlTjhc7V6jvQ2sK9thDMQmu+msk7PdbRGPGZ49eoDmWvj+dGiN1M+NH1Jy3T99MAFK1tLmj+f+hlt5M7CArKRYlt49Cd+Gp+H974E/CNM/CTvegkZ3EhHxI+GG/wtnXudOzHr7AUjNg5t+wZr2Cdz52EcE/Ibv3Xgml7e9B/kXub2KiHe3lbH4yTW0hMKdy3wGpoxOZm7+SM7OS2V6dgoTMhII+HtW3UrrmtlYVMtzqwpZurWMMSlx3HVBPgA1TW20tIXJS4tnQmYik7ISGZNyevYsjiochortcGgzHNoI5duh9gDUFkFLZLRTIB5y5ri/YVIWxIyAvctg/wddQZ2YBSlj3fcRae6rrcl9MDSUQfVeqD94fG0KJsHIfDcfUlyKey/EJUNskvvdPr97n/j8bg/Dht1XqAVCTW6Po67ErUNDGaRPgNxzIXduZI4l4ybYS8qC5Bz3Ot1ZC6FmaKl3rxVqcbcDse7xccnuMQ1l7m9Xtcf9XH8I2lvdqLKx50HmFPf+biiFphr3vPg09/6MideHmUf9pR798A16gB1vQ/k2yC2AMbMh2G10SfkO7Kv3Yg6spNimM9pfjz8cGVo5/Sa46juQPMb1Dre/ASXr4Nx7XK+ww/7l8OJnoeEQzPt79s36J554+tfcWfszxvnKsMEEzLU/gLM+zR82HeSLz65jyugk7r96Km3tYRpbQ+wsbWDN/mrWFlZzuNX1yGMDPnJS4/H5DH5jqD7cSlm9mxwsMTbAFxacwecuGj84L25dscuNeNrwHNQWumX+oOtRp45zH7Yjx7mAHHPWEdcQAOBwFez+owu6mkL3AdFYAYcr3VdMPCSMgsRR7jUzJrnXT8h0e3P+GBfYRN77hyvdB035dhfSzbXuw6apxnUEWuq7PliOxvhdByFpjLvgzYgM994q/RhsH8Ns/UH3AeYPQktD554k4baj/47YFBfSzTU9l8e7UWM0Hc/9l18AAAnoSURBVMfkfMbvyl+xKZCW7/4u6RPd36S9zX24NNdE/pZV7gMvNc99ZUyBUVN7/p/IoKGg769wmLee+A9iCpdxybkFBDLOcOGTM+f4X6O5FpY86GbPjE2BllrK4/L5t7obuDPwNuf6trEx/Wq+f2g2UzJiuG/+OEZMuhiSRvd4mVB7mN3ljXxcUsvHJXWU1jUTjpzglRAbYGZOCrNyU5g2JiW6Mz+2NbmD3EWrXRBX73O9zvaWrh6q8cGES2HGTZB9jgti/yC+8EtHTzvc7kI73O7WwUR66IG4o7e/tREObXLfse659Qehaq/b27BhCCa6PYbYpMgeRGSvMhDnvtoOuw+gumIXxplnul57+hluTyYQ69pYvRcOrILKXTAi3e05xKW6D5CmKmiqdj+3NLifq/a4QQktPc8XwRdwz49Pc+/f+oN0figaX9eHQ3K2+4pN7vogDLW45zTXuuekjHUfEilj3Xs6cVTX36q9DcIh98EsJ01BfxLCYUtre/jke8d734f3/hOmXAPn/R3rSxp5c9MBsjf8hNuan8Vvum2HEenwV785Yv78AdFYAcVr3R5IyVrX64wZ4f6p45JdL7ah1PXoss+GaYtg6vUujOoPdoVU5S6o2u1eM3G0C5WybW7vprUB/LGuDJI23oVRTLzrvSaNgek3ur0hiT5r3ba24cjeTtC9H7qXd0ItUHMAyre6D62DG90HeF0JtNT28aLG7QlY28f9xn2gtTV17b3EpbjSVNIY9z4JxLqyXWJm13srNgliEtzeRHya2zs7nuMzw4iCfpCrKdpGSrgGE4hz/wCv3uv+ka79Hpxzp6vBlm1x/wS5c0+s99tYAdv/4A46F6/tKpdgXM8sa5rrWR2ucr2w+FQXzLFJsO991+vD0Nmj6+ALuCDHuA+GljpXA556g+upj7sI/MPzWP+w0lF2Mj7AuFJbMAl8kWNITTWutFZzwJUw60tdaSgQ5/ZajHHL6ord+zzU7D5Y2pqgsfwYpaxk1wEJxLrXSxzljnmlTXDHajqOp4RaInsyde4DrePYSyDO3dfe6vYsrAWse15civsKxLoPwsYKtxdkfG7dfDHuNToeFz/SfcWlur22UJNbB3/QtbFjXTv2YtoOR9pU735HUrbr4Pn6P+JdQT/UNNW42v7udzrLPZ2CSTBhvrtEYs4cyJrhgr/+kOttVe7qqlWXb4cDK9ybOzkHxp7rSiU557gSVOwxrthkLZRuhu1vuqxPyna73yPzXe27e5C3HnZvaoW7DJRw2IVrwyH3gdLW6Epgh6vcAIiGcrcs1OqCte6g65gcz7GKwcgfhPGXwN+81K+na3jlUBOfCn/9PHz4I9ezz5oOo6a5ntCupbDrHXchFXAlkthEF+wdjN/1aJJz4OIvw9Tr3NnAJzrawhgYPdN9HYsO0MlA8/kgId19nYimajek1ra7zoov0HXsA7p696FWtwfij3WP6fj/CLe7+5trXa98RLorFcVHpjEPh9xeQEt95HhEjeucNVW7n32BSAkqzvXgWyN7Pda6Tpkv0HVMJjbJ7cXUlbi9mo4D6wNMPfqhyFp3cK54DRSvdm+2rEggZ05xu48nsQsoIkPPSfXojTGPAdcBZdbaGZFlDwGLgDBQBtxlrS3p47l3At+I3Px3a+2v+7cK0oMxkDrWfU3/ZLRbIyKD3PF0+x4Hru617BFr7Sxr7WzgdeBbvZ9kjEkDHgTOA84FHjTG6Fp9IiKn2TGD3lq7DKjqtaz7wNsEjhiSAcBVwBJrbZW1thpYwpEfGCIicor1+2CsMeZh4A6gFri0j4fkAAe63S6KLOvrte4B7gHIy8vrb5NERKQP/T5iZ619wFo7FngKuPdkGmGtfdRaW2CtLcjMzDyZlxIRkV4GYmjGU8DNfSwvBsZ2u50bWSYiIqdRv4LeGDOp281FwLY+HvYW8AljzMjIQdhPRJaJiMhpdDzDK58BFgAZxpgi3EiahcaYKbjhlfuBxZHHFgCLrbV3W2urIsMwV0Ve6tvW2iF6ypqIyNClE6ZERDxgSM11Y4wpx+0l9FcGUDFAzRkqhuM6w/Bc7+G4zjA81/tE13mctbbP0SyDLuhPljFm9dE+1bxqOK4zDM/1Ho7rDMNzvQdynTUhioiIxynoRUQ8zotB/2i0GxAFw3GdYXiu93BcZxie6z1g6+y5Gr2IiPTkxR69iIh0o6AXEfE4zwS9MeZqY8x2Y8wuY8z90W7PqWKMGWuMedcYs8UY87Ex5r7I8jRjzBJjzM7Id8/N/W+M8Rtj1hljXo/cHm+MWRnZ5s8ZY4LRbuNAM8akGmNeNMZsM8ZsNcac7/VtbYz5UuS9vdkY84wxJs6L29oY85gxpswYs7nbsj63rXF+FFn/jcaYc07kd3ki6I0xfuAnwDXANOBWY8y06LbqlAkB/2KtnQbMA/4hsq73A+9YaycB70Rue819wNZut/8L+IG1diJQDXwuKq06tX4IvGmtPRM4C7f+nt3Wxpgc4ItAQeSKdn7gM3hzWz/OkdfoONq2vQaYFPm6B/jpifwiTwQ97gpWu6y1e6y1rcCzuMnWPMdae9Bauzbycz3uHz8Ht74dl2r8NeCpawwaY3KBa4FfRG4b4DLgxchDvLjOKcAlwC8BrLWt1toaPL6tcXNwxRtjAsAI4CAe3NZ9XdSJo2/bRcAT1lkBpBpjxhzv7/JK0B/3RU68xBiTD5wNrASyrLUHI3cdArKi1KxT5X+Ar+Im0gNIB2qstaHIbS9u8/FAOfCrSMnqF8aYBDy8ra21xcB/A4W4gK8F1uD9bd3haNv2pDLOK0E/7BhjEoGXgH/qdWlHrBsz65lxs8aYjovTr4l2W06zAHAO8FNr7dlAI73KNB7c1iNxvdfxQDbuUqXD8hKkA7ltvRL0w+oiJ8aYGFzIP2WtfTmyuLRjVy7yvSxa7TsFLgRuMMbsw5XlLsPVrlMju/fgzW1eBBRZa1dGbr+IC34vb+srgL3W2nJrbRvwMm77e31bdzjatj2pjPNK0K8CJkWOzAdxB29ejXKbTolIbfqXwFZr7fe73fUqcGfk5zuB353utp0q1tqvW2tzrbX5uG37R2vtbcC7wC2Rh3lqnQGstYeAA5FrPwBcDmzBw9saV7KZZ4wZEXmvd6yzp7d1N0fbtq8Cd0RG38wDaruVeI7NWuuJL2AhsAPYDTwQ7facwvW8CLc7txFYH/laiKtZvwPsBJYCadFu6yla/wXA65GfJwAfAbuAF4DYaLfvFKzvbGB1ZHv/Fhjp9W0N/B/cVes2A78BYr24rYFncMch2nB7b5872rYFDG5k4W5gE25U0nH/Lk2BICLicV4p3YiIyFEo6EVEPE5BLyLicQp6ERGPU9CLiHicgl5ExOMU9CIiHvf/ATt4Iv1Pq7n8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(add_snap)\n",
    "plt.scatter([10], add_snap[10])\n",
    "plt.plot(add_no_snap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5489 - mse: 40080580608.0000 - mae: 580.5491 - val_loss: 0.3691 - val_mse: 1259.2681 - val_mae: 0.3691\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4198 - mse: 1270.0308 - mae: 0.4198 - val_loss: 0.3791 - val_mse: 1259.2639 - val_mae: 0.3791\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5428 - mse: 40080580608.0000 - mae: 580.5435 - val_loss: 0.3655 - val_mse: 1259.2637 - val_mae: 0.3655\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4424 - mse: 1395.3506 - mae: 0.4423 - val_loss: 0.3668 - val_mse: 1259.2661 - val_mae: 0.3668\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0805 - mse: 30060435456.0000 - mae: 387.0806 - val_loss: 0.3644 - val_mse: 1259.2584 - val_mae: 0.3644\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4033 - mse: 1357.1461 - mae: 0.4033 - val_loss: 0.3671 - val_mse: 1259.2605 - val_mae: 0.3671\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3132 - mse: 796.8045 - mae: 0.3132 - val_loss: 0.3713 - val_mse: 1259.2673 - val_mae: 0.3713\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2474 - mse: 30060435456.0000 - mae: 387.2474 - val_loss: 0.3697 - val_mse: 1259.2626 - val_mae: 0.3697\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2226 - mse: 30060435456.0000 - mae: 387.2225 - val_loss: 0.3644 - val_mse: 1259.2631 - val_mae: 0.3644\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2837 - mse: 587.5223 - mae: 0.2837 - val_loss: 0.3623 - val_mse: 1259.2686 - val_mae: 0.3623\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5230 - mse: 25050365952.0000 - mae: 290.5231 - val_loss: 0.3611 - val_mse: 1259.2610 - val_mae: 0.3611\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3414 - mse: 783.7728 - mae: 0.3414 - val_loss: 0.3680 - val_mse: 1259.2701 - val_mae: 0.3680\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4798 - mse: 25050363904.0000 - mae: 290.4798 - val_loss: 0.3619 - val_mse: 1259.2633 - val_mae: 0.3619\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3749 - mse: 1021.4915 - mae: 0.3749 - val_loss: 0.3625 - val_mse: 1259.2610 - val_mae: 0.3625\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3361 - mse: 909.7554 - mae: 0.3361 - val_loss: 0.3609 - val_mse: 1259.2743 - val_mae: 0.3609\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.0081 - mse: 50100727808.0000 - mae: 774.0082 - val_loss: 0.3653 - val_mse: 1259.2659 - val_mae: 0.3653\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3263 - mse: 873.5482 - mae: 0.3263 - val_loss: 0.3622 - val_mse: 1259.2604 - val_mae: 0.3622\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9154 - mse: 35070513152.0000 - mae: 483.9164 - val_loss: 0.3607 - val_mse: 1259.2708 - val_mae: 0.3607\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8866 - mse: 20040294400.0000 - mae: 193.8866 - val_loss: 0.3606 - val_mse: 1259.2682 - val_mae: 0.3606\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3167 - mse: 697.3915 - mae: 0.3167 - val_loss: 0.3627 - val_mse: 1259.2638 - val_mae: 0.3627\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2749 - mse: 564.0043 - mae: 0.2749 - val_loss: 0.3613 - val_mse: 1259.2568 - val_mae: 0.3613\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2199 - mse: 30060435456.0000 - mae: 387.2201 - val_loss: 0.3605 - val_mse: 1259.2604 - val_mae: 0.3605\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8269 - mse: 35070513152.0000 - mae: 483.8270 - val_loss: 0.3608 - val_mse: 1259.2549 - val_mae: 0.3608\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4354 - mse: 1331.4111 - mae: 0.4354 - val_loss: 0.3596 - val_mse: 1259.2572 - val_mae: 0.3596\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8555 - mse: 35070509056.0000 - mae: 483.8552 - val_loss: 0.3612 - val_mse: 1259.2612 - val_mae: 0.3612\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3466 - mse: 1063.7466 - mae: 0.3466 - val_loss: 0.3634 - val_mse: 1259.2701 - val_mae: 0.3634\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3778 - mse: 926.1521 - mae: 0.3778 - val_loss: 0.3597 - val_mse: 1259.2640 - val_mae: 0.3597\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7374 - mse: 20040290304.0000 - mae: 193.7374 - val_loss: 0.3602 - val_mse: 1259.2606 - val_mae: 0.3602\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3455 - mse: 923.1447 - mae: 0.3455 - val_loss: 0.3607 - val_mse: 1259.2601 - val_mae: 0.3607\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4737 - mse: 25050365952.0000 - mae: 290.4735 - val_loss: 0.3600 - val_mse: 1259.2572 - val_mae: 0.3600\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3483 - mse: 671.2170 - mae: 0.3483 - val_loss: 0.3699 - val_mse: 1259.2809 - val_mae: 0.3699\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5477 - mse: 25050365952.0000 - mae: 290.5474 - val_loss: 0.3663 - val_mse: 1259.2631 - val_mae: 0.3663\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2260 - mse: 30060435456.0000 - mae: 387.2257 - val_loss: 0.3703 - val_mse: 1259.2655 - val_mae: 0.3703\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3120 - mse: 749.3387 - mae: 0.3120 - val_loss: 0.3624 - val_mse: 1259.2653 - val_mae: 0.3624\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3879 - mse: 1151.4453 - mae: 0.3879 - val_loss: 0.3672 - val_mse: 1259.2607 - val_mae: 0.3672\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1051 - mse: 30060435456.0000 - mae: 387.1053 - val_loss: 0.3728 - val_mse: 1259.2678 - val_mae: 0.3728\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1135 - mse: 30060435456.0000 - mae: 387.1137 - val_loss: 0.3632 - val_mse: 1259.2612 - val_mae: 0.3632\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4396 - mse: 1388.2660 - mae: 0.4396 - val_loss: 0.3666 - val_mse: 1259.2642 - val_mae: 0.3666\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5628 - mse: 40080580608.0000 - mae: 580.5630 - val_loss: 0.3639 - val_mse: 1259.2627 - val_mae: 0.3639\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3695 - mse: 1090.8982 - mae: 0.3695 - val_loss: 0.3654 - val_mse: 1259.2593 - val_mae: 0.3654\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4286 - mse: 1339.9711 - mae: 0.4286 - val_loss: 0.3611 - val_mse: 1259.2646 - val_mae: 0.3611\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8025 - mse: 35070509056.0000 - mae: 483.8037 - val_loss: 0.3625 - val_mse: 1259.2648 - val_mae: 0.3625\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3462 - mse: 886.6990 - mae: 0.3462 - val_loss: 0.3660 - val_mse: 1259.2518 - val_mae: 0.3660\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7784 - mse: 20040290304.0000 - mae: 193.7785 - val_loss: 0.3647 - val_mse: 1259.2643 - val_mae: 0.3647\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7916 - mse: 20040292352.0000 - mae: 193.7916 - val_loss: 0.3621 - val_mse: 1259.2557 - val_mae: 0.3621\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3479 - mse: 924.6617 - mae: 0.3479 - val_loss: 0.3613 - val_mse: 1259.2612 - val_mae: 0.3613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4883 - mse: 25050365952.0000 - mae: 290.4885 - val_loss: 0.3619 - val_mse: 1259.2614 - val_mae: 0.3619\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3315 - mse: 821.8398 - mae: 0.3315 - val_loss: 0.3608 - val_mse: 1259.2617 - val_mae: 0.3608\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3935 - mse: 1190.4991 - mae: 0.3935 - val_loss: 0.3598 - val_mse: 1259.2578 - val_mae: 0.3598\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3977 - mse: 25050365952.0000 - mae: 290.3977 - val_loss: 0.3619 - val_mse: 1259.2578 - val_mae: 0.3619\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3711 - mse: 1157.4955 - mae: 0.3711 - val_loss: 0.3652 - val_mse: 1259.2463 - val_mae: 0.3652\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4702 - mse: 25050365952.0000 - mae: 290.4702 - val_loss: 0.3612 - val_mse: 1259.2675 - val_mae: 0.3612\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2800 - mse: 857.3860 - mae: 0.2800 - val_loss: 0.3597 - val_mse: 1259.2544 - val_mae: 0.3597\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5057 - mse: 25050365952.0000 - mae: 290.5056 - val_loss: 0.3607 - val_mse: 1259.2368 - val_mae: 0.3607\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3044 - mse: 715.9360 - mae: 0.3044 - val_loss: 0.3623 - val_mse: 1259.2537 - val_mae: 0.3623\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8968 - mse: 35070509056.0000 - mae: 483.8969 - val_loss: 0.3603 - val_mse: 1259.2676 - val_mae: 0.3603\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2440 - mse: 30060439552.0000 - mae: 387.2440 - val_loss: 0.3607 - val_mse: 1259.2682 - val_mae: 0.3607\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2867 - mse: 632.8071 - mae: 0.2867 - val_loss: 0.3602 - val_mse: 1259.2601 - val_mae: 0.3602\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3517 - mse: 942.0482 - mae: 0.3517 - val_loss: 0.3604 - val_mse: 1259.2628 - val_mae: 0.3604\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3023 - mse: 45090656256.0000 - mae: 677.3032 - val_loss: 0.3603 - val_mse: 1259.2593 - val_mae: 0.3603\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5160 - mse: 25050365952.0000 - mae: 290.5160 - val_loss: 0.3710 - val_mse: 1259.2662 - val_mae: 0.3710\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3537 - mse: 826.0305 - mae: 0.3537 - val_loss: 0.3815 - val_mse: 1259.2643 - val_mae: 0.3815\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9101 - mse: 35070509056.0000 - mae: 483.9099 - val_loss: 0.3812 - val_mse: 1259.2675 - val_mae: 0.3812\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3878 - mse: 1068.6891 - mae: 0.3878 - val_loss: 0.3669 - val_mse: 1259.2565 - val_mae: 0.3669\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1126 - mse: 30060435456.0000 - mae: 387.1126 - val_loss: 0.3780 - val_mse: 1269.7578 - val_mae: 0.3780\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3696 - mse: 1171.7708 - mae: 0.3696 - val_loss: 0.3694 - val_mse: 1259.2673 - val_mae: 0.3694\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4058 - mse: 1140.4203 - mae: 0.4058 - val_loss: 0.3633 - val_mse: 1259.2650 - val_mae: 0.3633\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5274 - mse: 40080580608.0000 - mae: 580.5278 - val_loss: 0.3632 - val_mse: 1259.2632 - val_mae: 0.3632\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1758 - mse: 30060439552.0000 - mae: 387.1758 - val_loss: 0.3624 - val_mse: 1259.2670 - val_mae: 0.3624\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3482 - mse: 914.7530 - mae: 0.3482 - val_loss: 0.3609 - val_mse: 1259.2631 - val_mae: 0.3609\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2487 - mse: 615.7972 - mae: 0.2487 - val_loss: 0.3620 - val_mse: 1259.2561 - val_mae: 0.3620\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9386 - mse: 35070509056.0000 - mae: 483.9391 - val_loss: 0.3636 - val_mse: 1259.2592 - val_mae: 0.3636\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4330 - mse: 25050365952.0000 - mae: 290.4331 - val_loss: 0.3637 - val_mse: 1259.2535 - val_mae: 0.3637\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4056 - mse: 1184.4391 - mae: 0.4056 - val_loss: 0.3652 - val_mse: 1259.2687 - val_mae: 0.3652\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3715 - mse: 944.2048 - mae: 0.3715 - val_loss: 0.3651 - val_mse: 1259.2627 - val_mae: 0.3651\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5828 - mse: 40080584704.0000 - mae: 580.5835 - val_loss: 0.3609 - val_mse: 1259.2611 - val_mae: 0.3609\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7421 - mse: 20040292352.0000 - mae: 193.7422 - val_loss: 0.3624 - val_mse: 1259.2509 - val_mae: 0.3624\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3611 - mse: 1035.7344 - mae: 0.3611 - val_loss: 0.3616 - val_mse: 1259.2614 - val_mae: 0.3616\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3152 - mse: 611.0121 - mae: 0.3152 - val_loss: 0.3606 - val_mse: 1259.2627 - val_mae: 0.3606\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2285 - mse: 30060435456.0000 - mae: 387.2284 - val_loss: 0.3620 - val_mse: 1259.2638 - val_mae: 0.3620\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3509 - mse: 885.3224 - mae: 0.3509 - val_loss: 0.3638 - val_mse: 1259.2578 - val_mae: 0.3638\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5466 - mse: 25050363904.0000 - mae: 290.5464 - val_loss: 0.3605 - val_mse: 1259.2629 - val_mae: 0.3605\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3641 - mse: 1002.8936 - mae: 0.3641 - val_loss: 0.3633 - val_mse: 1259.2548 - val_mae: 0.3633\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4715 - mse: 25050365952.0000 - mae: 290.4715 - val_loss: 0.3617 - val_mse: 1259.2552 - val_mae: 0.3617\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3669 - mse: 965.6967 - mae: 0.3669 - val_loss: 0.3659 - val_mse: 1259.2657 - val_mae: 0.3659\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4093 - mse: 25050363904.0000 - mae: 290.4092 - val_loss: 0.3623 - val_mse: 1259.2620 - val_mae: 0.3623\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1937 - mse: 30060435456.0000 - mae: 387.1938 - val_loss: 0.3599 - val_mse: 1259.2545 - val_mae: 0.3599\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2881 - mse: 644.3435 - mae: 0.2881 - val_loss: 0.3655 - val_mse: 1259.2594 - val_mae: 0.3655\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2981 - mse: 739.7661 - mae: 0.2981 - val_loss: 0.3598 - val_mse: 1259.2655 - val_mae: 0.3598\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4678 - mse: 25050363904.0000 - mae: 290.4675 - val_loss: 0.3609 - val_mse: 1259.2711 - val_mae: 0.3609\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3568 - mse: 810.7488 - mae: 0.3568 - val_loss: 0.3665 - val_mse: 1259.2678 - val_mae: 0.3665\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2687 - mse: 30060435456.0000 - mae: 387.2686 - val_loss: 0.3676 - val_mse: 1259.2626 - val_mae: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3190 - mse: 874.7178 - mae: 0.3190 - val_loss: 0.3656 - val_mse: 1259.2657 - val_mae: 0.3656\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4864 - mse: 25050365952.0000 - mae: 290.4866 - val_loss: 0.3764 - val_mse: 1259.2648 - val_mae: 0.3764\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4330 - mse: 25050363904.0000 - mae: 290.4326 - val_loss: 0.3648 - val_mse: 1259.2601 - val_mae: 0.3648\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3809 - mse: 1183.3646 - mae: 0.3809 - val_loss: 0.3663 - val_mse: 1259.2607 - val_mae: 0.3663\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6014 - mse: 40080580608.0000 - mae: 580.6014 - val_loss: 0.3619 - val_mse: 1259.2676 - val_mae: 0.3619\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3614 - mse: 1097.0166 - mae: 0.3614 - val_loss: 0.3629 - val_mse: 1259.2618 - val_mae: 0.3629\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.3080 - mse: 30060435456.0000 - mae: 387.3079 - val_loss: 0.3637 - val_mse: 1259.2605 - val_mae: 0.3637\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3024 - mse: 716.8394 - mae: 0.3024 - val_loss: 0.3670 - val_mse: 1259.2629 - val_mae: 0.3670\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 773.9238 - mse: 50100727808.0000 - mae: 773.9254 - val_loss: 0.3652 - val_mse: 1259.2650 - val_mae: 0.3652\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4788 - mse: 1453.2844 - mae: 0.4788 - val_loss: 0.3667 - val_mse: 1259.2610 - val_mae: 0.3667\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8349 - mse: 20040292352.0000 - mae: 193.8350 - val_loss: 0.3630 - val_mse: 1259.2625 - val_mae: 0.3630\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2615 - mse: 535.0854 - mae: 0.2615 - val_loss: 0.3635 - val_mse: 1259.2748 - val_mae: 0.3635\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4685 - mse: 1399.1870 - mae: 0.4685 - val_loss: 0.3655 - val_mse: 1259.2638 - val_mae: 0.3655\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5010 - mse: 40080580608.0000 - mae: 580.5018 - val_loss: 0.3608 - val_mse: 1259.2581 - val_mae: 0.3608\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8452 - mse: 35070513152.0000 - mae: 483.8461 - val_loss: 0.3603 - val_mse: 1259.2655 - val_mae: 0.3603\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3563 - mse: 1036.1975 - mae: 0.3563 - val_loss: 0.3636 - val_mse: 1259.2593 - val_mae: 0.3636\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3422 - mse: 845.4117 - mae: 0.3422 - val_loss: 0.3609 - val_mse: 1259.2599 - val_mae: 0.3609\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.8265 - mse: 20040290304.0000 - mae: 193.8266 - val_loss: 0.3643 - val_mse: 1259.2500 - val_mae: 0.3643\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3310 - mse: 874.0334 - mae: 0.3310 - val_loss: 0.3627 - val_mse: 1259.2622 - val_mae: 0.3627\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8222 - mse: 35070513152.0000 - mae: 483.8226 - val_loss: 0.3622 - val_mse: 1259.2595 - val_mae: 0.3622\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3267 - mse: 873.3839 - mae: 0.3267 - val_loss: 0.3609 - val_mse: 1259.2634 - val_mae: 0.3609\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7670 - mse: 20040292352.0000 - mae: 193.7670 - val_loss: 0.3599 - val_mse: 1259.2605 - val_mae: 0.3599\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3866 - mse: 1037.9291 - mae: 0.3866 - val_loss: 0.3593 - val_mse: 1259.2552 - val_mae: 0.3593\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4617 - mse: 25050365952.0000 - mae: 290.4616 - val_loss: 0.3618 - val_mse: 1259.2638 - val_mae: 0.3618\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3094 - mse: 819.1417 - mae: 0.3094 - val_loss: 0.3598 - val_mse: 1259.2561 - val_mae: 0.3598\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3123 - mse: 45090656256.0000 - mae: 677.3128 - val_loss: 0.3615 - val_mse: 1259.2560 - val_mae: 0.3615\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7239 - mse: 20040292352.0000 - mae: 193.7239 - val_loss: 0.3633 - val_mse: 1259.2522 - val_mae: 0.3633\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3611 - mse: 1167.5964 - mae: 0.3611 - val_loss: 0.3613 - val_mse: 1259.2599 - val_mae: 0.3613\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4511 - mse: 1232.8582 - mae: 0.4511 - val_loss: 0.3754 - val_mse: 1259.2773 - val_mae: 0.3754\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4140 - mse: 25050363904.0000 - mae: 290.4141 - val_loss: 0.3691 - val_mse: 1259.2551 - val_mae: 0.3691\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7932 - mse: 20040290304.0000 - mae: 193.7931 - val_loss: 0.3753 - val_mse: 1259.2687 - val_mae: 0.3753\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3287 - mse: 715.0685 - mae: 0.3287 - val_loss: 0.3657 - val_mse: 1259.2655 - val_mae: 0.3657\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3968 - mse: 1232.6179 - mae: 0.3968 - val_loss: 0.3684 - val_mse: 1259.2683 - val_mae: 0.3684\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5053 - mse: 40080580608.0000 - mae: 580.5052 - val_loss: 0.3647 - val_mse: 1259.2638 - val_mae: 0.3647\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3687 - mse: 1023.8792 - mae: 0.3687 - val_loss: 0.3711 - val_mse: 1259.2671 - val_mae: 0.3711\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9107 - mse: 35070509056.0000 - mae: 483.9109 - val_loss: 0.3631 - val_mse: 1259.2667 - val_mae: 0.3631\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3797 - mse: 1113.4832 - mae: 0.3797 - val_loss: 0.3685 - val_mse: 1259.2646 - val_mae: 0.3685\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5757 - mse: 40080580608.0000 - mae: 580.5768 - val_loss: 0.3666 - val_mse: 1259.2600 - val_mae: 0.3666\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3430 - mse: 991.8111 - mae: 0.3430 - val_loss: 0.3647 - val_mse: 1259.2670 - val_mae: 0.3647\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9005 - mse: 35070513152.0000 - mae: 483.9005 - val_loss: 0.3627 - val_mse: 1259.2552 - val_mae: 0.3627\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3310 - mse: 951.8340 - mae: 0.3310 - val_loss: 0.3649 - val_mse: 1259.2567 - val_mae: 0.3649\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4768 - mse: 25050365952.0000 - mae: 290.4768 - val_loss: 0.3616 - val_mse: 1259.2646 - val_mae: 0.3616\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3909 - mse: 1057.3622 - mae: 0.3909 - val_loss: 0.3608 - val_mse: 1259.2623 - val_mae: 0.3608\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 677.3247 - mse: 45090652160.0000 - mae: 677.3251 - val_loss: 0.3647 - val_mse: 1259.2659 - val_mae: 0.3647\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7067 - mse: 20040290304.0000 - mae: 193.7068 - val_loss: 0.3660 - val_mse: 1259.2616 - val_mae: 0.3660\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4499 - mse: 1339.4281 - mae: 0.4499 - val_loss: 0.3633 - val_mse: 1259.2604 - val_mae: 0.3633\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3175 - mse: 798.2923 - mae: 0.3175 - val_loss: 0.3609 - val_mse: 1259.2623 - val_mae: 0.3609\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8750 - mse: 35070509056.0000 - mae: 483.8754 - val_loss: 0.3604 - val_mse: 1259.2614 - val_mae: 0.3604\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5956 - mse: 25050363904.0000 - mae: 290.5958 - val_loss: 0.3604 - val_mse: 1259.2650 - val_mae: 0.3604\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2446 - mse: 438.5642 - mae: 0.2446 - val_loss: 0.3617 - val_mse: 1259.2744 - val_mae: 0.3617\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8045 - mse: 35070509056.0000 - mae: 483.8045 - val_loss: 0.3600 - val_mse: 1259.2607 - val_mae: 0.3600\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4100 - mse: 1249.4619 - mae: 0.4100 - val_loss: 0.3611 - val_mse: 1259.2612 - val_mae: 0.3611\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3084 - mse: 854.6510 - mae: 0.3084 - val_loss: 0.3604 - val_mse: 1259.2611 - val_mae: 0.3604\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1597 - mse: 30060435456.0000 - mae: 387.1595 - val_loss: 0.3600 - val_mse: 1259.2588 - val_mae: 0.3600\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4903 - mse: 25050365952.0000 - mae: 290.4905 - val_loss: 0.3601 - val_mse: 1259.2676 - val_mae: 0.3601\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3207 - mse: 851.3218 - mae: 0.3207 - val_loss: 0.3640 - val_mse: 1259.2595 - val_mae: 0.3640\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3798 - mse: 1129.1775 - mae: 0.3798 - val_loss: 0.3604 - val_mse: 1259.2655 - val_mae: 0.3604\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5625 - mse: 40080580608.0000 - mae: 580.5626 - val_loss: 0.3621 - val_mse: 1259.2611 - val_mae: 0.3621\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4878 - mse: 1478.8519 - mae: 0.4878 - val_loss: 0.3863 - val_mse: 1387.0942 - val_mae: 0.3863\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1348 - mse: 30060435456.0000 - mae: 387.1348 - val_loss: 0.3666 - val_mse: 1259.2700 - val_mae: 0.3666\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3823 - mse: 994.4796 - mae: 0.3823 - val_loss: 0.3656 - val_mse: 1259.2649 - val_mae: 0.3656\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5835 - mse: 40080580608.0000 - mae: 580.5850 - val_loss: 0.3646 - val_mse: 1259.2606 - val_mae: 0.3646\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5426 - mse: 25050365952.0000 - mae: 290.5422 - val_loss: 0.3655 - val_mse: 1259.2656 - val_mae: 0.3655\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3692 - mse: 909.3759 - mae: 0.3692 - val_loss: 0.3746 - val_mse: 1259.2673 - val_mae: 0.3746\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8151 - mse: 35070509056.0000 - mae: 483.8158 - val_loss: 0.3698 - val_mse: 1259.2581 - val_mae: 0.3698\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4236 - mse: 1302.0253 - mae: 0.4236 - val_loss: 0.3657 - val_mse: 1259.2612 - val_mae: 0.3657\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4114 - mse: 1181.1440 - mae: 0.4114 - val_loss: 0.3709 - val_mse: 1259.2607 - val_mae: 0.3709\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1499 - mse: 30060435456.0000 - mae: 387.1498 - val_loss: 0.3632 - val_mse: 1259.2653 - val_mae: 0.3632\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6028 - mse: 40080580608.0000 - mae: 580.6034 - val_loss: 0.3684 - val_mse: 1259.2681 - val_mae: 0.3684\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3479 - mse: 765.8046 - mae: 0.3479 - val_loss: 0.3626 - val_mse: 1259.2626 - val_mae: 0.3626\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3581 - mse: 1062.2886 - mae: 0.3581 - val_loss: 0.3690 - val_mse: 1259.2653 - val_mae: 0.3690\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8700 - mse: 35070513152.0000 - mae: 483.8705 - val_loss: 0.3690 - val_mse: 1259.2638 - val_mae: 0.3690\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4892 - mse: 25050363904.0000 - mae: 290.4895 - val_loss: 0.3720 - val_mse: 1259.2635 - val_mae: 0.3720\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2830 - mse: 677.3639 - mae: 0.2830 - val_loss: 0.3637 - val_mse: 1259.2627 - val_mae: 0.3637\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3254 - mse: 747.3479 - mae: 0.3254 - val_loss: 0.3644 - val_mse: 1259.2577 - val_mae: 0.3644\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9310 - mse: 35070513152.0000 - mae: 483.9311 - val_loss: 0.3595 - val_mse: 1259.2566 - val_mae: 0.3595\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6281 - mse: 40080580608.0000 - mae: 580.6286 - val_loss: 0.3622 - val_mse: 1259.2673 - val_mae: 0.3622\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3438 - mse: 983.7903 - mae: 0.3438 - val_loss: 0.3654 - val_mse: 1259.2728 - val_mae: 0.3654\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7879 - mse: 20040294400.0000 - mae: 193.7878 - val_loss: 0.3633 - val_mse: 1259.2561 - val_mae: 0.3633\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3217 - mse: 819.6428 - mae: 0.3217 - val_loss: 0.3613 - val_mse: 1259.2614 - val_mae: 0.3613\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3942 - mse: 1308.7452 - mae: 0.3942 - val_loss: 0.3623 - val_mse: 1259.2595 - val_mae: 0.3623\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4065 - mse: 25050365952.0000 - mae: 290.4064 - val_loss: 0.3619 - val_mse: 1259.2578 - val_mae: 0.3619\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3734 - mse: 1040.3792 - mae: 0.3734 - val_loss: 0.3607 - val_mse: 1259.2570 - val_mae: 0.3607\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 967.3986 - mse: 60120870912.0000 - mae: 967.3904 - val_loss: 0.3613 - val_mse: 1259.2671 - val_mae: 0.3613\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2177 - mse: 30060439552.0000 - mae: 387.2174 - val_loss: 0.3637 - val_mse: 1259.2471 - val_mae: 0.3637\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3150 - mse: 915.6465 - mae: 0.3150 - val_loss: 0.3606 - val_mse: 1259.2552 - val_mae: 0.3606\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2038 - mse: 30060435456.0000 - mae: 387.2037 - val_loss: 0.3603 - val_mse: 1259.2603 - val_mae: 0.3603\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3703 - mse: 1119.1400 - mae: 0.3703 - val_loss: 0.3605 - val_mse: 1259.2635 - val_mae: 0.3605\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3279 - mse: 803.3710 - mae: 0.3279 - val_loss: 0.3865 - val_mse: 1259.2666 - val_mae: 0.3865\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9251 - mse: 35070509056.0000 - mae: 483.9256 - val_loss: 0.3661 - val_mse: 1259.2640 - val_mae: 0.3661\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3318 - mse: 896.8804 - mae: 0.3318 - val_loss: 0.3659 - val_mse: 1259.2665 - val_mae: 0.3659\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8227 - mse: 20040290304.0000 - mae: 193.8228 - val_loss: 0.3717 - val_mse: 1259.2622 - val_mae: 0.3717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4222 - mse: 1181.1534 - mae: 0.4222 - val_loss: 0.3654 - val_mse: 1259.2673 - val_mae: 0.3654\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7518 - mse: 20040290304.0000 - mae: 193.7518 - val_loss: 0.3694 - val_mse: 1259.2661 - val_mae: 0.3694\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3382 - mse: 910.7788 - mae: 0.3382 - val_loss: 0.3651 - val_mse: 1259.2612 - val_mae: 0.3651\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8758 - mse: 35070509056.0000 - mae: 483.8758 - val_loss: 0.3682 - val_mse: 1259.2598 - val_mae: 0.3682\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3791 - mse: 25050363904.0000 - mae: 290.3790 - val_loss: 0.3640 - val_mse: 1259.2676 - val_mae: 0.3640\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3980 - mse: 1270.8134 - mae: 0.3980 - val_loss: 0.3622 - val_mse: 1259.2676 - val_mae: 0.3622\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3420 - mse: 870.4850 - mae: 0.3420 - val_loss: 0.3741 - val_mse: 1259.2670 - val_mae: 0.3741\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4830 - mse: 25050363904.0000 - mae: 290.4829 - val_loss: 0.3615 - val_mse: 1259.2704 - val_mae: 0.3615\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2942 - mse: 692.8892 - mae: 0.2942 - val_loss: 0.3637 - val_mse: 1259.2552 - val_mae: 0.3637\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5213 - mse: 25050365952.0000 - mae: 290.5213 - val_loss: 0.3649 - val_mse: 1259.2646 - val_mae: 0.3649\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3214 - mse: 877.0472 - mae: 0.3214 - val_loss: 0.3613 - val_mse: 1259.2601 - val_mae: 0.3613\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8643 - mse: 20040292352.0000 - mae: 193.8642 - val_loss: 0.3657 - val_mse: 1259.2579 - val_mae: 0.3657\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4488 - mse: 1376.5139 - mae: 0.4488 - val_loss: 0.3645 - val_mse: 1259.2538 - val_mae: 0.3645\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8136 - mse: 35070509056.0000 - mae: 483.8143 - val_loss: 0.3616 - val_mse: 1259.2578 - val_mae: 0.3616\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4077 - mse: 1393.7084 - mae: 0.4077 - val_loss: 0.3615 - val_mse: 1259.2570 - val_mae: 0.3615\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3786 - mse: 25050363904.0000 - mae: 290.3788 - val_loss: 0.3627 - val_mse: 1259.2533 - val_mae: 0.3627\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3098 - mse: 839.2162 - mae: 0.3098 - val_loss: 0.3638 - val_mse: 1259.2544 - val_mae: 0.3638\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5964 - mse: 40080580608.0000 - mae: 580.5967 - val_loss: 0.3612 - val_mse: 1259.2568 - val_mae: 0.3612\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3461 - mse: 962.6855 - mae: 0.3461 - val_loss: 0.3597 - val_mse: 1259.2596 - val_mae: 0.3597\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4538 - mse: 25050363904.0000 - mae: 290.4539 - val_loss: 0.3630 - val_mse: 1259.2657 - val_mae: 0.3630\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3459 - mse: 968.5754 - mae: 0.3459 - val_loss: 0.3635 - val_mse: 1259.2513 - val_mae: 0.3635\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7304 - mse: 20040292352.0000 - mae: 193.7304 - val_loss: 0.3649 - val_mse: 1259.2518 - val_mae: 0.3649\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5174 - mse: 25050363904.0000 - mae: 290.5173 - val_loss: 0.3608 - val_mse: 1259.2600 - val_mae: 0.3608\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2825 - mse: 736.2430 - mae: 0.2825 - val_loss: 0.3636 - val_mse: 1259.2548 - val_mae: 0.3636\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.7937 - mse: 35070509056.0000 - mae: 483.7935 - val_loss: 0.3616 - val_mse: 1259.2625 - val_mae: 0.3616\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3931 - mse: 1293.1792 - mae: 0.3931 - val_loss: 0.3648 - val_mse: 1259.2655 - val_mae: 0.3648\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4381 - mse: 1211.2896 - mae: 0.4381 - val_loss: 0.3758 - val_mse: 1259.2721 - val_mae: 0.3758\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4689 - mse: 25050363904.0000 - mae: 290.4690 - val_loss: 0.3784 - val_mse: 1259.2687 - val_mae: 0.3784\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5090 - mse: 25050363904.0000 - mae: 290.5090 - val_loss: 0.3662 - val_mse: 1259.2667 - val_mae: 0.3662\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2986 - mse: 710.6562 - mae: 0.2986 - val_loss: 0.3652 - val_mse: 1259.2659 - val_mae: 0.3652\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2923 - mse: 574.4533 - mae: 0.2923 - val_loss: 0.3662 - val_mse: 1259.2666 - val_mae: 0.3662\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9874 - mse: 35070509056.0000 - mae: 483.9887 - val_loss: 0.3653 - val_mse: 1259.2612 - val_mae: 0.3653\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4087 - mse: 1302.8423 - mae: 0.4087 - val_loss: 0.3757 - val_mse: 1283.5281 - val_mae: 0.3757\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.6953 - mse: 20040292352.0000 - mae: 193.6953 - val_loss: 0.3642 - val_mse: 1259.2603 - val_mae: 0.3642\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3890 - mse: 1142.4221 - mae: 0.3890 - val_loss: 0.3645 - val_mse: 1259.2648 - val_mae: 0.3645\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8762 - mse: 35070509056.0000 - mae: 483.8763 - val_loss: 0.3690 - val_mse: 1259.2729 - val_mae: 0.3690\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1579 - mse: 30060435456.0000 - mae: 387.1579 - val_loss: 0.3621 - val_mse: 1259.2617 - val_mae: 0.3621\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3829 - mse: 1082.7129 - mae: 0.3829 - val_loss: 0.3613 - val_mse: 1259.2744 - val_mae: 0.3613\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3136 - mse: 718.3494 - mae: 0.3136 - val_loss: 0.3616 - val_mse: 1259.2593 - val_mae: 0.3616\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8191 - mse: 20040292352.0000 - mae: 193.8190 - val_loss: 0.3610 - val_mse: 1259.2664 - val_mae: 0.3610\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3560 - mse: 970.5886 - mae: 0.3560 - val_loss: 0.3626 - val_mse: 1259.2607 - val_mae: 0.3626\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1687 - mse: 30060435456.0000 - mae: 387.1688 - val_loss: 0.3686 - val_mse: 1259.2672 - val_mae: 0.3686\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1620 - mse: 30060435456.0000 - mae: 387.1620 - val_loss: 0.3618 - val_mse: 1259.2600 - val_mae: 0.3618\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3811 - mse: 977.2159 - mae: 0.3811 - val_loss: 0.3599 - val_mse: 1259.2584 - val_mae: 0.3599\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8664 - mse: 35070509056.0000 - mae: 483.8670 - val_loss: 0.3639 - val_mse: 1259.2583 - val_mae: 0.3639\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3560 - mse: 1117.5514 - mae: 0.3560 - val_loss: 0.3632 - val_mse: 1259.2621 - val_mae: 0.3632\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 11ms/step - loss: 580.5318 - mse: 40080580608.0000 - mae: 580.5318 - val_loss: 0.3605 - val_mse: 1259.2712 - val_mae: 0.3605\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4243 - mse: 1278.9781 - mae: 0.4243 - val_loss: 0.3661 - val_mse: 1259.2552 - val_mae: 0.3661\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3946 - mse: 1169.5483 - mae: 0.3946 - val_loss: 0.3615 - val_mse: 1259.2639 - val_mae: 0.3615\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4501 - mse: 25050363904.0000 - mae: 290.4501 - val_loss: 0.3627 - val_mse: 1259.2603 - val_mae: 0.3627\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3451 - mse: 850.8871 - mae: 0.3451 - val_loss: 0.3614 - val_mse: 1259.2681 - val_mae: 0.3614\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9069 - mse: 35070509056.0000 - mae: 483.9071 - val_loss: 0.3626 - val_mse: 1259.2610 - val_mae: 0.3626\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5046 - mse: 25050365952.0000 - mae: 290.5046 - val_loss: 0.3596 - val_mse: 1259.2584 - val_mae: 0.3596\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3264 - mse: 812.3755 - mae: 0.3264 - val_loss: 0.3610 - val_mse: 1259.2806 - val_mae: 0.3610\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4717 - mse: 25050363904.0000 - mae: 290.4719 - val_loss: 0.3664 - val_mse: 1259.2494 - val_mae: 0.3664\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2617 - mse: 618.2737 - mae: 0.2617 - val_loss: 0.3606 - val_mse: 1259.2621 - val_mae: 0.3606\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3825 - mse: 857.9013 - mae: 0.3825 - val_loss: 0.3730 - val_mse: 1259.2614 - val_mae: 0.3730\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7822 - mse: 20040294400.0000 - mae: 193.7822 - val_loss: 0.3670 - val_mse: 1259.2664 - val_mae: 0.3670\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3305 - mse: 829.3133 - mae: 0.3305 - val_loss: 0.3767 - val_mse: 1259.2601 - val_mae: 0.3767\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4881 - mse: 25050363904.0000 - mae: 290.4879 - val_loss: 0.3691 - val_mse: 1259.2581 - val_mae: 0.3691\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9013 - mse: 35070509056.0000 - mae: 483.9024 - val_loss: 0.3654 - val_mse: 1259.2609 - val_mae: 0.3654\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3591 - mse: 1011.4412 - mae: 0.3591 - val_loss: 0.3622 - val_mse: 1259.2545 - val_mae: 0.3622\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2676 - mse: 568.4865 - mae: 0.2676 - val_loss: 0.3672 - val_mse: 1259.2659 - val_mae: 0.3672\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6128 - mse: 40080580608.0000 - mae: 580.6136 - val_loss: 0.3628 - val_mse: 1259.2631 - val_mae: 0.3628\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4229 - mse: 1213.1008 - mae: 0.4229 - val_loss: 0.3631 - val_mse: 1259.2665 - val_mae: 0.3631\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5525 - mse: 40080580608.0000 - mae: 580.5533 - val_loss: 0.3613 - val_mse: 1259.2610 - val_mae: 0.3613\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3191 - mse: 757.1416 - mae: 0.3191 - val_loss: 0.3627 - val_mse: 1259.2655 - val_mae: 0.3627\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7737 - mse: 20040292352.0000 - mae: 193.7737 - val_loss: 0.3686 - val_mse: 1259.2629 - val_mae: 0.3686\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1546 - mse: 30060435456.0000 - mae: 387.1547 - val_loss: 0.3610 - val_mse: 1259.2632 - val_mae: 0.3610\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3515 - mse: 974.5680 - mae: 0.3515 - val_loss: 0.3616 - val_mse: 1259.2689 - val_mae: 0.3616\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3660 - mse: 1077.9943 - mae: 0.3660 - val_loss: 0.3693 - val_mse: 1259.2592 - val_mae: 0.3693\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4657 - mse: 25050363904.0000 - mae: 290.4655 - val_loss: 0.3718 - val_mse: 1259.2653 - val_mae: 0.3718\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4664 - mse: 25050365952.0000 - mae: 290.4664 - val_loss: 0.3634 - val_mse: 1259.2703 - val_mae: 0.3634\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3679 - mse: 1125.4725 - mae: 0.3679 - val_loss: 0.3595 - val_mse: 1259.2701 - val_mae: 0.3595\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4270 - mse: 1331.2031 - mae: 0.4270 - val_loss: 0.3599 - val_mse: 1259.2542 - val_mae: 0.3599\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7786 - mse: 35070513152.0000 - mae: 483.7788 - val_loss: 0.3636 - val_mse: 1259.2563 - val_mae: 0.3636\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3271 - mse: 887.1082 - mae: 0.3271 - val_loss: 0.3596 - val_mse: 1259.2599 - val_mae: 0.3596\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5271 - mse: 25050365952.0000 - mae: 290.5272 - val_loss: 0.3605 - val_mse: 1259.2701 - val_mae: 0.3605\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5741 - mse: 25050365952.0000 - mae: 290.5741 - val_loss: 0.3654 - val_mse: 1259.2570 - val_mae: 0.3654\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2631 - mse: 525.1636 - mae: 0.2631 - val_loss: 0.3621 - val_mse: 1259.2587 - val_mae: 0.3621\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2777 - mse: 673.3025 - mae: 0.2777 - val_loss: 0.3604 - val_mse: 1259.2667 - val_mae: 0.3604\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4925 - mse: 25050363904.0000 - mae: 290.4926 - val_loss: 0.3611 - val_mse: 1259.2698 - val_mae: 0.3611\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4397 - mse: 1388.0454 - mae: 0.4397 - val_loss: 0.3598 - val_mse: 1259.2545 - val_mae: 0.3598\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0696 - mse: 30060435456.0000 - mae: 387.0694 - val_loss: 0.3616 - val_mse: 1259.2653 - val_mae: 0.3616\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3791 - mse: 1175.3270 - mae: 0.3791 - val_loss: 0.3594 - val_mse: 1259.2622 - val_mae: 0.3594\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4530 - mse: 25050363904.0000 - mae: 290.4531 - val_loss: 0.3597 - val_mse: 1259.2595 - val_mae: 0.3597\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.4414 - mse: 1193.9343 - mae: 0.4414 - val_loss: 0.3685 - val_mse: 1259.2723 - val_mae: 0.3685\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4237 - mse: 25050365952.0000 - mae: 290.4235 - val_loss: 0.3743 - val_mse: 1259.2694 - val_mae: 0.3743\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3564 - mse: 924.7026 - mae: 0.3564 - val_loss: 0.3740 - val_mse: 1259.2639 - val_mae: 0.3740\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1754 - mse: 30060435456.0000 - mae: 387.1753 - val_loss: 0.3632 - val_mse: 1259.2646 - val_mae: 0.3632\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5053 - mse: 40080584704.0000 - mae: 580.5060 - val_loss: 0.3859 - val_mse: 1259.2635 - val_mae: 0.3859\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3772 - mse: 1107.1057 - mae: 0.3772 - val_loss: 0.3640 - val_mse: 1259.2672 - val_mae: 0.3640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4331 - mse: 1306.9413 - mae: 0.4331 - val_loss: 0.3624 - val_mse: 1259.2656 - val_mae: 0.3624\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1106 - mse: 30060439552.0000 - mae: 387.1104 - val_loss: 0.3668 - val_mse: 1259.2646 - val_mae: 0.3668\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1698 - mse: 30060439552.0000 - mae: 387.1698 - val_loss: 0.3617 - val_mse: 1259.2616 - val_mae: 0.3617\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3367 - mse: 973.2290 - mae: 0.3367 - val_loss: 0.3643 - val_mse: 1259.2654 - val_mae: 0.3643\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.0878 - mse: 30060435456.0000 - mae: 387.0878 - val_loss: 0.3684 - val_mse: 1259.2605 - val_mae: 0.3684\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4687 - mse: 1488.7454 - mae: 0.4687 - val_loss: 0.3646 - val_mse: 1259.2639 - val_mae: 0.3646\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3473 - mse: 1050.1530 - mae: 0.3473 - val_loss: 0.3655 - val_mse: 1259.2567 - val_mae: 0.3655\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2314 - mse: 30060435456.0000 - mae: 387.2314 - val_loss: 0.3614 - val_mse: 1259.2533 - val_mae: 0.3614\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4107 - mse: 1166.6257 - mae: 0.4107 - val_loss: 0.3655 - val_mse: 1259.2538 - val_mae: 0.3655\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1567 - mse: 30060435456.0000 - mae: 387.1567 - val_loss: 0.3616 - val_mse: 1259.2627 - val_mae: 0.3616\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8693 - mse: 35070509056.0000 - mae: 483.8691 - val_loss: 0.3652 - val_mse: 1259.2552 - val_mae: 0.3652\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3416 - mse: 945.5486 - mae: 0.3416 - val_loss: 0.3652 - val_mse: 1259.2588 - val_mae: 0.3652\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2524 - mse: 576.2159 - mae: 0.2524 - val_loss: 0.3598 - val_mse: 1259.2660 - val_mae: 0.3598\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2232 - mse: 30060435456.0000 - mae: 387.2235 - val_loss: 0.3608 - val_mse: 1259.2548 - val_mae: 0.3608\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7558 - mse: 20040292352.0000 - mae: 193.7557 - val_loss: 0.3655 - val_mse: 1259.2598 - val_mae: 0.3655\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3944 - mse: 1209.4055 - mae: 0.3944 - val_loss: 0.3647 - val_mse: 1259.2595 - val_mae: 0.3647\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8551 - mse: 35070513152.0000 - mae: 483.8552 - val_loss: 0.3606 - val_mse: 1259.2714 - val_mae: 0.3606\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2999 - mse: 835.0356 - mae: 0.2999 - val_loss: 0.3650 - val_mse: 1259.2618 - val_mae: 0.3650\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4527 - mse: 25050365952.0000 - mae: 290.4528 - val_loss: 0.3609 - val_mse: 1259.2651 - val_mae: 0.3609\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3904 - mse: 1145.9711 - mae: 0.3904 - val_loss: 0.3651 - val_mse: 1259.2629 - val_mae: 0.3651\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7276 - mse: 20040292352.0000 - mae: 193.7275 - val_loss: 0.3599 - val_mse: 1259.2676 - val_mae: 0.3599\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3618 - mse: 1000.3361 - mae: 0.3618 - val_loss: 0.3616 - val_mse: 1259.2621 - val_mae: 0.3616\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3295 - mse: 829.6041 - mae: 0.3295 - val_loss: 0.3628 - val_mse: 1259.2390 - val_mae: 0.3628\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2119 - mse: 30060435456.0000 - mae: 387.2115 - val_loss: 0.3665 - val_mse: 1259.2600 - val_mae: 0.3665\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 11s 16ms/step - loss: 290.4962 - mse: 25050363904.0000 - mae: 290.4963 - val_loss: 0.3693 - val_mse: 1259.2618 - val_mae: 0.3693\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3311 - mse: 891.4069 - mae: 0.3311 - val_loss: 0.3661 - val_mse: 1259.2648 - val_mae: 0.3661\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7954 - mse: 20040290304.0000 - mae: 193.7953 - val_loss: 0.4095 - val_mse: 1259.2802 - val_mae: 0.4095\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3227 - mse: 855.0031 - mae: 0.3227 - val_loss: 0.3737 - val_mse: 1259.2537 - val_mae: 0.3737\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3145 - mse: 45090656256.0000 - mae: 677.3151 - val_loss: 0.3639 - val_mse: 1259.2646 - val_mae: 0.3639\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3422 - mse: 801.3632 - mae: 0.3422 - val_loss: 0.3657 - val_mse: 1259.2631 - val_mae: 0.3657\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3123 - mse: 797.7304 - mae: 0.3123 - val_loss: 0.3740 - val_mse: 1259.2689 - val_mae: 0.3740\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8744 - mse: 35070509056.0000 - mae: 483.8749 - val_loss: 0.3682 - val_mse: 1259.2600 - val_mae: 0.3682\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9197 - mse: 35070513152.0000 - mae: 483.9201 - val_loss: 0.3689 - val_mse: 1259.2583 - val_mae: 0.3689\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3456 - mse: 876.9249 - mae: 0.3456 - val_loss: 0.3646 - val_mse: 1259.2670 - val_mae: 0.3646\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1586 - mse: 30060435456.0000 - mae: 387.1588 - val_loss: 0.3703 - val_mse: 1259.2703 - val_mae: 0.3703\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3961 - mse: 1293.8206 - mae: 0.3961 - val_loss: 0.3626 - val_mse: 1259.2628 - val_mae: 0.3626\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5137 - mse: 40080584704.0000 - mae: 580.5139 - val_loss: 0.3671 - val_mse: 1259.2739 - val_mae: 0.3671\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4046 - mse: 1292.6420 - mae: 0.4046 - val_loss: 0.3631 - val_mse: 1259.2546 - val_mae: 0.3631\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4217 - mse: 1224.1854 - mae: 0.4217 - val_loss: 0.3634 - val_mse: 1259.2618 - val_mae: 0.3634\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1086 - mse: 30060435456.0000 - mae: 387.1088 - val_loss: 0.3621 - val_mse: 1259.2706 - val_mae: 0.3621\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1033 - mse: 30060435456.0000 - mae: 387.1035 - val_loss: 0.3624 - val_mse: 1259.2665 - val_mae: 0.3624\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4444 - mse: 1173.6809 - mae: 0.4444 - val_loss: 0.3633 - val_mse: 1259.2599 - val_mae: 0.3633\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9571 - mse: 35070509056.0000 - mae: 483.9572 - val_loss: 0.3662 - val_mse: 1259.2638 - val_mae: 0.3662\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3090 - mse: 758.3457 - mae: 0.3090 - val_loss: 0.3618 - val_mse: 1259.2706 - val_mae: 0.3618\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3559 - mse: 961.0238 - mae: 0.3559 - val_loss: 0.3622 - val_mse: 1259.2635 - val_mae: 0.3622\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4659 - mse: 25050363904.0000 - mae: 290.4660 - val_loss: 0.3640 - val_mse: 1259.2638 - val_mae: 0.3640\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3729 - mse: 1044.1765 - mae: 0.3729 - val_loss: 0.3643 - val_mse: 1259.2639 - val_mae: 0.3643\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9036 - mse: 35070513152.0000 - mae: 483.9040 - val_loss: 0.3622 - val_mse: 1259.2633 - val_mae: 0.3622\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8832 - mse: 35070509056.0000 - mae: 483.8839 - val_loss: 0.3597 - val_mse: 1259.2681 - val_mae: 0.3597\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2986 - mse: 755.2435 - mae: 0.2986 - val_loss: 0.3608 - val_mse: 1259.2539 - val_mae: 0.3608\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4629 - mse: 25050365952.0000 - mae: 290.4629 - val_loss: 0.3629 - val_mse: 1259.2603 - val_mae: 0.3629\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3833 - mse: 1125.4956 - mae: 0.3833 - val_loss: 0.3662 - val_mse: 1259.2588 - val_mae: 0.3662\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2420 - mse: 571.1183 - mae: 0.2420 - val_loss: 0.3603 - val_mse: 1259.2548 - val_mae: 0.3603\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2595 - mse: 30060435456.0000 - mae: 387.2594 - val_loss: 0.3610 - val_mse: 1259.2678 - val_mae: 0.3610\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2821 - mse: 484.0206 - mae: 0.2821 - val_loss: 0.3870 - val_mse: 1259.2755 - val_mae: 0.3870\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.3107 - mse: 30060435456.0000 - mae: 387.3106 - val_loss: 0.3832 - val_mse: 1259.2621 - val_mae: 0.3832\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4132 - mse: 1106.5295 - mae: 0.4132 - val_loss: 0.3649 - val_mse: 1259.2687 - val_mae: 0.3649\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1732 - mse: 30060435456.0000 - mae: 387.1730 - val_loss: 0.3676 - val_mse: 1259.2683 - val_mae: 0.3676\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1843 - mse: 30060435456.0000 - mae: 387.1846 - val_loss: 0.3630 - val_mse: 1259.2528 - val_mae: 0.3630\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4183 - mse: 1228.7101 - mae: 0.4183 - val_loss: 0.3637 - val_mse: 1259.2689 - val_mae: 0.3637\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8399 - mse: 20040290304.0000 - mae: 193.8399 - val_loss: 0.3621 - val_mse: 1259.2563 - val_mae: 0.3621\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3058 - mse: 655.7651 - mae: 0.3058 - val_loss: 0.3699 - val_mse: 1259.2601 - val_mae: 0.3699\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4732 - mse: 25050365952.0000 - mae: 290.4733 - val_loss: 0.3642 - val_mse: 1259.2595 - val_mae: 0.3642\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3559 - mse: 1110.8910 - mae: 0.3559 - val_loss: 0.3609 - val_mse: 1259.2631 - val_mae: 0.3609\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3675 - mse: 1015.6054 - mae: 0.3675 - val_loss: 0.3631 - val_mse: 1259.2556 - val_mae: 0.3631\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5424 - mse: 40080580608.0000 - mae: 580.5433 - val_loss: 0.3628 - val_mse: 1259.2629 - val_mae: 0.3628\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3839 - mse: 1011.0419 - mae: 0.3839 - val_loss: 0.3688 - val_mse: 1259.2670 - val_mae: 0.3688\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4462 - mse: 25050363904.0000 - mae: 290.4463 - val_loss: 0.3618 - val_mse: 1259.2585 - val_mae: 0.3618\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.6801 - mse: 20040292352.0000 - mae: 193.6801 - val_loss: 0.3604 - val_mse: 1259.2639 - val_mae: 0.3604\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4349 - mse: 1239.0587 - mae: 0.4349 - val_loss: 0.3628 - val_mse: 1259.2635 - val_mae: 0.3628\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4019 - mse: 25050363904.0000 - mae: 290.4018 - val_loss: 0.3641 - val_mse: 1259.2664 - val_mae: 0.3641\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4132 - mse: 1217.5549 - mae: 0.4132 - val_loss: 0.3617 - val_mse: 1259.2678 - val_mae: 0.3617\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0605 - mse: 30060443648.0000 - mae: 387.0604 - val_loss: 0.3616 - val_mse: 1259.2629 - val_mae: 0.3616\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4574 - mse: 1539.1952 - mae: 0.4574 - val_loss: 0.3624 - val_mse: 1259.2675 - val_mae: 0.3624\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1325 - mse: 30060435456.0000 - mae: 387.1324 - val_loss: 0.3594 - val_mse: 1259.2542 - val_mae: 0.3594\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4198 - mse: 1179.3925 - mae: 0.4198 - val_loss: 0.3597 - val_mse: 1259.2556 - val_mae: 0.3597\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7616 - mse: 35070509056.0000 - mae: 483.7617 - val_loss: 0.3606 - val_mse: 1259.2573 - val_mae: 0.3606\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4838 - mse: 1467.1443 - mae: 0.4838 - val_loss: 0.3599 - val_mse: 1259.2595 - val_mae: 0.3599\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7673 - mse: 20040292352.0000 - mae: 193.7672 - val_loss: 0.3616 - val_mse: 1259.2555 - val_mae: 0.3616\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3962 - mse: 1209.5038 - mae: 0.3962 - val_loss: 0.3609 - val_mse: 1259.2673 - val_mae: 0.3609\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7295 - mse: 20040290304.0000 - mae: 193.7295 - val_loss: 0.3622 - val_mse: 1259.2599 - val_mae: 0.3622\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3686 - mse: 1225.4487 - mae: 0.3686 - val_loss: 0.3608 - val_mse: 1259.2582 - val_mae: 0.3608\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8181 - mse: 35070509056.0000 - mae: 483.8181 - val_loss: 0.3645 - val_mse: 1259.2554 - val_mae: 0.3645\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3875 - mse: 1175.0270 - mae: 0.3875 - val_loss: 0.3604 - val_mse: 1259.2583 - val_mae: 0.3604\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2101 - mse: 30060435456.0000 - mae: 387.2100 - val_loss: 0.3755 - val_mse: 1259.2648 - val_mae: 0.3755\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3599 - mse: 1017.5059 - mae: 0.3599 - val_loss: 0.3688 - val_mse: 1259.2720 - val_mae: 0.3688\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1674 - mse: 30060435456.0000 - mae: 387.1674 - val_loss: 0.3669 - val_mse: 1259.2540 - val_mae: 0.3669\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3520 - mse: 1110.7566 - mae: 0.3520 - val_loss: 0.3647 - val_mse: 1259.2749 - val_mae: 0.3647\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2866 - mse: 610.0145 - mae: 0.2866 - val_loss: 0.3759 - val_mse: 1259.2692 - val_mae: 0.3759\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9848 - mse: 35070509056.0000 - mae: 483.9849 - val_loss: 0.3810 - val_mse: 1259.2740 - val_mae: 0.3810\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2770 - mse: 633.1982 - mae: 0.2770 - val_loss: 0.3618 - val_mse: 1259.2594 - val_mae: 0.3618\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.9012 - mse: 20040290304.0000 - mae: 193.9011 - val_loss: 0.3641 - val_mse: 1259.2616 - val_mae: 0.3641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3129 - mse: 795.6802 - mae: 0.3129 - val_loss: 0.3691 - val_mse: 1259.2640 - val_mae: 0.3691\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1499 - mse: 30060435456.0000 - mae: 387.1505 - val_loss: 0.3646 - val_mse: 1259.2676 - val_mae: 0.3646\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2588 - mse: 45090652160.0000 - mae: 677.2592 - val_loss: 0.3665 - val_mse: 1259.2556 - val_mae: 0.3665\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4135 - mse: 1198.3979 - mae: 0.4135 - val_loss: 0.3742 - val_mse: 1259.2686 - val_mae: 0.3742\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3353 - mse: 862.9945 - mae: 0.3353 - val_loss: 0.3617 - val_mse: 1259.2607 - val_mae: 0.3617\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5790 - mse: 40080580608.0000 - mae: 580.5792 - val_loss: 0.3670 - val_mse: 1259.2548 - val_mae: 0.3670\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9420 - mse: 35070513152.0000 - mae: 483.9420 - val_loss: 0.3709 - val_mse: 1259.2599 - val_mae: 0.3709\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2509 - mse: 622.2307 - mae: 0.2509 - val_loss: 0.3612 - val_mse: 1259.2585 - val_mae: 0.3612\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4257 - mse: 1227.1040 - mae: 0.4257 - val_loss: 0.3639 - val_mse: 1259.2678 - val_mae: 0.3639\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1618 - mse: 30060435456.0000 - mae: 387.1619 - val_loss: 0.3620 - val_mse: 1259.2607 - val_mae: 0.3620\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3465 - mse: 868.7825 - mae: 0.3465 - val_loss: 0.3647 - val_mse: 1259.2606 - val_mae: 0.3647\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2794 - mse: 30060439552.0000 - mae: 387.2795 - val_loss: 0.3616 - val_mse: 1259.2656 - val_mae: 0.3616\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3322 - mse: 913.6999 - mae: 0.3322 - val_loss: 0.3608 - val_mse: 1259.2621 - val_mae: 0.3608\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4095 - mse: 25050363904.0000 - mae: 290.4095 - val_loss: 0.3624 - val_mse: 1259.2590 - val_mae: 0.3624\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3173 - mse: 847.5355 - mae: 0.3173 - val_loss: 0.3605 - val_mse: 1259.2635 - val_mae: 0.3605\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7610 - mse: 20040292352.0000 - mae: 193.7610 - val_loss: 0.3650 - val_mse: 1259.2693 - val_mae: 0.3650\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3640 - mse: 1082.4885 - mae: 0.3640 - val_loss: 0.3592 - val_mse: 1259.2598 - val_mae: 0.3592\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5937 - mse: 40080580608.0000 - mae: 580.5938 - val_loss: 0.3597 - val_mse: 1259.2582 - val_mae: 0.3597\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8243 - mse: 20040292352.0000 - mae: 193.8245 - val_loss: 0.3604 - val_mse: 1259.2601 - val_mae: 0.3604\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3119 - mse: 748.2035 - mae: 0.3119 - val_loss: 0.3593 - val_mse: 1259.2565 - val_mae: 0.3593\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7890 - mse: 20040292352.0000 - mae: 193.7892 - val_loss: 0.3620 - val_mse: 1259.2639 - val_mae: 0.3620\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2286 - mse: 436.0067 - mae: 0.2286 - val_loss: 0.3596 - val_mse: 1259.2656 - val_mae: 0.3596\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 677.3069 - mse: 45090652160.0000 - mae: 677.3073 - val_loss: 0.3713 - val_mse: 1259.2616 - val_mae: 0.3713\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3509 - mse: 877.7906 - mae: 0.3509 - val_loss: 0.3811 - val_mse: 1259.2524 - val_mae: 0.3811\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3978 - mse: 1097.6216 - mae: 0.3978 - val_loss: 0.3715 - val_mse: 1259.2661 - val_mae: 0.3715\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3983 - mse: 25050363904.0000 - mae: 290.3984 - val_loss: 0.3672 - val_mse: 1259.2589 - val_mae: 0.3672\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4196 - mse: 1262.5195 - mae: 0.4196 - val_loss: 0.3658 - val_mse: 1259.2516 - val_mae: 0.3658\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.6955 - mse: 20040292352.0000 - mae: 193.6955 - val_loss: 0.3636 - val_mse: 1259.2648 - val_mae: 0.3636\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2816 - mse: 30060435456.0000 - mae: 387.2816 - val_loss: 0.3634 - val_mse: 1259.2714 - val_mae: 0.3634\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3229 - mse: 854.4521 - mae: 0.3229 - val_loss: 0.3634 - val_mse: 1259.2618 - val_mae: 0.3634\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2041 - mse: 30060435456.0000 - mae: 387.2039 - val_loss: 0.3628 - val_mse: 1259.2616 - val_mae: 0.3628\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3407 - mse: 914.5992 - mae: 0.3407 - val_loss: 0.3643 - val_mse: 1259.2557 - val_mae: 0.3643\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3501 - mse: 1100.4834 - mae: 0.3501 - val_loss: 0.3640 - val_mse: 1259.2666 - val_mae: 0.3640\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5448 - mse: 40080580608.0000 - mae: 580.5451 - val_loss: 0.3623 - val_mse: 1259.2556 - val_mae: 0.3623\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3657 - mse: 1033.7729 - mae: 0.3657 - val_loss: 0.3650 - val_mse: 1259.2593 - val_mae: 0.3650\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5680 - mse: 40080580608.0000 - mae: 580.5682 - val_loss: 0.3609 - val_mse: 1259.2631 - val_mae: 0.3609\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1923 - mse: 30060435456.0000 - mae: 387.1924 - val_loss: 0.3614 - val_mse: 1259.2552 - val_mae: 0.3614\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3492 - mse: 941.5913 - mae: 0.3492 - val_loss: 0.3665 - val_mse: 1259.2556 - val_mae: 0.3665\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2228 - mse: 30060435456.0000 - mae: 387.2227 - val_loss: 0.3645 - val_mse: 1259.2659 - val_mae: 0.3645\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3044 - mse: 866.1527 - mae: 0.3044 - val_loss: 0.3616 - val_mse: 1259.2657 - val_mae: 0.3616\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3386 - mse: 969.7252 - mae: 0.3386 - val_loss: 0.3610 - val_mse: 1259.2634 - val_mae: 0.3610\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4243 - mse: 25050363904.0000 - mae: 290.4243 - val_loss: 0.3600 - val_mse: 1259.2604 - val_mae: 0.3600\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1969 - mse: 30060435456.0000 - mae: 387.1973 - val_loss: 0.3625 - val_mse: 1259.2670 - val_mae: 0.3625\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3802 - mse: 937.3945 - mae: 0.3802 - val_loss: 0.3646 - val_mse: 1279.0840 - val_mae: 0.3646\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3263 - mse: 806.0383 - mae: 0.3263 - val_loss: 0.3611 - val_mse: 1259.2712 - val_mae: 0.3611\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4731 - mse: 25050365952.0000 - mae: 290.4732 - val_loss: 0.3630 - val_mse: 1259.2659 - val_mae: 0.3630\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5496 - mse: 40080580608.0000 - mae: 580.5496 - val_loss: 0.3613 - val_mse: 1259.2618 - val_mae: 0.3613\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3570 - mse: 1036.8732 - mae: 0.3570 - val_loss: 0.3611 - val_mse: 1259.2540 - val_mae: 0.3611\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2920 - mse: 654.0816 - mae: 0.2920 - val_loss: 0.3624 - val_mse: 1259.2510 - val_mae: 0.3624\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5337 - mse: 25050365952.0000 - mae: 290.5337 - val_loss: 0.3642 - val_mse: 1259.2676 - val_mae: 0.3642\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3383 - mse: 966.4819 - mae: 0.3383 - val_loss: 0.3608 - val_mse: 1259.2587 - val_mae: 0.3608\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1942 - mse: 30060435456.0000 - mae: 387.1942 - val_loss: 0.3598 - val_mse: 1259.2585 - val_mae: 0.3598\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3931 - mse: 1001.9042 - mae: 0.3931 - val_loss: 0.3729 - val_mse: 1259.2723 - val_mae: 0.3729\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9357 - mse: 35070513152.0000 - mae: 483.9360 - val_loss: 0.3704 - val_mse: 1259.2693 - val_mae: 0.3704\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 484.0075 - mse: 35070513152.0000 - mae: 484.0088 - val_loss: 0.3695 - val_mse: 1259.2594 - val_mae: 0.3695\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2176 - mse: 446.6037 - mae: 0.2176 - val_loss: 0.3661 - val_mse: 1259.2644 - val_mae: 0.3661\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8064 - mse: 20040292352.0000 - mae: 193.8063 - val_loss: 0.3647 - val_mse: 1259.2561 - val_mae: 0.3647\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3795 - mse: 945.0112 - mae: 0.3795 - val_loss: 0.3706 - val_mse: 1259.2567 - val_mae: 0.3706\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5223 - mse: 25050365952.0000 - mae: 290.5225 - val_loss: 0.3730 - val_mse: 1259.2445 - val_mae: 0.3730\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2618 - mse: 532.8122 - mae: 0.2618 - val_loss: 0.3685 - val_mse: 1259.2598 - val_mae: 0.3685\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7329 - mse: 20040290304.0000 - mae: 193.7328 - val_loss: 0.3617 - val_mse: 1259.2625 - val_mae: 0.3617\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3568 - mse: 1079.1017 - mae: 0.3568 - val_loss: 0.3620 - val_mse: 1259.2609 - val_mae: 0.3620\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3110 - mse: 700.3785 - mae: 0.3110 - val_loss: 0.3646 - val_mse: 1259.2682 - val_mae: 0.3646\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5348 - mse: 25050363904.0000 - mae: 290.5350 - val_loss: 0.3677 - val_mse: 1259.2631 - val_mae: 0.3677\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4081 - mse: 25050365952.0000 - mae: 290.4081 - val_loss: 0.3651 - val_mse: 1259.2650 - val_mae: 0.3651\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3966 - mse: 1024.3060 - mae: 0.3966 - val_loss: 0.3607 - val_mse: 1259.2617 - val_mae: 0.3607\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3339 - mse: 828.4852 - mae: 0.3339 - val_loss: 0.3737 - val_mse: 1259.2618 - val_mae: 0.3737\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2002 - mse: 30060439552.0000 - mae: 387.2003 - val_loss: 0.3614 - val_mse: 1259.2555 - val_mae: 0.3614\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4039 - mse: 1084.6740 - mae: 0.4039 - val_loss: 0.3664 - val_mse: 1259.2585 - val_mae: 0.3664\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1683 - mse: 30060435456.0000 - mae: 387.1682 - val_loss: 0.3643 - val_mse: 1259.2633 - val_mae: 0.3643\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3136 - mse: 875.9456 - mae: 0.3136 - val_loss: 0.3618 - val_mse: 1259.2723 - val_mae: 0.3618\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4994 - mse: 25050365952.0000 - mae: 290.4994 - val_loss: 0.3600 - val_mse: 1259.2648 - val_mae: 0.3600\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4401 - mse: 25050365952.0000 - mae: 290.4402 - val_loss: 0.3649 - val_mse: 1259.2588 - val_mae: 0.3649\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3938 - mse: 1228.0289 - mae: 0.3938 - val_loss: 0.3600 - val_mse: 1259.2676 - val_mae: 0.3600\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1939 - mse: 30060435456.0000 - mae: 387.1940 - val_loss: 0.3597 - val_mse: 1259.2648 - val_mae: 0.3597\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3011 - mse: 852.7410 - mae: 0.3011 - val_loss: 0.3606 - val_mse: 1259.2672 - val_mae: 0.3606\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5435 - mse: 40080580608.0000 - mae: 580.5435 - val_loss: 0.3597 - val_mse: 1259.2556 - val_mae: 0.3597\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4123 - mse: 1210.5306 - mae: 0.4123 - val_loss: 0.3612 - val_mse: 1259.2507 - val_mae: 0.3612\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5857 - mse: 40080580608.0000 - mae: 580.5856 - val_loss: 0.3598 - val_mse: 1259.2662 - val_mae: 0.3598\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3147 - mse: 825.8250 - mae: 0.3147 - val_loss: 0.3613 - val_mse: 1259.6128 - val_mae: 0.3613\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4051 - mse: 1204.4714 - mae: 0.4051 - val_loss: 0.3595 - val_mse: 1259.2615 - val_mae: 0.3595\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1842 - mse: 30060435456.0000 - mae: 387.1845 - val_loss: 0.3606 - val_mse: 1259.2656 - val_mae: 0.3606\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5152 - mse: 25050365952.0000 - mae: 290.5154 - val_loss: 0.3678 - val_mse: 1259.2711 - val_mae: 0.3678\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3164 - mse: 827.8987 - mae: 0.3164 - val_loss: 0.3698 - val_mse: 1259.2633 - val_mae: 0.3698\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3554 - mse: 858.6683 - mae: 0.3554 - val_loss: 0.3769 - val_mse: 1259.2666 - val_mae: 0.3769\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8689 - mse: 35070509056.0000 - mae: 483.8693 - val_loss: 0.3715 - val_mse: 1259.2723 - val_mae: 0.3715\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8766 - mse: 35070509056.0000 - mae: 483.8768 - val_loss: 0.3730 - val_mse: 1259.2676 - val_mae: 0.3730\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3486 - mse: 857.0132 - mae: 0.3486 - val_loss: 0.3661 - val_mse: 1259.2667 - val_mae: 0.3661\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1848 - mse: 30060435456.0000 - mae: 387.1849 - val_loss: 0.3770 - val_mse: 1259.2683 - val_mae: 0.3770\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3565 - mse: 995.4670 - mae: 0.3565 - val_loss: 0.3637 - val_mse: 1259.2618 - val_mae: 0.3637\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3231 - mse: 794.0471 - mae: 0.3231 - val_loss: 0.3775 - val_mse: 1259.2634 - val_mae: 0.3775\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3211 - mse: 45090652160.0000 - mae: 677.3214 - val_loss: 0.3681 - val_mse: 1259.2612 - val_mae: 0.3681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2673 - mse: 30060435456.0000 - mae: 387.2673 - val_loss: 0.3666 - val_mse: 1259.2729 - val_mae: 0.3666\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2803 - mse: 606.8764 - mae: 0.2803 - val_loss: 0.3623 - val_mse: 1259.2589 - val_mae: 0.3623\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1922 - mse: 30060435456.0000 - mae: 387.1923 - val_loss: 0.3625 - val_mse: 1259.2599 - val_mae: 0.3625\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3623 - mse: 963.3416 - mae: 0.3623 - val_loss: 0.3619 - val_mse: 1259.2678 - val_mae: 0.3619\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8384 - mse: 35070509056.0000 - mae: 483.8386 - val_loss: 0.3612 - val_mse: 1259.2495 - val_mae: 0.3612\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3722 - mse: 1103.0594 - mae: 0.3722 - val_loss: 0.3611 - val_mse: 1259.2524 - val_mae: 0.3611\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1697 - mse: 30060439552.0000 - mae: 387.1697 - val_loss: 0.3615 - val_mse: 1259.2629 - val_mae: 0.3615\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3856 - mse: 1013.3690 - mae: 0.3856 - val_loss: 0.3633 - val_mse: 1259.2614 - val_mae: 0.3633\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4335 - mse: 25050365952.0000 - mae: 290.4337 - val_loss: 0.3608 - val_mse: 1259.2548 - val_mae: 0.3608\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3650 - mse: 1029.7244 - mae: 0.3650 - val_loss: 0.3628 - val_mse: 1259.2612 - val_mae: 0.3628\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2949 - mse: 683.6315 - mae: 0.2949 - val_loss: 0.3608 - val_mse: 1259.2629 - val_mae: 0.3608\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2443 - mse: 30060435456.0000 - mae: 387.2444 - val_loss: 0.3601 - val_mse: 1259.2704 - val_mae: 0.3601\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7253 - mse: 20040292352.0000 - mae: 193.7253 - val_loss: 0.3610 - val_mse: 1259.2614 - val_mae: 0.3610\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4117 - mse: 1237.3043 - mae: 0.4117 - val_loss: 0.3604 - val_mse: 1259.2661 - val_mae: 0.3604\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3073 - mse: 709.0121 - mae: 0.3073 - val_loss: 0.3605 - val_mse: 1259.2546 - val_mae: 0.3605\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9026 - mse: 35070517248.0000 - mae: 483.9019 - val_loss: 0.3612 - val_mse: 1259.2662 - val_mae: 0.3612\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8684 - mse: 35070513152.0000 - mae: 483.8683 - val_loss: 0.3611 - val_mse: 1259.2476 - val_mae: 0.3611\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3440 - mse: 845.3158 - mae: 0.3440 - val_loss: 0.3604 - val_mse: 1259.2599 - val_mae: 0.3604\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3574 - mse: 1049.9664 - mae: 0.3574 - val_loss: 0.3611 - val_mse: 1259.2650 - val_mae: 0.3611\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8388 - mse: 35070509056.0000 - mae: 483.8385 - val_loss: 0.3620 - val_mse: 1259.2550 - val_mae: 0.3620\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.2177 - mse: 30060435456.0000 - mae: 387.2174 - val_loss: 0.3761 - val_mse: 1259.2682 - val_mae: 0.3761\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3639 - mse: 943.7972 - mae: 0.3639 - val_loss: 0.3665 - val_mse: 1259.2606 - val_mae: 0.3665\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9000 - mse: 35070509056.0000 - mae: 483.8998 - val_loss: 0.3738 - val_mse: 1259.2679 - val_mae: 0.3738\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3617 - mse: 1039.7334 - mae: 0.3617 - val_loss: 0.3659 - val_mse: 1259.2601 - val_mae: 0.3659\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4146 - mse: 25050365952.0000 - mae: 290.4146 - val_loss: 0.3691 - val_mse: 1259.2618 - val_mae: 0.3691\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3787 - mse: 1037.5433 - mae: 0.3787 - val_loss: 0.3640 - val_mse: 1259.2593 - val_mae: 0.3640\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3188 - mse: 912.9743 - mae: 0.3188 - val_loss: 0.3664 - val_mse: 1259.2549 - val_mae: 0.3664\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2030 - mse: 30060435456.0000 - mae: 387.2031 - val_loss: 0.3624 - val_mse: 1259.2609 - val_mae: 0.3624\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7951 - mse: 20040292352.0000 - mae: 193.7951 - val_loss: 0.3684 - val_mse: 1259.2719 - val_mae: 0.3684\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3199 - mse: 913.7326 - mae: 0.3199 - val_loss: 0.3674 - val_mse: 1259.2682 - val_mae: 0.3674\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3544 - mse: 970.0534 - mae: 0.3544 - val_loss: 0.3724 - val_mse: 1259.2672 - val_mae: 0.3724\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4623 - mse: 25050365952.0000 - mae: 290.4622 - val_loss: 0.3702 - val_mse: 1259.2706 - val_mae: 0.3702\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4223 - mse: 1290.6387 - mae: 0.4223 - val_loss: 0.3636 - val_mse: 1259.2633 - val_mae: 0.3636\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4058 - mse: 25050363904.0000 - mae: 290.4058 - val_loss: 0.3615 - val_mse: 1259.2595 - val_mae: 0.3615\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2605 - mse: 573.0170 - mae: 0.2605 - val_loss: 0.3616 - val_mse: 1259.2638 - val_mae: 0.3616\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4856 - mse: 25050363904.0000 - mae: 290.4854 - val_loss: 0.3630 - val_mse: 1259.2625 - val_mae: 0.3630\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7433 - mse: 20040292352.0000 - mae: 193.7432 - val_loss: 0.3606 - val_mse: 1259.2560 - val_mae: 0.3606\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3354 - mse: 878.6620 - mae: 0.3354 - val_loss: 0.3628 - val_mse: 1259.2567 - val_mae: 0.3628\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3415 - mse: 946.7709 - mae: 0.3415 - val_loss: 0.3640 - val_mse: 1259.2512 - val_mae: 0.3640\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1568 - mse: 30060435456.0000 - mae: 387.1570 - val_loss: 0.3620 - val_mse: 1259.2637 - val_mae: 0.3620\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1430 - mse: 30060435456.0000 - mae: 387.1431 - val_loss: 0.3612 - val_mse: 1259.2643 - val_mae: 0.3612\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3844 - mse: 1102.4604 - mae: 0.3844 - val_loss: 0.3608 - val_mse: 1259.2522 - val_mae: 0.3608\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3774 - mse: 1091.5072 - mae: 0.3774 - val_loss: 0.3623 - val_mse: 1259.2646 - val_mae: 0.3623\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1430 - mse: 30060439552.0000 - mae: 387.1430 - val_loss: 0.3614 - val_mse: 1259.2430 - val_mae: 0.3614\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1451 - mse: 30060435456.0000 - mae: 387.1452 - val_loss: 0.3620 - val_mse: 1259.2618 - val_mae: 0.3620\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3384 - mse: 917.0248 - mae: 0.3384 - val_loss: 0.3651 - val_mse: 1259.2495 - val_mae: 0.3651\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4287 - mse: 25050365952.0000 - mae: 290.4288 - val_loss: 0.3597 - val_mse: 1259.2583 - val_mae: 0.3597\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4354 - mse: 1250.9486 - mae: 0.4354 - val_loss: 0.3605 - val_mse: 1259.2554 - val_mae: 0.3605\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3127 - mse: 783.5004 - mae: 0.3127 - val_loss: 0.3595 - val_mse: 1259.2542 - val_mae: 0.3595\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1423 - mse: 30060435456.0000 - mae: 387.1423 - val_loss: 0.3600 - val_mse: 1259.2587 - val_mae: 0.3600\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8839 - mse: 20040294400.0000 - mae: 193.8839 - val_loss: 0.3678 - val_mse: 1259.2936 - val_mae: 0.3678\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2728 - mse: 583.5578 - mae: 0.2728 - val_loss: 0.3674 - val_mse: 1259.2637 - val_mae: 0.3674\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4433 - mse: 1302.7667 - mae: 0.4433 - val_loss: 0.3666 - val_mse: 1259.2618 - val_mae: 0.3666\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1188 - mse: 30060435456.0000 - mae: 387.1191 - val_loss: 0.3640 - val_mse: 1259.2604 - val_mae: 0.3640\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3379 - mse: 886.9381 - mae: 0.3379 - val_loss: 0.3669 - val_mse: 1259.2601 - val_mae: 0.3669\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4999 - mse: 25050363904.0000 - mae: 290.4998 - val_loss: 0.3653 - val_mse: 1259.2638 - val_mae: 0.3653\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1669 - mse: 30060435456.0000 - mae: 387.1669 - val_loss: 0.3633 - val_mse: 1259.2645 - val_mae: 0.3633\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3782 - mse: 1021.8259 - mae: 0.3782 - val_loss: 0.3630 - val_mse: 1259.2611 - val_mae: 0.3630\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4090 - mse: 1207.5316 - mae: 0.4090 - val_loss: 0.3640 - val_mse: 1259.2650 - val_mae: 0.3640\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4461 - mse: 25050365952.0000 - mae: 290.4459 - val_loss: 0.3677 - val_mse: 1259.2665 - val_mae: 0.3677\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3518 - mse: 1051.6342 - mae: 0.3518 - val_loss: 0.3643 - val_mse: 1259.2612 - val_mae: 0.3643\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7465 - mse: 20040290304.0000 - mae: 193.7465 - val_loss: 0.3612 - val_mse: 1259.2587 - val_mae: 0.3612\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7834 - mse: 20040292352.0000 - mae: 193.7834 - val_loss: 0.3646 - val_mse: 1259.2651 - val_mae: 0.3646\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3308 - mse: 813.6038 - mae: 0.3308 - val_loss: 0.3609 - val_mse: 1259.2559 - val_mae: 0.3609\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8344 - mse: 35070509056.0000 - mae: 483.8345 - val_loss: 0.3628 - val_mse: 1259.2618 - val_mae: 0.3628\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3974 - mse: 1294.6768 - mae: 0.3974 - val_loss: 0.3613 - val_mse: 1259.2666 - val_mae: 0.3613\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4380 - mse: 25050363904.0000 - mae: 290.4380 - val_loss: 0.3657 - val_mse: 1259.2695 - val_mae: 0.3657\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3848 - mse: 1273.5422 - mae: 0.3848 - val_loss: 0.3634 - val_mse: 1259.2628 - val_mae: 0.3634\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3596 - mse: 997.3969 - mae: 0.3596 - val_loss: 0.3664 - val_mse: 1259.2635 - val_mae: 0.3664\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5927 - mse: 40080580608.0000 - mae: 580.5931 - val_loss: 0.3607 - val_mse: 1259.2572 - val_mae: 0.3607\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3744 - mse: 910.2556 - mae: 0.3744 - val_loss: 0.3620 - val_mse: 1259.2584 - val_mae: 0.3620\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1793 - mse: 30060435456.0000 - mae: 387.1793 - val_loss: 0.3599 - val_mse: 1259.2677 - val_mae: 0.3599\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4599 - mse: 25050365952.0000 - mae: 290.4599 - val_loss: 0.3730 - val_mse: 1259.2576 - val_mae: 0.3730\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3447 - mse: 1004.4822 - mae: 0.3447 - val_loss: 0.3598 - val_mse: 1259.2664 - val_mae: 0.3598\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3698 - mse: 985.4029 - mae: 0.3698 - val_loss: 0.3627 - val_mse: 1259.2593 - val_mae: 0.3627\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4936 - mse: 25050363904.0000 - mae: 290.4936 - val_loss: 0.3606 - val_mse: 1259.2457 - val_mae: 0.3606\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 870.6587 - mse: 55110799360.0000 - mae: 870.6547 - val_loss: 0.3592 - val_mse: 1259.2595 - val_mae: 0.3592\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3725 - mse: 1124.5388 - mae: 0.3725 - val_loss: 0.3594 - val_mse: 1259.2616 - val_mae: 0.3594\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5619 - mse: 40080580608.0000 - mae: 580.5618 - val_loss: 0.3602 - val_mse: 1259.2738 - val_mae: 0.3602\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3124 - mse: 780.3048 - mae: 0.3124 - val_loss: 0.3625 - val_mse: 1259.2562 - val_mae: 0.3625\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.2153 - mse: 30060439552.0000 - mae: 387.2154 - val_loss: 0.3708 - val_mse: 1259.2715 - val_mae: 0.3708\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3613 - mse: 970.0021 - mae: 0.3613 - val_loss: 0.3641 - val_mse: 1259.2708 - val_mae: 0.3641\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2125 - mse: 30060435456.0000 - mae: 387.2125 - val_loss: 0.3740 - val_mse: 1259.2684 - val_mae: 0.3740\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3677 - mse: 852.5327 - mae: 0.3677 - val_loss: 0.3637 - val_mse: 1259.2681 - val_mae: 0.3637\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3117 - mse: 884.7915 - mae: 0.3117 - val_loss: 0.3663 - val_mse: 1259.2715 - val_mae: 0.3663\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1750 - mse: 30060435456.0000 - mae: 387.1749 - val_loss: 0.3631 - val_mse: 1259.2649 - val_mae: 0.3631\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2753 - mse: 601.0443 - mae: 0.2753 - val_loss: 0.3658 - val_mse: 1259.2633 - val_mae: 0.3658\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.0734 - mse: 50100727808.0000 - mae: 774.0737 - val_loss: 0.3626 - val_mse: 1259.2646 - val_mae: 0.3626\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4452 - mse: 1315.2797 - mae: 0.4452 - val_loss: 0.3719 - val_mse: 1259.2678 - val_mae: 0.3719\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3888 - mse: 25050365952.0000 - mae: 290.3888 - val_loss: 0.3621 - val_mse: 1259.2637 - val_mae: 0.3621\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5942 - mse: 40080580608.0000 - mae: 580.5942 - val_loss: 0.3639 - val_mse: 1259.2667 - val_mae: 0.3639\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3393 - mse: 997.8735 - mae: 0.3393 - val_loss: 0.3631 - val_mse: 1259.2666 - val_mae: 0.3631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3868 - mse: 917.3211 - mae: 0.3868 - val_loss: 0.3642 - val_mse: 1259.2563 - val_mae: 0.3642\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7509 - mse: 20040290304.0000 - mae: 193.7509 - val_loss: 0.3612 - val_mse: 1259.2605 - val_mae: 0.3612\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1623 - mse: 30060435456.0000 - mae: 387.1623 - val_loss: 0.3676 - val_mse: 1259.2600 - val_mae: 0.3676\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3069 - mse: 794.7369 - mae: 0.3069 - val_loss: 0.3726 - val_mse: 1259.2650 - val_mae: 0.3726\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3334 - mse: 830.5289 - mae: 0.3334 - val_loss: 0.3633 - val_mse: 1259.2595 - val_mae: 0.3633\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1627 - mse: 30060435456.0000 - mae: 387.1625 - val_loss: 0.3653 - val_mse: 1259.2604 - val_mae: 0.3653\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7475 - mse: 20040290304.0000 - mae: 193.7475 - val_loss: 0.3618 - val_mse: 1259.2656 - val_mae: 0.3618\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3100 - mse: 874.3382 - mae: 0.3100 - val_loss: 0.3603 - val_mse: 1259.2633 - val_mae: 0.3603\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7561 - mse: 20040292352.0000 - mae: 193.7561 - val_loss: 0.3622 - val_mse: 1259.2664 - val_mae: 0.3622\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3019 - mse: 787.5676 - mae: 0.3019 - val_loss: 0.3597 - val_mse: 1259.2655 - val_mae: 0.3597\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5456 - mse: 40080580608.0000 - mae: 580.5463 - val_loss: 0.3616 - val_mse: 1259.2677 - val_mae: 0.3616\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4020 - mse: 1185.6196 - mae: 0.4020 - val_loss: 0.3597 - val_mse: 1259.2565 - val_mae: 0.3597\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4971 - mse: 25050363904.0000 - mae: 290.4973 - val_loss: 0.3640 - val_mse: 1259.2727 - val_mae: 0.3640\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3520 - mse: 1003.2698 - mae: 0.3520 - val_loss: 0.3608 - val_mse: 1259.2618 - val_mae: 0.3608\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8934 - mse: 35070509056.0000 - mae: 483.8933 - val_loss: 0.3597 - val_mse: 1259.2659 - val_mae: 0.3597\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3546 - mse: 930.1997 - mae: 0.3546 - val_loss: 0.3597 - val_mse: 1259.2640 - val_mae: 0.3597\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 484.0171 - mse: 35070513152.0000 - mae: 484.0167 - val_loss: 0.3604 - val_mse: 1259.2584 - val_mae: 0.3604\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2568 - mse: 526.5497 - mae: 0.2568 - val_loss: 0.3604 - val_mse: 1259.2661 - val_mae: 0.3604\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3498 - mse: 793.0891 - mae: 0.3498 - val_loss: 0.3745 - val_mse: 1259.2714 - val_mae: 0.3745\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7797 - mse: 20040294400.0000 - mae: 193.7797 - val_loss: 0.3700 - val_mse: 1259.2699 - val_mae: 0.3700\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5302 - mse: 25050365952.0000 - mae: 290.5302 - val_loss: 0.3656 - val_mse: 1259.2660 - val_mae: 0.3656\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3326 - mse: 926.5523 - mae: 0.3326 - val_loss: 0.3676 - val_mse: 1259.2695 - val_mae: 0.3676\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2636 - mse: 30060439552.0000 - mae: 387.2637 - val_loss: 0.3753 - val_mse: 1259.2573 - val_mae: 0.3753\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2852 - mse: 618.4785 - mae: 0.2852 - val_loss: 0.3687 - val_mse: 1259.2646 - val_mae: 0.3687\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3510 - mse: 845.3204 - mae: 0.3510 - val_loss: 0.3642 - val_mse: 1259.2610 - val_mae: 0.3642\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2552 - mse: 30060435456.0000 - mae: 387.2549 - val_loss: 0.3635 - val_mse: 1259.2510 - val_mae: 0.3635\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8473 - mse: 35070509056.0000 - mae: 483.8486 - val_loss: 0.3690 - val_mse: 1259.2638 - val_mae: 0.3690\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3826 - mse: 1160.4694 - mae: 0.3826 - val_loss: 0.3738 - val_mse: 1259.2690 - val_mae: 0.3738\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3741 - mse: 1032.6136 - mae: 0.3741 - val_loss: 0.3644 - val_mse: 1259.2638 - val_mae: 0.3644\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4526 - mse: 25050363904.0000 - mae: 290.4526 - val_loss: 0.3649 - val_mse: 1259.2548 - val_mae: 0.3649\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8596 - mse: 35070509056.0000 - mae: 483.8594 - val_loss: 0.3652 - val_mse: 1259.2563 - val_mae: 0.3652\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3849 - mse: 1124.0583 - mae: 0.3849 - val_loss: 0.3612 - val_mse: 1259.2690 - val_mae: 0.3612\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2897 - mse: 672.1366 - mae: 0.2897 - val_loss: 0.3652 - val_mse: 1259.2579 - val_mae: 0.3652\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9388 - mse: 35070517248.0000 - mae: 483.9392 - val_loss: 0.3614 - val_mse: 1259.2671 - val_mae: 0.3614\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7258 - mse: 20040292352.0000 - mae: 193.7258 - val_loss: 0.3608 - val_mse: 1259.2635 - val_mae: 0.3608\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3511 - mse: 978.1959 - mae: 0.3511 - val_loss: 0.3616 - val_mse: 1259.2676 - val_mae: 0.3616\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4707 - mse: 25050363904.0000 - mae: 290.4708 - val_loss: 0.3660 - val_mse: 1259.2583 - val_mae: 0.3660\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3529 - mse: 959.0507 - mae: 0.3529 - val_loss: 0.3618 - val_mse: 1259.2607 - val_mae: 0.3618\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8850 - mse: 35070509056.0000 - mae: 483.8853 - val_loss: 0.3645 - val_mse: 1259.2704 - val_mae: 0.3645\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3649 - mse: 915.9472 - mae: 0.3649 - val_loss: 0.3606 - val_mse: 1259.2570 - val_mae: 0.3606\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4458 - mse: 25050365952.0000 - mae: 290.4457 - val_loss: 0.3596 - val_mse: 1259.2606 - val_mae: 0.3596\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3778 - mse: 1143.5142 - mae: 0.3778 - val_loss: 0.3612 - val_mse: 1259.2620 - val_mae: 0.3612\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3819 - mse: 963.0085 - mae: 0.3819 - val_loss: 0.3658 - val_mse: 1259.2611 - val_mae: 0.3658\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5275 - mse: 25050365952.0000 - mae: 290.5275 - val_loss: 0.3601 - val_mse: 1259.2556 - val_mae: 0.3601\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3777 - mse: 1168.9862 - mae: 0.3777 - val_loss: 0.3594 - val_mse: 1259.2662 - val_mae: 0.3594\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9288 - mse: 35070509056.0000 - mae: 483.9294 - val_loss: 0.3601 - val_mse: 1259.2562 - val_mae: 0.3601\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3323 - mse: 1062.3602 - mae: 0.3323 - val_loss: 0.3600 - val_mse: 1259.2570 - val_mae: 0.3600\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4553 - mse: 25050363904.0000 - mae: 290.4553 - val_loss: 0.3629 - val_mse: 1259.2556 - val_mae: 0.3629\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4410 - mse: 1229.9906 - mae: 0.4410 - val_loss: 0.3785 - val_mse: 1259.2628 - val_mae: 0.3785\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4014 - mse: 25050363904.0000 - mae: 290.4013 - val_loss: 0.3673 - val_mse: 1259.2605 - val_mae: 0.3673\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3118 - mse: 864.0360 - mae: 0.3118 - val_loss: 0.3689 - val_mse: 1259.2582 - val_mae: 0.3689\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7622 - mse: 20040292352.0000 - mae: 193.7623 - val_loss: 0.3716 - val_mse: 1259.2587 - val_mae: 0.3716\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5307 - mse: 25050365952.0000 - mae: 290.5307 - val_loss: 0.3632 - val_mse: 1259.2627 - val_mae: 0.3632\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3050 - mse: 657.9821 - mae: 0.3050 - val_loss: 0.3647 - val_mse: 1259.2700 - val_mae: 0.3647\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1176 - mse: 30060435456.0000 - mae: 387.1176 - val_loss: 0.3654 - val_mse: 1259.2648 - val_mae: 0.3654\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4285 - mse: 1278.5105 - mae: 0.4285 - val_loss: 0.3636 - val_mse: 1259.2576 - val_mae: 0.3636\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.0161 - mse: 50100727808.0000 - mae: 774.0167 - val_loss: 0.3622 - val_mse: 1259.2686 - val_mae: 0.3622\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4155 - mse: 1261.1040 - mae: 0.4155 - val_loss: 0.3619 - val_mse: 1259.2656 - val_mae: 0.3619\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8444 - mse: 20040290304.0000 - mae: 193.8444 - val_loss: 0.3623 - val_mse: 1259.2598 - val_mae: 0.3623\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2831 - mse: 761.5337 - mae: 0.2831 - val_loss: 0.3667 - val_mse: 1259.2638 - val_mae: 0.3667\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3565 - mse: 1216.2906 - mae: 0.3565 - val_loss: 0.3625 - val_mse: 1259.2570 - val_mae: 0.3625\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7875 - mse: 35070509056.0000 - mae: 483.7877 - val_loss: 0.3614 - val_mse: 1259.2693 - val_mae: 0.3614\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3374 - mse: 807.7845 - mae: 0.3374 - val_loss: 0.3628 - val_mse: 1259.2546 - val_mae: 0.3628\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7968 - mse: 20040292352.0000 - mae: 193.7969 - val_loss: 0.3599 - val_mse: 1259.2601 - val_mae: 0.3599\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4240 - mse: 1214.6338 - mae: 0.4240 - val_loss: 0.3603 - val_mse: 1259.2510 - val_mae: 0.3603\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2694 - mse: 45090652160.0000 - mae: 677.2693 - val_loss: 0.3613 - val_mse: 1259.2629 - val_mae: 0.3613\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3186 - mse: 794.9944 - mae: 0.3186 - val_loss: 0.3616 - val_mse: 1259.2625 - val_mae: 0.3616\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6165 - mse: 40080580608.0000 - mae: 580.6167 - val_loss: 0.3611 - val_mse: 1259.2699 - val_mae: 0.3611\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3200 - mse: 45090652160.0000 - mae: 677.3203 - val_loss: 0.3638 - val_mse: 1259.2611 - val_mae: 0.3638\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3016 - mse: 675.6085 - mae: 0.3016 - val_loss: 0.3706 - val_mse: 1259.2614 - val_mae: 0.3706\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3183 - mse: 577.7431 - mae: 0.3183 - val_loss: 0.3592 - val_mse: 1259.2570 - val_mae: 0.3592\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5276 - mse: 25050365952.0000 - mae: 290.5276 - val_loss: 0.3638 - val_mse: 1259.2625 - val_mae: 0.3638\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7767 - mse: 20040292352.0000 - mae: 193.7766 - val_loss: 0.3604 - val_mse: 1259.2610 - val_mae: 0.3604\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3094 - mse: 767.4611 - mae: 0.3094 - val_loss: 0.3601 - val_mse: 1259.2684 - val_mae: 0.3601\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4338 - mse: 25050363904.0000 - mae: 290.4339 - val_loss: 0.3594 - val_mse: 1259.2706 - val_mae: 0.3594\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3441 - mse: 853.4772 - mae: 0.3441 - val_loss: 0.3604 - val_mse: 1259.2494 - val_mae: 0.3604\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3315 - mse: 1030.6565 - mae: 0.3315 - val_loss: 0.3599 - val_mse: 1259.2488 - val_mae: 0.3599\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8236 - mse: 20040290304.0000 - mae: 193.8237 - val_loss: 0.3607 - val_mse: 1259.2635 - val_mae: 0.3607\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8115 - mse: 20040292352.0000 - mae: 193.8116 - val_loss: 0.3748 - val_mse: 1259.2677 - val_mae: 0.3748\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3925 - mse: 1012.9796 - mae: 0.3925 - val_loss: 0.3673 - val_mse: 1259.2712 - val_mae: 0.3673\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7581 - mse: 20040290304.0000 - mae: 193.7581 - val_loss: 0.3959 - val_mse: 1259.2755 - val_mae: 0.3959\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3887 - mse: 1028.9995 - mae: 0.3887 - val_loss: 0.3664 - val_mse: 1259.2725 - val_mae: 0.3664\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4322 - mse: 25050363904.0000 - mae: 290.4324 - val_loss: 0.3652 - val_mse: 1259.2670 - val_mae: 0.3652\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3816 - mse: 1001.6921 - mae: 0.3816 - val_loss: 0.3630 - val_mse: 1259.2679 - val_mae: 0.3630\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8856 - mse: 35070509056.0000 - mae: 483.8867 - val_loss: 0.3650 - val_mse: 1259.2590 - val_mae: 0.3650\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3773 - mse: 937.6435 - mae: 0.3773 - val_loss: 0.3682 - val_mse: 1259.2623 - val_mae: 0.3682\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2178 - mse: 30060435456.0000 - mae: 387.2176 - val_loss: 0.3697 - val_mse: 1259.2638 - val_mae: 0.3697\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3222 - mse: 940.5278 - mae: 0.3222 - val_loss: 0.3634 - val_mse: 1259.2563 - val_mae: 0.3634\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2909 - mse: 628.4532 - mae: 0.2909 - val_loss: 0.3659 - val_mse: 1259.2673 - val_mae: 0.3659\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9222 - mse: 35070509056.0000 - mae: 483.9229 - val_loss: 0.3635 - val_mse: 1259.2646 - val_mae: 0.3635\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4272 - mse: 1380.4397 - mae: 0.4272 - val_loss: 0.3612 - val_mse: 1259.2627 - val_mae: 0.3612\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7859 - mse: 35070509056.0000 - mae: 483.7866 - val_loss: 0.3637 - val_mse: 1259.2616 - val_mae: 0.3637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3124 - mse: 768.7750 - mae: 0.3124 - val_loss: 0.3606 - val_mse: 1259.2646 - val_mae: 0.3606\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2164 - mse: 30060439552.0000 - mae: 387.2162 - val_loss: 0.3638 - val_mse: 1259.2710 - val_mae: 0.3638\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2942 - mse: 700.9583 - mae: 0.2942 - val_loss: 0.3683 - val_mse: 1259.2698 - val_mae: 0.3683\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7970 - mse: 20040292352.0000 - mae: 193.7969 - val_loss: 0.3602 - val_mse: 1259.2644 - val_mae: 0.3602\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.3353 - mse: 30060435456.0000 - mae: 387.3352 - val_loss: 0.3604 - val_mse: 1259.2532 - val_mae: 0.3604\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2159 - mse: 439.0816 - mae: 0.2159 - val_loss: 0.3641 - val_mse: 1259.2726 - val_mae: 0.3641\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3652 - mse: 1147.4382 - mae: 0.3652 - val_loss: 0.3600 - val_mse: 1259.2612 - val_mae: 0.3600\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1693 - mse: 30060439552.0000 - mae: 387.1691 - val_loss: 0.3631 - val_mse: 1259.2670 - val_mae: 0.3631\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7141 - mse: 20040290304.0000 - mae: 193.7141 - val_loss: 0.3604 - val_mse: 1259.2609 - val_mae: 0.3604\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3051 - mse: 791.8307 - mae: 0.3051 - val_loss: 0.3604 - val_mse: 1259.2643 - val_mae: 0.3604\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3582 - mse: 1004.9600 - mae: 0.3582 - val_loss: 0.3668 - val_mse: 1259.2635 - val_mae: 0.3668\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5629 - mse: 40080580608.0000 - mae: 580.5632 - val_loss: 0.3639 - val_mse: 1259.2681 - val_mae: 0.3639\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9526 - mse: 35070509056.0000 - mae: 483.9525 - val_loss: 0.3607 - val_mse: 1259.2659 - val_mae: 0.3607\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3197 - mse: 878.3214 - mae: 0.3197 - val_loss: 0.3671 - val_mse: 1259.2607 - val_mae: 0.3671\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3741 - mse: 1091.4958 - mae: 0.3741 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1957 - mse: 30060435456.0000 - mae: 387.1956 - val_loss: 0.3601 - val_mse: 1259.2676 - val_mae: 0.3601\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2088 - mse: 30060435456.0000 - mae: 387.2085 - val_loss: 0.3689 - val_mse: 1259.2704 - val_mae: 0.3689\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3600 - mse: 914.1329 - mae: 0.3600 - val_loss: 0.3841 - val_mse: 1259.2650 - val_mae: 0.3841\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5399 - mse: 40080580608.0000 - mae: 580.5406 - val_loss: 0.3653 - val_mse: 1259.2689 - val_mae: 0.3653\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4030 - mse: 1183.6583 - mae: 0.4030 - val_loss: 0.3643 - val_mse: 1259.2678 - val_mae: 0.3643\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1741 - mse: 30060435456.0000 - mae: 387.1739 - val_loss: 0.3629 - val_mse: 1259.2563 - val_mae: 0.3629\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3729 - mse: 1068.5476 - mae: 0.3729 - val_loss: 0.3695 - val_mse: 1259.2751 - val_mae: 0.3695\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2663 - mse: 520.5640 - mae: 0.2663 - val_loss: 0.3638 - val_mse: 1259.2642 - val_mae: 0.3638\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.8790 - mse: 20040292352.0000 - mae: 193.8791 - val_loss: 0.3615 - val_mse: 1259.2592 - val_mae: 0.3615\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7376 - mse: 20040290304.0000 - mae: 193.7375 - val_loss: 0.3682 - val_mse: 1259.2656 - val_mae: 0.3682\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3530 - mse: 1026.3905 - mae: 0.3530 - val_loss: 0.3619 - val_mse: 1259.2638 - val_mae: 0.3619\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3928 - mse: 1270.0129 - mae: 0.3928 - val_loss: 0.3659 - val_mse: 1259.2576 - val_mae: 0.3659\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8769 - mse: 35070509056.0000 - mae: 483.8769 - val_loss: 0.3616 - val_mse: 1259.2659 - val_mae: 0.3616\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4033 - mse: 1211.2124 - mae: 0.4033 - val_loss: 0.3658 - val_mse: 1259.2598 - val_mae: 0.3658\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2069 - mse: 30060435456.0000 - mae: 387.2070 - val_loss: 0.3651 - val_mse: 1259.2681 - val_mae: 0.3651\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4567 - mse: 25050363904.0000 - mae: 290.4568 - val_loss: 0.3627 - val_mse: 1259.2704 - val_mae: 0.3627\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3256 - mse: 914.8184 - mae: 0.3256 - val_loss: 0.3804 - val_mse: 1259.2662 - val_mae: 0.3804\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4167 - mse: 1335.7001 - mae: 0.4167 - val_loss: 0.3609 - val_mse: 1259.2676 - val_mae: 0.3609\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7235 - mse: 20040290304.0000 - mae: 193.7236 - val_loss: 0.3627 - val_mse: 1259.2653 - val_mae: 0.3627\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2255 - mse: 45090652160.0000 - mae: 677.2253 - val_loss: 0.3641 - val_mse: 1259.2603 - val_mae: 0.3641\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3788 - mse: 1147.6465 - mae: 0.3788 - val_loss: 0.3601 - val_mse: 1259.2629 - val_mae: 0.3601\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7311 - mse: 20040290304.0000 - mae: 193.7311 - val_loss: 0.3652 - val_mse: 1259.2604 - val_mae: 0.3652\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4345 - mse: 1355.4497 - mae: 0.4345 - val_loss: 0.3652 - val_mse: 1259.2552 - val_mae: 0.3652\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8047 - mse: 20040292352.0000 - mae: 193.8047 - val_loss: 0.3593 - val_mse: 1259.2548 - val_mae: 0.3593\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3142 - mse: 811.4857 - mae: 0.3142 - val_loss: 0.3636 - val_mse: 1259.2603 - val_mae: 0.3636\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7688 - mse: 20040290304.0000 - mae: 193.7688 - val_loss: 0.3597 - val_mse: 1259.2587 - val_mae: 0.3597\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3030 - mse: 850.7011 - mae: 0.3030 - val_loss: 0.3620 - val_mse: 1259.2601 - val_mae: 0.3620\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3335 - mse: 937.3788 - mae: 0.3335 - val_loss: 0.3630 - val_mse: 1259.2605 - val_mae: 0.3630\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5716 - mse: 40080580608.0000 - mae: 580.5707 - val_loss: 0.3597 - val_mse: 1259.2550 - val_mae: 0.3597\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7193 - mse: 20040292352.0000 - mae: 193.7193 - val_loss: 0.3641 - val_mse: 1259.2714 - val_mae: 0.3641\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3855 - mse: 1071.4635 - mae: 0.3855 - val_loss: 0.3660 - val_mse: 1259.2563 - val_mae: 0.3660\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4966 - mse: 1429.7765 - mae: 0.4966 - val_loss: 0.3875 - val_mse: 1259.2698 - val_mae: 0.3875\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3812 - mse: 25050363904.0000 - mae: 290.3815 - val_loss: 0.3678 - val_mse: 1259.2678 - val_mae: 0.3678\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3978 - mse: 25050363904.0000 - mae: 290.3976 - val_loss: 0.3660 - val_mse: 1259.2693 - val_mae: 0.3660\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4703 - mse: 1426.9281 - mae: 0.4703 - val_loss: 0.3708 - val_mse: 1259.2642 - val_mae: 0.3708\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2670 - mse: 429.4161 - mae: 0.2670 - val_loss: 0.3698 - val_mse: 1259.2681 - val_mae: 0.3698\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2684 - mse: 30060445696.0000 - mae: 387.2683 - val_loss: 0.3656 - val_mse: 1259.2665 - val_mae: 0.3656\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3914 - mse: 1020.7378 - mae: 0.3914 - val_loss: 0.3761 - val_mse: 1259.2677 - val_mae: 0.3761\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8909 - mse: 35070509056.0000 - mae: 483.8921 - val_loss: 0.3730 - val_mse: 1259.2690 - val_mae: 0.3730\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3619 - mse: 1003.2103 - mae: 0.3619 - val_loss: 0.3645 - val_mse: 1259.2646 - val_mae: 0.3645\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5122 - mse: 25050363904.0000 - mae: 290.5121 - val_loss: 0.3675 - val_mse: 1259.2612 - val_mae: 0.3675\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9738 - mse: 35070509056.0000 - mae: 483.9746 - val_loss: 0.3624 - val_mse: 1259.2604 - val_mae: 0.3624\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2604 - mse: 497.3052 - mae: 0.2604 - val_loss: 0.3649 - val_mse: 1259.2656 - val_mae: 0.3649\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4951 - mse: 25050365952.0000 - mae: 290.4951 - val_loss: 0.3644 - val_mse: 1259.2667 - val_mae: 0.3644\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2894 - mse: 722.0561 - mae: 0.2894 - val_loss: 0.3618 - val_mse: 1259.2703 - val_mae: 0.3618\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8564 - mse: 20040290304.0000 - mae: 193.8564 - val_loss: 0.3658 - val_mse: 1259.2668 - val_mae: 0.3658\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2462 - mse: 454.8774 - mae: 0.2462 - val_loss: 0.3625 - val_mse: 1259.2653 - val_mae: 0.3625\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4713 - mse: 1380.4711 - mae: 0.4713 - val_loss: 0.3605 - val_mse: 1259.2625 - val_mae: 0.3605\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3726 - mse: 25050363904.0000 - mae: 290.3726 - val_loss: 0.3612 - val_mse: 1259.2631 - val_mae: 0.3612\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4369 - mse: 25050365952.0000 - mae: 290.4370 - val_loss: 0.3616 - val_mse: 1259.2566 - val_mae: 0.3616\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3821 - mse: 1081.8665 - mae: 0.3821 - val_loss: 0.3624 - val_mse: 1259.2632 - val_mae: 0.3624\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2835 - mse: 715.3389 - mae: 0.2835 - val_loss: 0.3625 - val_mse: 1259.2546 - val_mae: 0.3625\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.3009 - mse: 45090652160.0000 - mae: 677.3017 - val_loss: 0.3610 - val_mse: 1259.2676 - val_mae: 0.3610\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1606 - mse: 30060435456.0000 - mae: 387.1604 - val_loss: 0.3608 - val_mse: 1259.2577 - val_mae: 0.3608\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3759 - mse: 1223.6068 - mae: 0.3759 - val_loss: 0.3619 - val_mse: 1259.2609 - val_mae: 0.3619\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3387 - mse: 968.4770 - mae: 0.3387 - val_loss: 0.3619 - val_mse: 1259.2614 - val_mae: 0.3619\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6111 - mse: 40080580608.0000 - mae: 580.6115 - val_loss: 0.3596 - val_mse: 1259.2581 - val_mae: 0.3596\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3190 - mse: 971.4191 - mae: 0.3190 - val_loss: 0.3596 - val_mse: 1259.2567 - val_mae: 0.3596\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1632 - mse: 30060435456.0000 - mae: 387.1635 - val_loss: 0.3609 - val_mse: 1259.2642 - val_mae: 0.3609\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3809 - mse: 1111.0098 - mae: 0.3809 - val_loss: 0.3606 - val_mse: 1259.2653 - val_mae: 0.3606\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5706 - mse: 40080584704.0000 - mae: 580.5705 - val_loss: 0.3593 - val_mse: 1259.2677 - val_mae: 0.3593\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4402 - mse: 1174.5807 - mae: 0.4402 - val_loss: 0.3729 - val_mse: 1259.2834 - val_mae: 0.3729\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4385 - mse: 25050363904.0000 - mae: 290.4386 - val_loss: 0.3643 - val_mse: 1259.2721 - val_mae: 0.3643\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2881 - mse: 583.2921 - mae: 0.2881 - val_loss: 0.3947 - val_mse: 1259.2611 - val_mae: 0.3947\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 870.7299 - mse: 55110799360.0000 - mae: 870.7283 - val_loss: 0.3750 - val_mse: 1259.2684 - val_mae: 0.3750\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3040 - mse: 775.5506 - mae: 0.3040 - val_loss: 0.3722 - val_mse: 1259.2649 - val_mae: 0.3722\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7916 - mse: 20040292352.0000 - mae: 193.7916 - val_loss: 0.3660 - val_mse: 1259.2556 - val_mae: 0.3660\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0951 - mse: 30060435456.0000 - mae: 387.0949 - val_loss: 0.3654 - val_mse: 1259.2728 - val_mae: 0.3654\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4158 - mse: 1276.0885 - mae: 0.4158 - val_loss: 0.3650 - val_mse: 1259.2761 - val_mae: 0.3650\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3804 - mse: 1177.1617 - mae: 0.3804 - val_loss: 0.3701 - val_mse: 1259.2654 - val_mae: 0.3701\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4592 - mse: 25050363904.0000 - mae: 290.4591 - val_loss: 0.3731 - val_mse: 1259.2621 - val_mae: 0.3731\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8519 - mse: 35070509056.0000 - mae: 483.8519 - val_loss: 0.3651 - val_mse: 1259.2625 - val_mae: 0.3651\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3103 - mse: 869.3452 - mae: 0.3103 - val_loss: 0.3622 - val_mse: 1259.2628 - val_mae: 0.3622\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8684 - mse: 35070513152.0000 - mae: 483.8692 - val_loss: 0.3702 - val_mse: 1259.2594 - val_mae: 0.3702\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4579 - mse: 1241.2224 - mae: 0.4579 - val_loss: 0.3711 - val_mse: 1259.2618 - val_mae: 0.3711\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7611 - mse: 35070509056.0000 - mae: 483.7619 - val_loss: 0.3664 - val_mse: 1259.2590 - val_mae: 0.3664\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.5181 - mse: 1850.6106 - mae: 0.5181 - val_loss: 0.3634 - val_mse: 1259.2623 - val_mae: 0.3634\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4715 - mse: 1500.9056 - mae: 0.4715 - val_loss: 0.3607 - val_mse: 1259.2604 - val_mae: 0.3607\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4065 - mse: 25050365952.0000 - mae: 290.4065 - val_loss: 0.3629 - val_mse: 1259.2505 - val_mae: 0.3629\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3766 - mse: 1082.2667 - mae: 0.3766 - val_loss: 0.3609 - val_mse: 1259.2606 - val_mae: 0.3609\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7726 - mse: 20040292352.0000 - mae: 193.7726 - val_loss: 0.3617 - val_mse: 1259.2606 - val_mae: 0.3617\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8062 - mse: 20040292352.0000 - mae: 193.8062 - val_loss: 0.3608 - val_mse: 1259.2589 - val_mae: 0.3608\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3670 - mse: 953.5411 - mae: 0.3670 - val_loss: 0.3606 - val_mse: 1259.2593 - val_mae: 0.3606\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3251 - mse: 928.7961 - mae: 0.3251 - val_loss: 0.3620 - val_mse: 1259.2621 - val_mae: 0.3620\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.0010 - mse: 50100727808.0000 - mae: 774.0007 - val_loss: 0.3609 - val_mse: 1259.2653 - val_mae: 0.3609\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3751 - mse: 1164.0326 - mae: 0.3751 - val_loss: 0.3608 - val_mse: 1259.2732 - val_mae: 0.3608\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8193 - mse: 35070509056.0000 - mae: 483.8191 - val_loss: 0.3609 - val_mse: 1259.2615 - val_mae: 0.3609\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2380 - mse: 45090652160.0000 - mae: 677.2375 - val_loss: 0.3598 - val_mse: 1259.2604 - val_mae: 0.3598\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3671 - mse: 1116.3552 - mae: 0.3671 - val_loss: 0.3623 - val_mse: 1259.2537 - val_mae: 0.3623\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5291 - mse: 40080580608.0000 - mae: 580.5292 - val_loss: 0.3590 - val_mse: 1259.2505 - val_mae: 0.3590\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3898 - mse: 1188.8767 - mae: 0.3898 - val_loss: 0.3601 - val_mse: 1259.2556 - val_mae: 0.3601\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.2202 - mse: 30060439552.0000 - mae: 387.2202 - val_loss: 0.3712 - val_mse: 1259.2648 - val_mae: 0.3712\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3724 - mse: 1018.7732 - mae: 0.3724 - val_loss: 0.3747 - val_mse: 1259.2631 - val_mae: 0.3747\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3709 - mse: 1146.0999 - mae: 0.3709 - val_loss: 0.3720 - val_mse: 1259.2616 - val_mae: 0.3720\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4397 - mse: 25050365952.0000 - mae: 290.4396 - val_loss: 0.3713 - val_mse: 1259.2715 - val_mae: 0.3713\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9233 - mse: 35070513152.0000 - mae: 483.9235 - val_loss: 0.3665 - val_mse: 1259.2673 - val_mae: 0.3665\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3480 - mse: 836.5560 - mae: 0.3480 - val_loss: 0.3715 - val_mse: 1259.2653 - val_mae: 0.3715\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6044 - mse: 40080584704.0000 - mae: 580.6042 - val_loss: 0.3646 - val_mse: 1259.2684 - val_mae: 0.3646\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3329 - mse: 833.6595 - mae: 0.3329 - val_loss: 0.3649 - val_mse: 1259.2539 - val_mae: 0.3649\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1788 - mse: 30060435456.0000 - mae: 387.1789 - val_loss: 0.3694 - val_mse: 1259.2616 - val_mae: 0.3694\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3042 - mse: 683.1758 - mae: 0.3042 - val_loss: 0.3629 - val_mse: 1259.2623 - val_mae: 0.3629\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3797 - mse: 1091.2092 - mae: 0.3797 - val_loss: 0.3654 - val_mse: 1259.2712 - val_mae: 0.3654\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5031 - mse: 25050365952.0000 - mae: 290.5031 - val_loss: 0.3634 - val_mse: 1259.2581 - val_mae: 0.3634\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9172 - mse: 35070509056.0000 - mae: 483.9170 - val_loss: 0.3623 - val_mse: 1259.2592 - val_mae: 0.3623\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3730 - mse: 860.1434 - mae: 0.3730 - val_loss: 0.3625 - val_mse: 1259.2533 - val_mae: 0.3625\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7401 - mse: 20040292352.0000 - mae: 193.7401 - val_loss: 0.3675 - val_mse: 1259.2688 - val_mae: 0.3675\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3862 - mse: 964.5711 - mae: 0.3862 - val_loss: 0.3628 - val_mse: 1259.2599 - val_mae: 0.3628\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4839 - mse: 25050365952.0000 - mae: 290.4839 - val_loss: 0.3615 - val_mse: 1259.2583 - val_mae: 0.3615\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3377 - mse: 917.5709 - mae: 0.3377 - val_loss: 0.3639 - val_mse: 1259.2725 - val_mae: 0.3639\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4608 - mse: 1503.8188 - mae: 0.4608 - val_loss: 0.3619 - val_mse: 1259.2455 - val_mae: 0.3619\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.7623 - mse: 35070513152.0000 - mae: 483.7627 - val_loss: 0.3652 - val_mse: 1259.2573 - val_mae: 0.3652\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3613 - mse: 1117.0675 - mae: 0.3613 - val_loss: 0.3707 - val_mse: 1273.8129 - val_mae: 0.3707\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5538 - mse: 40080580608.0000 - mae: 580.5535 - val_loss: 0.3615 - val_mse: 1259.2634 - val_mae: 0.3615\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1345 - mse: 30060435456.0000 - mae: 387.1344 - val_loss: 0.3605 - val_mse: 1259.2661 - val_mae: 0.3605\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4201 - mse: 1227.3320 - mae: 0.4201 - val_loss: 0.3641 - val_mse: 1259.2635 - val_mae: 0.3641\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6865 - mse: 40080580608.0000 - mae: 580.6860 - val_loss: 0.3614 - val_mse: 1259.2635 - val_mae: 0.3614\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3077 - mse: 666.7142 - mae: 0.3077 - val_loss: 0.3607 - val_mse: 1259.2623 - val_mae: 0.3607\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4342 - mse: 25050365952.0000 - mae: 290.4342 - val_loss: 0.3617 - val_mse: 1259.2604 - val_mae: 0.3617\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3753 - mse: 1101.4308 - mae: 0.3753 - val_loss: 0.3615 - val_mse: 1259.2642 - val_mae: 0.3615\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4525 - mse: 25050365952.0000 - mae: 290.4524 - val_loss: 0.3595 - val_mse: 1259.2456 - val_mae: 0.3595\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3524 - mse: 1011.1116 - mae: 0.3524 - val_loss: 0.3593 - val_mse: 1259.2598 - val_mae: 0.3593\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3964 - mse: 1057.1792 - mae: 0.3964 - val_loss: 0.3679 - val_mse: 1259.2764 - val_mae: 0.3679\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1178 - mse: 30060439552.0000 - mae: 387.1178 - val_loss: 0.3672 - val_mse: 1259.2682 - val_mae: 0.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4214 - mse: 25050365952.0000 - mae: 290.4218 - val_loss: 0.3660 - val_mse: 1259.2727 - val_mae: 0.3660\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3979 - mse: 1178.2612 - mae: 0.3979 - val_loss: 0.3668 - val_mse: 1259.2642 - val_mae: 0.3668\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1945 - mse: 30060439552.0000 - mae: 387.1946 - val_loss: 0.3642 - val_mse: 1259.2653 - val_mae: 0.3642\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3482 - mse: 1002.4147 - mae: 0.3482 - val_loss: 0.3668 - val_mse: 1259.2667 - val_mae: 0.3668\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9221 - mse: 35070509056.0000 - mae: 483.9230 - val_loss: 0.3636 - val_mse: 1259.2533 - val_mae: 0.3636\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2630 - mse: 612.3834 - mae: 0.2630 - val_loss: 0.3719 - val_mse: 1259.2604 - val_mae: 0.3719\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7757 - mse: 20040294400.0000 - mae: 193.7758 - val_loss: 0.3624 - val_mse: 1259.2570 - val_mae: 0.3624\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3312 - mse: 828.5171 - mae: 0.3312 - val_loss: 0.3741 - val_mse: 1259.2726 - val_mae: 0.3741\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3677 - mse: 25050363904.0000 - mae: 290.3679 - val_loss: 0.3623 - val_mse: 1259.2666 - val_mae: 0.3623\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4955 - mse: 1589.8350 - mae: 0.4955 - val_loss: 0.3659 - val_mse: 1259.2721 - val_mae: 0.3659\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1574 - mse: 30060439552.0000 - mae: 387.1573 - val_loss: 0.3663 - val_mse: 1259.2682 - val_mae: 0.3663\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3253 - mse: 811.9861 - mae: 0.3253 - val_loss: 0.3636 - val_mse: 1259.2629 - val_mae: 0.3636\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0811 - mse: 30060439552.0000 - mae: 387.0811 - val_loss: 0.3619 - val_mse: 1259.2616 - val_mae: 0.3619\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4778 - mse: 1470.7341 - mae: 0.4778 - val_loss: 0.3611 - val_mse: 1259.2623 - val_mae: 0.3611\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4143 - mse: 25050363904.0000 - mae: 290.4144 - val_loss: 0.3630 - val_mse: 1259.2709 - val_mae: 0.3630\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3972 - mse: 1120.9875 - mae: 0.3972 - val_loss: 0.3611 - val_mse: 1259.2642 - val_mae: 0.3611\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5985 - mse: 40080580608.0000 - mae: 580.5985 - val_loss: 0.3621 - val_mse: 1259.2526 - val_mae: 0.3621\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3864 - mse: 1017.9769 - mae: 0.3864 - val_loss: 0.3603 - val_mse: 1259.2599 - val_mae: 0.3603\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3939 - mse: 1284.2156 - mae: 0.3939 - val_loss: 0.3609 - val_mse: 1259.2598 - val_mae: 0.3609\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4183 - mse: 25050363904.0000 - mae: 290.4183 - val_loss: 0.3604 - val_mse: 1259.2524 - val_mae: 0.3604\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4580 - mse: 25050365952.0000 - mae: 290.4579 - val_loss: 0.3604 - val_mse: 1259.2687 - val_mae: 0.3604\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3730 - mse: 1013.8854 - mae: 0.3730 - val_loss: 0.3632 - val_mse: 1259.2605 - val_mae: 0.3632\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3410 - mse: 25050363904.0000 - mae: 290.3410 - val_loss: 0.3604 - val_mse: 1259.2720 - val_mae: 0.3604\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4648 - mse: 1437.7512 - mae: 0.4648 - val_loss: 0.3623 - val_mse: 1259.2670 - val_mae: 0.3623\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6186 - mse: 40080580608.0000 - mae: 580.6185 - val_loss: 0.3598 - val_mse: 1259.2648 - val_mae: 0.3598\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3074 - mse: 704.8163 - mae: 0.3074 - val_loss: 0.3676 - val_mse: 1259.2692 - val_mae: 0.3676\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3284 - mse: 1015.8011 - mae: 0.3284 - val_loss: 0.3625 - val_mse: 1259.2665 - val_mae: 0.3625\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8773 - mse: 35070509056.0000 - mae: 483.8775 - val_loss: 0.3600 - val_mse: 1259.2582 - val_mae: 0.3600\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.7703 - mse: 20040290304.0000 - mae: 193.7703 - val_loss: 0.3691 - val_mse: 1259.2655 - val_mae: 0.3691\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3843 - mse: 1019.7774 - mae: 0.3843 - val_loss: 0.3639 - val_mse: 1259.2590 - val_mae: 0.3639\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4846 - mse: 25050365952.0000 - mae: 290.4846 - val_loss: 0.3651 - val_mse: 1259.2666 - val_mae: 0.3651\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3423 - mse: 893.0380 - mae: 0.3423 - val_loss: 0.3645 - val_mse: 1259.2682 - val_mae: 0.3645\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3062 - mse: 766.1950 - mae: 0.3062 - val_loss: 0.3627 - val_mse: 1259.2631 - val_mae: 0.3627\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8232 - mse: 20040290304.0000 - mae: 193.8232 - val_loss: 0.3634 - val_mse: 1259.2622 - val_mae: 0.3634\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3704 - mse: 1022.2124 - mae: 0.3704 - val_loss: 0.3624 - val_mse: 1259.2571 - val_mae: 0.3624\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9383 - mse: 35070513152.0000 - mae: 483.9384 - val_loss: 0.3771 - val_mse: 1259.2673 - val_mae: 0.3771\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3583 - mse: 934.4760 - mae: 0.3583 - val_loss: 0.3622 - val_mse: 1259.2556 - val_mae: 0.3622\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8852 - mse: 35070509056.0000 - mae: 483.8853 - val_loss: 0.3694 - val_mse: 1259.2604 - val_mae: 0.3694\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.3633 - mse: 25050365952.0000 - mae: 290.3630 - val_loss: 0.3628 - val_mse: 1259.2623 - val_mae: 0.3628\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4681 - mse: 1423.6804 - mae: 0.4681 - val_loss: 0.3625 - val_mse: 1259.2594 - val_mae: 0.3625\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8072 - mse: 20040290304.0000 - mae: 193.8073 - val_loss: 0.3629 - val_mse: 1259.2690 - val_mae: 0.3629\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3578 - mse: 932.3893 - mae: 0.3578 - val_loss: 0.3637 - val_mse: 1259.2705 - val_mae: 0.3637\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1120 - mse: 30060435456.0000 - mae: 387.1120 - val_loss: 0.3646 - val_mse: 1259.2671 - val_mae: 0.3646\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4524 - mse: 1210.0183 - mae: 0.4524 - val_loss: 0.3674 - val_mse: 1259.2544 - val_mae: 0.3674\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4066 - mse: 1172.2399 - mae: 0.4066 - val_loss: 0.3656 - val_mse: 1259.2572 - val_mae: 0.3656\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4469 - mse: 25050363904.0000 - mae: 290.4470 - val_loss: 0.3611 - val_mse: 1259.2631 - val_mae: 0.3611\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7750 - mse: 20040292352.0000 - mae: 193.7749 - val_loss: 0.3638 - val_mse: 1259.2507 - val_mae: 0.3638\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3679 - mse: 1086.8135 - mae: 0.3679 - val_loss: 0.3666 - val_mse: 1259.2653 - val_mae: 0.3666\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2881 - mse: 664.0914 - mae: 0.2881 - val_loss: 0.3643 - val_mse: 1259.2605 - val_mae: 0.3643\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5196 - mse: 25050365952.0000 - mae: 290.5198 - val_loss: 0.3620 - val_mse: 1259.2595 - val_mae: 0.3620\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8585 - mse: 35070509056.0000 - mae: 483.8591 - val_loss: 0.3599 - val_mse: 1259.2656 - val_mae: 0.3599\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4338 - mse: 1456.4835 - mae: 0.4338 - val_loss: 0.3603 - val_mse: 1259.2581 - val_mae: 0.3603\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3306 - mse: 930.8922 - mae: 0.3306 - val_loss: 0.3638 - val_mse: 1259.2457 - val_mae: 0.3638\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1616 - mse: 30060435456.0000 - mae: 387.1617 - val_loss: 0.3615 - val_mse: 1259.2633 - val_mae: 0.3615\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5854 - mse: 40080580608.0000 - mae: 580.5855 - val_loss: 0.3603 - val_mse: 1259.2690 - val_mae: 0.3603\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3258 - mse: 974.0143 - mae: 0.3258 - val_loss: 0.3621 - val_mse: 1259.2561 - val_mae: 0.3621\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3555 - mse: 1158.0490 - mae: 0.3555 - val_loss: 0.3621 - val_mse: 1259.2578 - val_mae: 0.3621\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4287 - mse: 25050363904.0000 - mae: 290.4287 - val_loss: 0.3589 - val_mse: 1259.2561 - val_mae: 0.3589\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3848 - mse: 975.5751 - mae: 0.3848 - val_loss: 0.3805 - val_mse: 1259.2766 - val_mae: 0.3805\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1822 - mse: 30060439552.0000 - mae: 387.1825 - val_loss: 0.3683 - val_mse: 1259.2721 - val_mae: 0.3683\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3478 - mse: 857.4081 - mae: 0.3478 - val_loss: 0.3654 - val_mse: 1259.2667 - val_mae: 0.3654\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5907 - mse: 40080580608.0000 - mae: 580.5915 - val_loss: 0.3644 - val_mse: 1259.2706 - val_mae: 0.3644\n",
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4601 - mse: 1297.6752 - mae: 0.4601 - val_loss: 0.3622 - val_mse: 1259.2638 - val_mae: 0.3622\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7254 - mse: 20040292352.0000 - mae: 193.7254 - val_loss: 0.3733 - val_mse: 1259.2563 - val_mae: 0.3733\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2879 - mse: 645.5625 - mae: 0.2879 - val_loss: 0.3618 - val_mse: 1259.2670 - val_mae: 0.3618\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9771 - mse: 35070509056.0000 - mae: 483.9779 - val_loss: 0.3626 - val_mse: 1259.2678 - val_mae: 0.3626\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4248 - mse: 1300.4700 - mae: 0.4248 - val_loss: 0.3641 - val_mse: 1259.2657 - val_mae: 0.3641\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7390 - mse: 20040292352.0000 - mae: 193.7391 - val_loss: 0.3649 - val_mse: 1259.2695 - val_mae: 0.3649\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3831 - mse: 1125.2747 - mae: 0.3831 - val_loss: 0.3631 - val_mse: 1259.2616 - val_mae: 0.3631\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1161 - mse: 30060435456.0000 - mae: 387.1161 - val_loss: 0.3652 - val_mse: 1259.2604 - val_mae: 0.3652\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4418 - mse: 1453.7727 - mae: 0.4418 - val_loss: 0.3686 - val_mse: 1259.2590 - val_mae: 0.3686\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.6769 - mse: 20040292352.0000 - mae: 193.6768 - val_loss: 0.3610 - val_mse: 1259.2749 - val_mae: 0.3610\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3856 - mse: 1042.8911 - mae: 0.3856 - val_loss: 0.3676 - val_mse: 1259.2629 - val_mae: 0.3676\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5063 - mse: 40080580608.0000 - mae: 580.5074 - val_loss: 0.3714 - val_mse: 1259.2522 - val_mae: 0.3714\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5205 - mse: 25050363904.0000 - mae: 290.5205 - val_loss: 0.3622 - val_mse: 1259.2733 - val_mae: 0.3622\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2993 - mse: 612.9626 - mae: 0.2993 - val_loss: 0.3597 - val_mse: 1259.2653 - val_mae: 0.3597\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4277 - mse: 1326.5992 - mae: 0.4277 - val_loss: 0.3642 - val_mse: 1259.2645 - val_mae: 0.3642\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8276 - mse: 35070509056.0000 - mae: 483.8278 - val_loss: 0.3607 - val_mse: 1259.2577 - val_mae: 0.3607\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3504 - mse: 889.8384 - mae: 0.3504 - val_loss: 0.3652 - val_mse: 1259.2643 - val_mae: 0.3652\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1826 - mse: 30060439552.0000 - mae: 387.1826 - val_loss: 0.3622 - val_mse: 1259.2548 - val_mae: 0.3622\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4544 - mse: 25050365952.0000 - mae: 290.4544 - val_loss: 0.3601 - val_mse: 1259.2654 - val_mae: 0.3601\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3795 - mse: 1048.6951 - mae: 0.3795 - val_loss: 0.3628 - val_mse: 1259.2587 - val_mae: 0.3628\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1197 - mse: 30060435456.0000 - mae: 387.1196 - val_loss: 0.3677 - val_mse: 1259.2679 - val_mae: 0.3677\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4122 - mse: 1203.0131 - mae: 0.4122 - val_loss: 0.3596 - val_mse: 1259.2657 - val_mae: 0.3596\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3304 - mse: 868.7560 - mae: 0.3304 - val_loss: 0.3620 - val_mse: 1259.2629 - val_mae: 0.3620\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2018 - mse: 30060435456.0000 - mae: 387.2018 - val_loss: 0.3612 - val_mse: 1259.2627 - val_mae: 0.3612\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9064 - mse: 35070509056.0000 - mae: 483.9062 - val_loss: 0.3593 - val_mse: 1259.2671 - val_mae: 0.3593\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3352 - mse: 1042.4036 - mae: 0.3352 - val_loss: 0.3606 - val_mse: 1259.2650 - val_mae: 0.3606\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/30\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3210 - mse: 544.1800 - mae: 0.3210 - val_loss: 0.3744 - val_mse: 1259.2727 - val_mae: 0.3744\n",
      "Epoch 2/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4843 - mse: 25050363904.0000 - mae: 290.4840 - val_loss: 0.3654 - val_mse: 1259.2639 - val_mae: 0.3654\n",
      "Epoch 3/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1705 - mse: 30060439552.0000 - mae: 387.1707 - val_loss: 0.3653 - val_mse: 1259.2626 - val_mae: 0.3653\n",
      "Epoch 4/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3282 - mse: 879.7169 - mae: 0.3282 - val_loss: 0.3655 - val_mse: 1259.2704 - val_mae: 0.3655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4288 - mse: 25050363904.0000 - mae: 290.4287 - val_loss: 0.3664 - val_mse: 1259.2556 - val_mae: 0.3664\n",
      "Epoch 6/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3878 - mse: 1031.6949 - mae: 0.3878 - val_loss: 0.3732 - val_mse: 1259.2544 - val_mae: 0.3732\n",
      "Epoch 7/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1284 - mse: 30060439552.0000 - mae: 387.1285 - val_loss: 0.3659 - val_mse: 1259.2745 - val_mae: 0.3659\n",
      "Epoch 8/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4126 - mse: 1227.6304 - mae: 0.4126 - val_loss: 0.3630 - val_mse: 1259.2769 - val_mae: 0.3630\n",
      "Epoch 9/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3480 - mse: 767.9404 - mae: 0.3480 - val_loss: 0.3653 - val_mse: 1259.2648 - val_mae: 0.3653\n",
      "Epoch 10/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5305 - mse: 25050365952.0000 - mae: 290.5304 - val_loss: 0.3706 - val_mse: 1259.2599 - val_mae: 0.3706\n",
      "Epoch 11/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3596 - mse: 1002.6157 - mae: 0.3596 - val_loss: 0.3677 - val_mse: 1259.2639 - val_mae: 0.3677\n",
      "Epoch 12/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5208 - mse: 25050363904.0000 - mae: 290.5208 - val_loss: 0.3614 - val_mse: 1259.2622 - val_mae: 0.3614\n",
      "Epoch 13/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4624 - mse: 1476.1075 - mae: 0.4624 - val_loss: 0.3653 - val_mse: 1259.2689 - val_mae: 0.3653\n",
      "Epoch 14/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3439 - mse: 25050365952.0000 - mae: 290.3438 - val_loss: 0.3605 - val_mse: 1259.2632 - val_mae: 0.3605\n",
      "Epoch 15/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4553 - mse: 25050365952.0000 - mae: 290.4551 - val_loss: 0.3623 - val_mse: 1259.2584 - val_mae: 0.3623\n",
      "Epoch 16/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4052 - mse: 1085.2759 - mae: 0.4052 - val_loss: 0.3624 - val_mse: 1259.2673 - val_mae: 0.3624\n",
      "Epoch 17/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3238 - mse: 799.5316 - mae: 0.3238 - val_loss: 0.3638 - val_mse: 1259.2684 - val_mae: 0.3638\n",
      "Epoch 18/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6145 - mse: 40080580608.0000 - mae: 580.6143 - val_loss: 0.3620 - val_mse: 1259.2653 - val_mae: 0.3620\n",
      "Epoch 19/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3400 - mse: 946.4777 - mae: 0.3400 - val_loss: 0.3640 - val_mse: 1259.2621 - val_mae: 0.3640\n",
      "Epoch 20/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7830 - mse: 20040292352.0000 - mae: 193.7831 - val_loss: 0.3599 - val_mse: 1259.2593 - val_mae: 0.3599\n",
      "Epoch 21/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3867 - mse: 1171.5675 - mae: 0.3867 - val_loss: 0.3699 - val_mse: 1259.2559 - val_mae: 0.3699\n",
      "Epoch 22/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4437 - mse: 25050365952.0000 - mae: 290.4436 - val_loss: 0.3632 - val_mse: 1259.2600 - val_mae: 0.3632\n",
      "Epoch 23/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8456 - mse: 35070509056.0000 - mae: 483.8458 - val_loss: 0.3607 - val_mse: 1259.2665 - val_mae: 0.3607\n",
      "Epoch 24/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3368 - mse: 1050.1625 - mae: 0.3368 - val_loss: 0.3705 - val_mse: 1259.2605 - val_mae: 0.3705\n",
      "Epoch 25/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4120 - mse: 1401.8380 - mae: 0.4120 - val_loss: 0.3617 - val_mse: 1259.2676 - val_mae: 0.3617\n",
      "Epoch 26/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.3706 - mse: 25050363904.0000 - mae: 290.3707 - val_loss: 0.3651 - val_mse: 1259.2616 - val_mae: 0.3651\n",
      "Epoch 27/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9839 - mse: 35070509056.0000 - mae: 483.9842 - val_loss: 0.3646 - val_mse: 1259.2655 - val_mae: 0.3646\n",
      "Epoch 28/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2501 - mse: 583.9889 - mae: 0.2501 - val_loss: 0.3670 - val_mse: 1259.2644 - val_mae: 0.3670\n",
      "Epoch 29/30\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3274 - mse: 988.5288 - mae: 0.3274 - val_loss: 0.3619 - val_mse: 1259.2654 - val_mae: 0.3619\n",
      "Epoch 30/30\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6289 - mse: 40080580608.0000 - mae: 580.6288 - val_loss: 0.3601 - val_mse: 1259.2615 - val_mae: 0.3601\n"
     ]
    }
   ],
   "source": [
    "snap_dirs = ['/tmp/snapshot/snap_{}'.format(i) for i in range(30)]\n",
    "\n",
    "for snap_dir in snap_dirs:\n",
    "    run_snapshot(snap_dir, num=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirs = [[d + '__{}/best_weights.h5'.format(i) for i in range(30)] for d in snap_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:17<00:00,  1.75it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.86it/s]\n",
      "100%|██████████| 30/30 [00:17<00:00,  1.67it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.87it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n",
      "100%|██████████| 30/30 [00:15<00:00,  1.88it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.66it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.86it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.83it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.83it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(30):\n",
    "    snap_model_dirs = model_dirs[i]\n",
    "    \n",
    "    preds_snap = ensemble_preds(snap_model_dirs, X_test)\n",
    "\n",
    "    add_snap = [evaluate_ensemble(preds_snap[:j+1], y_test) for j in range(30)]\n",
    "    \n",
    "    results.append(add_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa274155898>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in results:\n",
    "    plt.plot(r)\n",
    "\n",
    "    \n",
    "plt.plot(add_no_snap[:30], c='black', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.83it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.81it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.81it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.85it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.84it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.64it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.86it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.83it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
      "100%|██████████| 30/30 [00:16<00:00,  1.82it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
      "100%|██████████| 30/30 [00:18<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "results_tuned = []\n",
    "\n",
    "for i in range(30):\n",
    "    snap_model_dirs = model_dirs[i]\n",
    "    \n",
    "    preds_snap = ensemble_preds(snap_model_dirs, X_test)\n",
    "  \n",
    "    results_tuned.append(evaluate_ensemble(preds_snap[2:10], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa2a372e7f0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.955389942546097"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_snap_1 = ensemble_preds(model_dirs[0][2:10], X_test)\n",
    "preds_snap_2 = ensemble_preds(model_dirs[1][2:10], X_test)\n",
    "\n",
    "preds_snap = np.r_[preds_snap_1, preds_snap_2]\n",
    "\n",
    "r = evaluate_ensemble(preds_snap, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.059560070586063"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.89it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.28it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "i1 = np.random.choice(30, size=100)\n",
    "i2 = np.random.choice(30, size=100)\n",
    "\n",
    "results_multi = []\n",
    "\n",
    "for i in range(100):\n",
    "    preds_snap_1 = ensemble_preds(model_dirs[i1[i]][2:10], X_test)\n",
    "    preds_snap_2 = ensemble_preds(model_dirs[i2[i]][2:10], X_test)\n",
    "\n",
    "    preds_snap = np.r_[preds_snap_1, preds_snap_2]\n",
    "\n",
    "    results_multi.append(evaluate_ensemble(preds_snap, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa6fc827400>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results_tuned)\n",
    "\n",
    "sns.distplot(results_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.72it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.71it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.76it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.70it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.78it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.85it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "i1 = np.random.choice(30, size=100)\n",
    "i2 = np.random.choice(30, size=100)\n",
    "i3 = np.random.choice(30, size=100)\n",
    "i4 = np.random.choice(30, size=100)\n",
    "i5 = np.random.choice(30, size=100)\n",
    "\n",
    "results_multi_3 = []\n",
    "results_multi_4 = []\n",
    "results_multi_5 = []\n",
    "\n",
    "for i in range(100):\n",
    "    preds_snap_1 = ensemble_preds(model_dirs[i1[i]][2:10], X_test)\n",
    "    preds_snap_2 = ensemble_preds(model_dirs[i2[i]][2:10], X_test)\n",
    "    preds_snap_3 = ensemble_preds(model_dirs[i3[i]][2:10], X_test)\n",
    "    preds_snap_4 = ensemble_preds(model_dirs[i4[i]][2:10], X_test)\n",
    "    preds_snap_5 = ensemble_preds(model_dirs[i5[i]][2:10], X_test)\n",
    "\n",
    "    preds_snap = np.r_[preds_snap_1, preds_snap_2, preds_snap_3]\n",
    "    results_multi_3.append(evaluate_ensemble(preds_snap, y_test))\n",
    "\n",
    "    preds_snap = np.r_[preds_snap, preds_snap_4]\n",
    "    results_multi_4.append(evaluate_ensemble(preds_snap, y_test))\n",
    "\n",
    "    preds_snap = np.r_[preds_snap, preds_snap_5]\n",
    "    results_multi_5.append(evaluate_ensemble(preds_snap, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa6fd07ed30>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results_tuned)\n",
    "sns.distplot(results_multi)\n",
    "sns.distplot(results_multi_3)\n",
    "sns.distplot(results_multi_4)\n",
    "sns.distplot(results_multi_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1e1985ae48>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [cosine_annealing(e) for e in range(1000)]\n",
    "\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snapshot(snap_dir='/tmp/snapshot/snap/', num=100):\n",
    "    \n",
    "    for i in range(num):\n",
    "\n",
    "        run_dir = snap_dir + '__' + str(i)\n",
    "\n",
    "        if not os.path.isdir(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "\n",
    "        model = networks.convolutional_ae_4_layer(hparams, ['mse', 'mae'])\n",
    "\n",
    "    callbacks = [utils.callbacks.SnapshotEnsemble(snap_dir, len(train_set)//batch_size+1,\n",
    "                                                  n_cycles=num, max_epochs=num+5)]\n",
    "\n",
    "    model.fit(train_set, epochs=num+5, steps_per_epoch=len(train_set)//batch_size+1,\n",
    "          validation_steps=len(test_set)//batch_size+1, validation_data=test_set,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 290.4991 - mse: 25050365952.0000 - mae: 290.4992 - val_loss: 0.3689 - val_mse: 1259.2704 - val_mae: 0.3689\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3285 - mse: 779.8119 - mae: 0.3285 - val_loss: 0.3616 - val_mse: 1259.2638 - val_mae: 0.3616\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3612 - mse: 985.9623 - mae: 0.3612 - val_loss: 0.3608 - val_mse: 1259.2644 - val_mae: 0.3608\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4886 - mse: 25050363904.0000 - mae: 290.4887 - val_loss: 0.3605 - val_mse: 1259.2646 - val_mae: 0.3605\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3417 - mse: 943.7161 - mae: 0.3417 - val_loss: 0.3602 - val_mse: 1259.2661 - val_mae: 0.3602\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0169 - mse: 60120870912.0000 - mae: 774.0173 - val_loss: 0.3599 - val_mse: 1259.2617 - val_mae: 0.3599\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3473 - mse: 45090652160.0000 - mae: 677.3480 - val_loss: 0.3597 - val_mse: 1259.2633 - val_mae: 0.3597\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3073 - mse: 748.7079 - mae: 0.3073 - val_loss: 0.3595 - val_mse: 1259.2648 - val_mae: 0.3595\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4071 - mse: 1232.2219 - mae: 0.4071 - val_loss: 0.3594 - val_mse: 1259.2633 - val_mae: 0.3594\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 677.2919 - mse: 45090652160.0000 - mae: 677.2923 - val_loss: 0.3593 - val_mse: 1259.2605 - val_mae: 0.3593\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7692 - mse: 35070509056.0000 - mae: 483.7688 - val_loss: 0.3591 - val_mse: 1259.2644 - val_mae: 0.3591\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4022 - mse: 1306.5302 - mae: 0.4022 - val_loss: 0.3590 - val_mse: 1259.2638 - val_mae: 0.3590\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1746 - mse: 30060435456.0000 - mae: 387.1747 - val_loss: 0.3589 - val_mse: 1259.2625 - val_mae: 0.3589\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4049 - mse: 1195.9569 - mae: 0.4049 - val_loss: 0.3588 - val_mse: 1259.2626 - val_mae: 0.3588\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8948 - mse: 35070509056.0000 - mae: 483.8946 - val_loss: 0.3588 - val_mse: 1259.2629 - val_mae: 0.3588\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3662 - mse: 943.3118 - mae: 0.3662 - val_loss: 0.3586 - val_mse: 1259.2599 - val_mae: 0.3586\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2342 - mse: 448.4147 - mae: 0.2342 - val_loss: 0.3585 - val_mse: 1259.2646 - val_mae: 0.3585\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.9137 - mse: 20040290304.0000 - mae: 193.9138 - val_loss: 0.3584 - val_mse: 1259.2635 - val_mae: 0.3584\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3276 - mse: 798.4902 - mae: 0.3276 - val_loss: 0.3584 - val_mse: 1259.2622 - val_mae: 0.3584\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9551 - mse: 35070509056.0000 - mae: 483.9552 - val_loss: 0.3582 - val_mse: 1259.2635 - val_mae: 0.3582\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3601 - mse: 1051.9709 - mae: 0.3601 - val_loss: 0.3581 - val_mse: 1259.2615 - val_mae: 0.3581\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1230 - mse: 30060435456.0000 - mae: 387.1230 - val_loss: 0.3580 - val_mse: 1259.2605 - val_mae: 0.3580\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2674 - mse: 659.8954 - mae: 0.2674 - val_loss: 0.3580 - val_mse: 1259.2642 - val_mae: 0.3580\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2633 - mse: 30060439552.0000 - mae: 387.2632 - val_loss: 0.3579 - val_mse: 1259.2635 - val_mae: 0.3579\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3193 - mse: 798.6526 - mae: 0.3193 - val_loss: 0.3579 - val_mse: 1259.2592 - val_mae: 0.3579\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2305 - mse: 30060435456.0000 - mae: 387.2305 - val_loss: 0.3578 - val_mse: 1259.2635 - val_mae: 0.3578\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4773 - mse: 25050363904.0000 - mae: 290.4774 - val_loss: 0.3578 - val_mse: 1259.2620 - val_mae: 0.3578\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3653 - mse: 1012.5217 - mae: 0.3653 - val_loss: 0.3576 - val_mse: 1259.2585 - val_mae: 0.3576\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8804 - mse: 35070509056.0000 - mae: 483.8795 - val_loss: 0.3576 - val_mse: 1259.2627 - val_mae: 0.3576\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3405 - mse: 909.4683 - mae: 0.3405 - val_loss: 0.3575 - val_mse: 1259.2629 - val_mae: 0.3575\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3450 - mse: 1010.7985 - mae: 0.3450 - val_loss: 0.3574 - val_mse: 1259.2599 - val_mae: 0.3574\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8904 - mse: 35070509056.0000 - mae: 483.8901 - val_loss: 0.3574 - val_mse: 1259.2598 - val_mae: 0.3574\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3442 - mse: 876.9293 - mae: 0.3442 - val_loss: 0.3574 - val_mse: 1259.2626 - val_mae: 0.3574\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2029 - mse: 30060439552.0000 - mae: 387.2029 - val_loss: 0.3573 - val_mse: 1259.2611 - val_mae: 0.3573\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1440 - mse: 30060435456.0000 - mae: 387.1441 - val_loss: 0.3574 - val_mse: 1259.2592 - val_mae: 0.3574\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3530 - mse: 1079.5548 - mae: 0.3530 - val_loss: 0.3571 - val_mse: 1259.2603 - val_mae: 0.3571\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1933 - mse: 30060435456.0000 - mae: 387.1935 - val_loss: 0.3572 - val_mse: 1259.2585 - val_mae: 0.3572\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3671 - mse: 1027.6625 - mae: 0.3671 - val_loss: 0.3572 - val_mse: 1259.2612 - val_mae: 0.3572\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7379 - mse: 20040290304.0000 - mae: 193.7379 - val_loss: 0.3572 - val_mse: 1259.2596 - val_mae: 0.3572\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3370 - mse: 905.1113 - mae: 0.3370 - val_loss: 0.3571 - val_mse: 1259.2623 - val_mae: 0.3571\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3067 - mse: 841.8380 - mae: 0.3067 - val_loss: 0.3572 - val_mse: 1259.2601 - val_mae: 0.3572\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6199 - mse: 40080580608.0000 - mae: 580.6193 - val_loss: 0.3571 - val_mse: 1259.2601 - val_mae: 0.3571\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8683 - mse: 35070509056.0000 - mae: 483.8676 - val_loss: 0.3572 - val_mse: 1259.2595 - val_mae: 0.3572\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3518 - mse: 959.3959 - mae: 0.3518 - val_loss: 0.3571 - val_mse: 1259.2617 - val_mae: 0.3571\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7994 - mse: 45090652160.0000 - mae: 483.7988 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4306 - mse: 1351.6121 - mae: 0.4306 - val_loss: 0.3571 - val_mse: 1259.2612 - val_mae: 0.3571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4568 - mse: 1473.6893 - mae: 0.4568 - val_loss: 0.3572 - val_mse: 1259.2594 - val_mae: 0.3572\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5082 - mse: 40080580608.0000 - mae: 580.5075 - val_loss: 0.3570 - val_mse: 1259.2599 - val_mae: 0.3570\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9154 - mse: 35070509056.0000 - mae: 483.9147 - val_loss: 0.3570 - val_mse: 1259.2589 - val_mae: 0.3570\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3097 - mse: 873.9026 - mae: 0.3097 - val_loss: 0.3570 - val_mse: 1259.2593 - val_mae: 0.3570\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7581 - mse: 35070509056.0000 - mae: 483.7576 - val_loss: 0.3571 - val_mse: 1259.2610 - val_mae: 0.3571\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4548 - mse: 1470.1598 - mae: 0.4548 - val_loss: 0.3570 - val_mse: 1259.2623 - val_mae: 0.3570\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3477 - mse: 924.1386 - mae: 0.3477 - val_loss: 0.3572 - val_mse: 1259.2607 - val_mae: 0.3572\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1728 - mse: 30060435456.0000 - mae: 387.1729 - val_loss: 0.3571 - val_mse: 1259.2542 - val_mae: 0.3571\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2629 - mse: 720.8060 - mae: 0.2629 - val_loss: 0.3573 - val_mse: 1259.2585 - val_mae: 0.3573\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2239 - mse: 30060435456.0000 - mae: 387.2239 - val_loss: 0.3572 - val_mse: 1259.2570 - val_mae: 0.3572\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8520 - mse: 35070509056.0000 - mae: 483.8519 - val_loss: 0.3573 - val_mse: 1259.2607 - val_mae: 0.3573\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3598 - mse: 1051.7892 - mae: 0.3598 - val_loss: 0.3573 - val_mse: 1259.2562 - val_mae: 0.3573\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5326 - mse: 25050363904.0000 - mae: 290.5327 - val_loss: 0.3574 - val_mse: 1259.2572 - val_mae: 0.3574\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2457 - mse: 474.9157 - mae: 0.2457 - val_loss: 0.3573 - val_mse: 1259.2622 - val_mae: 0.3573\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4345 - mse: 1244.3214 - mae: 0.4345 - val_loss: 0.3574 - val_mse: 1259.2607 - val_mae: 0.3574\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8055 - mse: 35070509056.0000 - mae: 483.8054 - val_loss: 0.3572 - val_mse: 1259.2618 - val_mae: 0.3572\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4534 - mse: 25050365952.0000 - mae: 290.4535 - val_loss: 0.3574 - val_mse: 1259.2589 - val_mae: 0.3574\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3417 - mse: 956.2205 - mae: 0.3417 - val_loss: 0.3575 - val_mse: 1259.2620 - val_mae: 0.3575\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8076 - mse: 35070509056.0000 - mae: 483.8066 - val_loss: 0.3576 - val_mse: 1259.2610 - val_mae: 0.3576\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4295 - mse: 1405.2197 - mae: 0.4295 - val_loss: 0.3573 - val_mse: 1259.2605 - val_mae: 0.3573\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8717 - mse: 35070509056.0000 - mae: 483.8701 - val_loss: 0.3576 - val_mse: 1259.2623 - val_mae: 0.3576\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3700 - mse: 965.5297 - mae: 0.3700 - val_loss: 0.3574 - val_mse: 1259.2622 - val_mae: 0.3574\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3666 - mse: 1123.2272 - mae: 0.3666 - val_loss: 0.3575 - val_mse: 1259.2627 - val_mae: 0.3575\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4194 - mse: 25050363904.0000 - mae: 290.4192 - val_loss: 0.3574 - val_mse: 1259.2627 - val_mae: 0.3574\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3464 - mse: 986.8465 - mae: 0.3464 - val_loss: 0.3577 - val_mse: 1259.2590 - val_mae: 0.3577\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5572 - mse: 40080580608.0000 - mae: 580.5568 - val_loss: 0.3575 - val_mse: 1259.2593 - val_mae: 0.3575\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8497 - mse: 35070509056.0000 - mae: 483.8481 - val_loss: 0.3577 - val_mse: 1259.2621 - val_mae: 0.3577\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3262 - mse: 1069.3767 - mae: 0.3262 - val_loss: 0.3576 - val_mse: 1259.2625 - val_mae: 0.3576\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3271 - mse: 45090652160.0000 - mae: 677.3258 - val_loss: 0.3577 - val_mse: 1259.2616 - val_mae: 0.3576\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2885 - mse: 872.4600 - mae: 0.2885 - val_loss: 0.3577 - val_mse: 1259.2614 - val_mae: 0.3577\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3925 - mse: 25050365952.0000 - mae: 290.3926 - val_loss: 0.3579 - val_mse: 1259.2620 - val_mae: 0.3579\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3973 - mse: 1183.4056 - mae: 0.3973 - val_loss: 0.3577 - val_mse: 1259.2615 - val_mae: 0.3577\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.3982 - mse: 25050365952.0000 - mae: 290.3982 - val_loss: 0.3577 - val_mse: 1259.2598 - val_mae: 0.3577\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3827 - mse: 1200.7324 - mae: 0.3827 - val_loss: 0.3578 - val_mse: 1259.2612 - val_mae: 0.3578\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2669 - mse: 690.8525 - mae: 0.2669 - val_loss: 0.3577 - val_mse: 1259.2609 - val_mae: 0.3577\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2338 - mse: 30060435456.0000 - mae: 387.2338 - val_loss: 0.3581 - val_mse: 1259.2598 - val_mae: 0.3581\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5648 - mse: 25050365952.0000 - mae: 290.5648 - val_loss: 0.3579 - val_mse: 1259.2573 - val_mae: 0.3579\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2321 - mse: 524.7920 - mae: 0.2321 - val_loss: 0.3577 - val_mse: 1259.2610 - val_mae: 0.3577\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4073 - mse: 1265.1942 - mae: 0.4073 - val_loss: 0.3579 - val_mse: 1259.2601 - val_mae: 0.3579\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.3862 - mse: 25050365952.0000 - mae: 290.3862 - val_loss: 0.3580 - val_mse: 1259.2618 - val_mae: 0.3580\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3329 - mse: 806.5642 - mae: 0.3329 - val_loss: 0.3580 - val_mse: 1259.2622 - val_mae: 0.3580\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 483.8909 - mse: 35070513152.0000 - mae: 483.8891 - val_loss: 0.3579 - val_mse: 1259.2589 - val_mae: 0.3579\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5460 - mse: 25050363904.0000 - mae: 290.5459 - val_loss: 0.3579 - val_mse: 1259.2633 - val_mae: 0.3579\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3103 - mse: 753.2450 - mae: 0.3103 - val_loss: 0.3578 - val_mse: 1259.2612 - val_mae: 0.3578\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3128 - mse: 742.7287 - mae: 0.3128 - val_loss: 0.3580 - val_mse: 1259.2631 - val_mae: 0.3580\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2195 - mse: 30060435456.0000 - mae: 387.2196 - val_loss: 0.3578 - val_mse: 1259.2643 - val_mae: 0.3578\n",
      "Epoch 93/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2738 - mse: 620.5303 - mae: 0.2738 - val_loss: 0.3581 - val_mse: 1259.2594 - val_mae: 0.3581\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5653 - mse: 25050363904.0000 - mae: 290.5650 - val_loss: 0.3578 - val_mse: 1259.2626 - val_mae: 0.3578\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.5076 - mse: 25050365952.0000 - mae: 290.5076 - val_loss: 0.3583 - val_mse: 1259.2616 - val_mae: 0.3583\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.2595 - mse: 658.4157 - mae: 0.2595 - val_loss: 0.3582 - val_mse: 1259.2629 - val_mae: 0.3582\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4590 - mse: 1471.1921 - mae: 0.4590 - val_loss: 0.3581 - val_mse: 1259.2607 - val_mae: 0.3581\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1374 - mse: 30060435456.0000 - mae: 387.1375 - val_loss: 0.3580 - val_mse: 1259.2618 - val_mae: 0.3580\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6356 - mse: 20040292352.0000 - mae: 193.6356 - val_loss: 0.3583 - val_mse: 1259.2633 - val_mae: 0.3583\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4727 - mse: 1588.9856 - mae: 0.4727 - val_loss: 0.3582 - val_mse: 1259.2578 - val_mae: 0.3582\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4627 - mse: 1460.3823 - mae: 0.4627 - val_loss: 0.3644 - val_mse: 1259.2850 - val_mae: 0.3644\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1073 - mse: 30060435456.0000 - mae: 387.1073 - val_loss: 0.3614 - val_mse: 1259.2651 - val_mae: 0.3614\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3705 - mse: 898.1005 - mae: 0.3705 - val_loss: 0.3607 - val_mse: 1259.2642 - val_mae: 0.3607\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8806 - mse: 35070513152.0000 - mae: 483.8817 - val_loss: 0.3603 - val_mse: 1259.2653 - val_mae: 0.3603\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 580.6592 - mse: 40080580608.0000 - mae: 580.6600 - val_loss: 0.3601 - val_mse: 1259.2639 - val_mae: 0.3601\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2996 - mse: 683.2167 - mae: 0.2996 - val_loss: 0.3997 - val_mse: 1478.2689 - val_mae: 0.3997\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3823 - mse: 25050365952.0000 - mae: 290.3823 - val_loss: 0.3596 - val_mse: 1259.2623 - val_mae: 0.3596\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4283 - mse: 1330.4429 - mae: 0.4283 - val_loss: 0.3595 - val_mse: 1259.2633 - val_mae: 0.3595\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8051 - mse: 20040292352.0000 - mae: 193.8051 - val_loss: 0.3594 - val_mse: 1259.2629 - val_mae: 0.3594\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3203 - mse: 922.0565 - mae: 0.3203 - val_loss: 0.3592 - val_mse: 1259.2633 - val_mae: 0.3592\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4448 - mse: 25050365952.0000 - mae: 290.4449 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3893 - mse: 1010.4250 - mae: 0.3893 - val_loss: 0.3589 - val_mse: 1259.2617 - val_mae: 0.3589\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3541 - mse: 940.7860 - mae: 0.3541 - val_loss: 0.3587 - val_mse: 1259.2648 - val_mae: 0.3587\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1702 - mse: 30060435456.0000 - mae: 387.1701 - val_loss: 0.3586 - val_mse: 1259.2628 - val_mae: 0.3586\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 483.9080 - mse: 35070509056.0000 - mae: 483.9080 - val_loss: 0.3585 - val_mse: 1259.2601 - val_mae: 0.3585\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3584 - mse: 932.1639 - mae: 0.3584 - val_loss: 0.3585 - val_mse: 1259.2629 - val_mae: 0.3585\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4409 - mse: 25050365952.0000 - mae: 290.4406 - val_loss: 0.3584 - val_mse: 1259.2650 - val_mae: 0.3584\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4481 - mse: 1291.3680 - mae: 0.4481 - val_loss: 0.3583 - val_mse: 1259.2611 - val_mae: 0.3583\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4274 - mse: 1238.5527 - mae: 0.4274 - val_loss: 0.3582 - val_mse: 1259.2633 - val_mae: 0.3582\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.4108 - mse: 25050365952.0000 - mae: 290.4107 - val_loss: 0.3580 - val_mse: 1259.2653 - val_mae: 0.3580\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3888 - mse: 1214.8291 - mae: 0.3888 - val_loss: 0.3581 - val_mse: 1259.2625 - val_mae: 0.3581\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7637 - mse: 20040292352.0000 - mae: 193.7637 - val_loss: 0.3581 - val_mse: 1259.2616 - val_mae: 0.3581\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 580.6241 - mse: 40080580608.0000 - mae: 580.6243 - val_loss: 0.3580 - val_mse: 1259.2638 - val_mae: 0.3580\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3189 - mse: 879.3226 - mae: 0.3189 - val_loss: 0.3580 - val_mse: 1259.2639 - val_mae: 0.3580\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2738 - mse: 641.1595 - mae: 0.2738 - val_loss: 0.3578 - val_mse: 1259.2632 - val_mae: 0.3578\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5034 - mse: 25050365952.0000 - mae: 290.5034 - val_loss: 0.3581 - val_mse: 1259.3184 - val_mae: 0.3581\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8750 - mse: 35070509056.0000 - mae: 483.8748 - val_loss: 0.3578 - val_mse: 1259.2607 - val_mae: 0.3578\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3592 - mse: 998.2363 - mae: 0.3592 - val_loss: 0.3576 - val_mse: 1259.2633 - val_mae: 0.3576\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8448 - mse: 35070509056.0000 - mae: 483.8448 - val_loss: 0.3577 - val_mse: 1259.2629 - val_mae: 0.3577\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3196 - mse: 866.1201 - mae: 0.3196 - val_loss: 0.3576 - val_mse: 1259.2631 - val_mae: 0.3576\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4644 - mse: 1439.3322 - mae: 0.4644 - val_loss: 0.3577 - val_mse: 1259.2601 - val_mae: 0.3577\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1289 - mse: 30060435456.0000 - mae: 387.1291 - val_loss: 0.3576 - val_mse: 1259.2604 - val_mae: 0.3576\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 387.2435 - mse: 30060439552.0000 - mae: 387.2436 - val_loss: 0.3575 - val_mse: 1259.2627 - val_mae: 0.3575\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3622 - mse: 864.8208 - mae: 0.3622 - val_loss: 0.3575 - val_mse: 1259.2618 - val_mae: 0.3575\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4556 - mse: 1415.0698 - mae: 0.4556 - val_loss: 0.3575 - val_mse: 1259.2577 - val_mae: 0.3575\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 483.7612 - mse: 35070509056.0000 - mae: 483.7605 - val_loss: 0.3574 - val_mse: 1259.2653 - val_mae: 0.3574\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.3919 - mse: 25050363904.0000 - mae: 290.3915 - val_loss: 0.3574 - val_mse: 1259.2598 - val_mae: 0.3574\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4757 - mse: 1611.0514 - mae: 0.4757 - val_loss: 0.3572 - val_mse: 1259.2616 - val_mae: 0.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3108 - mse: 743.9236 - mae: 0.3108 - val_loss: 0.3573 - val_mse: 1259.2614 - val_mae: 0.3573\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8810 - mse: 35070509056.0000 - mae: 483.8811 - val_loss: 0.3573 - val_mse: 1259.2593 - val_mae: 0.3573\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 483.9858 - mse: 35070509056.0000 - mae: 483.9855 - val_loss: 0.3574 - val_mse: 1259.2533 - val_mae: 0.3574\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.2868 - mse: 749.9562 - mae: 0.2868 - val_loss: 0.3572 - val_mse: 1259.2612 - val_mae: 0.3572\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.3933 - mse: 25050363904.0000 - mae: 290.3933 - val_loss: 0.3575 - val_mse: 1259.2609 - val_mae: 0.3575\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3642 - mse: 1045.5616 - mae: 0.3642 - val_loss: 0.3573 - val_mse: 1259.2595 - val_mae: 0.3573\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3593 - mse: 985.7634 - mae: 0.3593 - val_loss: 0.3573 - val_mse: 1259.2640 - val_mae: 0.3573\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5462 - mse: 40080580608.0000 - mae: 580.5460 - val_loss: 0.3573 - val_mse: 1259.2598 - val_mae: 0.3573\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4428 - mse: 1500.9680 - mae: 0.4428 - val_loss: 0.3574 - val_mse: 1259.2622 - val_mae: 0.3574\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7179 - mse: 20040290304.0000 - mae: 193.7178 - val_loss: 0.3573 - val_mse: 1259.2614 - val_mae: 0.3573\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1454 - mse: 30060435456.0000 - mae: 387.1455 - val_loss: 0.3574 - val_mse: 1259.2623 - val_mae: 0.3574\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3568 - mse: 1062.8302 - mae: 0.3568 - val_loss: 0.3573 - val_mse: 1259.2565 - val_mae: 0.3573\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2786 - mse: 45090652160.0000 - mae: 677.2776 - val_loss: 0.3575 - val_mse: 1259.2610 - val_mae: 0.3575\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3035 - mse: 754.3414 - mae: 0.3035 - val_loss: 0.3574 - val_mse: 1259.2618 - val_mae: 0.3574\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3002 - mse: 711.1190 - mae: 0.3002 - val_loss: 0.3574 - val_mse: 1259.2631 - val_mae: 0.3574\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2019 - mse: 30060435456.0000 - mae: 387.2022 - val_loss: 0.3574 - val_mse: 1259.2598 - val_mae: 0.3574\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8248 - mse: 35070509056.0000 - mae: 483.8244 - val_loss: 0.3576 - val_mse: 1259.2610 - val_mae: 0.3576\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4285 - mse: 1294.9518 - mae: 0.4285 - val_loss: 0.3574 - val_mse: 1259.2583 - val_mae: 0.3574\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4060 - mse: 1277.6697 - mae: 0.4060 - val_loss: 0.3576 - val_mse: 1259.2627 - val_mae: 0.3576\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0941 - mse: 30060439552.0000 - mae: 387.0939 - val_loss: 0.3575 - val_mse: 1259.2621 - val_mae: 0.3575\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3791 - mse: 25050365952.0000 - mae: 290.3792 - val_loss: 0.3576 - val_mse: 1259.2588 - val_mae: 0.3576\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4942 - mse: 1532.0072 - mae: 0.4942 - val_loss: 0.3575 - val_mse: 1259.2639 - val_mae: 0.3575\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3608 - mse: 1027.6871 - mae: 0.3608 - val_loss: 0.3577 - val_mse: 1259.2572 - val_mae: 0.3577\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 193.7444 - mse: 20040292352.0000 - mae: 193.7443 - val_loss: 0.3577 - val_mse: 1259.2618 - val_mae: 0.3577\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2932 - mse: 658.0049 - mae: 0.2932 - val_loss: 0.3577 - val_mse: 1259.2639 - val_mae: 0.3577\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2294 - mse: 30060435456.0000 - mae: 387.2298 - val_loss: 0.3576 - val_mse: 1259.2621 - val_mae: 0.3576\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5799 - mse: 40080580608.0000 - mae: 580.5792 - val_loss: 0.3579 - val_mse: 1259.2642 - val_mae: 0.3579\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3899 - mse: 1191.1307 - mae: 0.3899 - val_loss: 0.3577 - val_mse: 1259.2690 - val_mae: 0.3577\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3803 - mse: 1173.8654 - mae: 0.3803 - val_loss: 0.3580 - val_mse: 1259.2583 - val_mae: 0.3580\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.4864 - mse: 25050365952.0000 - mae: 290.4863 - val_loss: 0.3577 - val_mse: 1259.2570 - val_mae: 0.3577\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3435 - mse: 1137.1661 - mae: 0.3435 - val_loss: 0.3579 - val_mse: 1259.2618 - val_mae: 0.3579\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1420 - mse: 30060435456.0000 - mae: 387.1419 - val_loss: 0.3579 - val_mse: 1259.2664 - val_mae: 0.3579\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3104 - mse: 790.1664 - mae: 0.3104 - val_loss: 0.3579 - val_mse: 1259.2634 - val_mae: 0.3579\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7622 - mse: 20040292352.0000 - mae: 193.7621 - val_loss: 0.3578 - val_mse: 1259.2638 - val_mae: 0.3578\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 193.7477 - mse: 20040290304.0000 - mae: 193.7477 - val_loss: 0.3583 - val_mse: 1259.2622 - val_mae: 0.3583\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3975 - mse: 1319.6121 - mae: 0.3975 - val_loss: 0.3580 - val_mse: 1259.2646 - val_mae: 0.3580\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3942 - mse: 1094.1083 - mae: 0.3942 - val_loss: 0.3584 - val_mse: 1259.2693 - val_mae: 0.3584\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4441 - mse: 25050363904.0000 - mae: 290.4439 - val_loss: 0.3581 - val_mse: 1259.2648 - val_mae: 0.3581\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.3879 - mse: 25050363904.0000 - mae: 290.3879 - val_loss: 0.3582 - val_mse: 1259.2645 - val_mae: 0.3582\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4235 - mse: 1226.2372 - mae: 0.4235 - val_loss: 0.3581 - val_mse: 1259.2632 - val_mae: 0.3581\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 193.8124 - mse: 20040290304.0000 - mae: 193.8124 - val_loss: 0.3582 - val_mse: 1259.2593 - val_mae: 0.3582\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3421 - mse: 877.3840 - mae: 0.3421 - val_loss: 0.3582 - val_mse: 1259.2616 - val_mae: 0.3582\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 677.2801 - mse: 45090652160.0000 - mae: 677.2783 - val_loss: 0.3584 - val_mse: 1259.2622 - val_mae: 0.3584\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.2985 - mse: 727.0819 - mae: 0.2985 - val_loss: 0.3582 - val_mse: 1259.2646 - val_mae: 0.3582\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.4357 - mse: 25050365952.0000 - mae: 290.4358 - val_loss: 0.3583 - val_mse: 1259.2607 - val_mae: 0.3583\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3459 - mse: 1044.2389 - mae: 0.3459 - val_loss: 0.3582 - val_mse: 1259.2642 - val_mae: 0.3582\n",
      "Epoch 85/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3830 - mse: 1060.1312 - mae: 0.3830 - val_loss: 0.3585 - val_mse: 1259.2656 - val_mae: 0.3585\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1814 - mse: 30060439552.0000 - mae: 387.1812 - val_loss: 0.3584 - val_mse: 1259.2646 - val_mae: 0.3584\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4212 - mse: 1411.4806 - mae: 0.4212 - val_loss: 0.3583 - val_mse: 1259.2622 - val_mae: 0.3583\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8089 - mse: 35070513152.0000 - mae: 483.8084 - val_loss: 0.3584 - val_mse: 1259.2655 - val_mae: 0.3584\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5076 - mse: 25050365952.0000 - mae: 290.5074 - val_loss: 0.3586 - val_mse: 1259.2593 - val_mae: 0.3586\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2655 - mse: 571.2252 - mae: 0.2655 - val_loss: 0.3585 - val_mse: 1259.2657 - val_mae: 0.3585\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3793 - mse: 1053.2695 - mae: 0.3793 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8628 - mse: 35070509056.0000 - mae: 483.8616 - val_loss: 0.3584 - val_mse: 1259.2594 - val_mae: 0.3584\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3332 - mse: 979.0528 - mae: 0.3332 - val_loss: 0.3587 - val_mse: 1259.2653 - val_mae: 0.3587\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8948 - mse: 35070509056.0000 - mae: 483.8931 - val_loss: 0.3587 - val_mse: 1259.2646 - val_mae: 0.3587\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2815 - mse: 775.3777 - mae: 0.2815 - val_loss: 0.3588 - val_mse: 1259.2645 - val_mae: 0.3588\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1487 - mse: 30060435456.0000 - mae: 387.1487 - val_loss: 0.3587 - val_mse: 1259.2643 - val_mae: 0.3587\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2721 - mse: 708.1008 - mae: 0.2721 - val_loss: 0.3587 - val_mse: 1259.2653 - val_mae: 0.3587\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5168 - mse: 25050363904.0000 - mae: 290.5166 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8156 - mse: 35070509056.0000 - mae: 483.8141 - val_loss: 0.3589 - val_mse: 1259.2622 - val_mae: 0.3589\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3755 - mse: 1143.1925 - mae: 0.3755 - val_loss: 0.3586 - val_mse: 1259.2655 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4773 - mse: 25050363904.0000 - mae: 290.4773 - val_loss: 0.3654 - val_mse: 1259.3008 - val_mae: 0.3654\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3652 - mse: 986.4691 - mae: 0.3652 - val_loss: 0.3617 - val_mse: 1259.2655 - val_mae: 0.3617\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3281 - mse: 709.8934 - mae: 0.3281 - val_loss: 0.3610 - val_mse: 1259.2650 - val_mae: 0.3610\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.3032 - mse: 30060439552.0000 - mae: 387.3032 - val_loss: 0.3606 - val_mse: 1259.2635 - val_mae: 0.3606\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3586 - mse: 936.9871 - mae: 0.3586 - val_loss: 0.3602 - val_mse: 1259.2607 - val_mae: 0.3602\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8734 - mse: 35070509056.0000 - mae: 483.8732 - val_loss: 0.3600 - val_mse: 1259.2606 - val_mae: 0.3600\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5273 - mse: 25050365952.0000 - mae: 290.5272 - val_loss: 0.3597 - val_mse: 1259.2614 - val_mae: 0.3597\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2681 - mse: 520.2871 - mae: 0.2681 - val_loss: 0.3596 - val_mse: 1259.2659 - val_mae: 0.3596\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4908 - mse: 25050363904.0000 - mae: 290.4909 - val_loss: 0.3594 - val_mse: 1259.2646 - val_mae: 0.3594\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3391 - mse: 1019.5703 - mae: 0.3391 - val_loss: 0.3593 - val_mse: 1259.2639 - val_mae: 0.3593\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.2020 - mse: 316.7774 - mae: 0.2020 - val_loss: 0.3592 - val_mse: 1259.2627 - val_mae: 0.3592\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.6242 - mse: 25050365952.0000 - mae: 290.6242 - val_loss: 0.3591 - val_mse: 1259.2610 - val_mae: 0.3591\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3194 - mse: 840.4484 - mae: 0.3194 - val_loss: 0.3589 - val_mse: 1259.2615 - val_mae: 0.3589\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7657 - mse: 20040292352.0000 - mae: 193.7657 - val_loss: 0.3588 - val_mse: 1259.2628 - val_mae: 0.3588\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2438 - mse: 421.8345 - mae: 0.2438 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3620 - mse: 45090652160.0000 - mae: 677.3619 - val_loss: 0.3586 - val_mse: 1259.2611 - val_mae: 0.3586\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5371 - mse: 25050365952.0000 - mae: 290.5371 - val_loss: 0.3586 - val_mse: 1259.2642 - val_mae: 0.3586\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3517 - mse: 921.6340 - mae: 0.3517 - val_loss: 0.3584 - val_mse: 1259.2648 - val_mae: 0.3584\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3347 - mse: 893.2867 - mae: 0.3347 - val_loss: 0.3584 - val_mse: 1259.2650 - val_mae: 0.3584\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7612 - mse: 20040292352.0000 - mae: 193.7612 - val_loss: 0.3583 - val_mse: 1259.2614 - val_mae: 0.3583\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4576 - mse: 25050363904.0000 - mae: 290.4576 - val_loss: 0.3583 - val_mse: 1259.2629 - val_mae: 0.3583\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4009 - mse: 1226.3879 - mae: 0.4009 - val_loss: 0.3581 - val_mse: 1259.2633 - val_mae: 0.3581\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4620 - mse: 25050363904.0000 - mae: 290.4618 - val_loss: 0.3581 - val_mse: 1259.2622 - val_mae: 0.3581\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3552 - mse: 908.6558 - mae: 0.3552 - val_loss: 0.3581 - val_mse: 1259.2626 - val_mae: 0.3581\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2664 - mse: 531.0015 - mae: 0.2664 - val_loss: 0.3580 - val_mse: 1259.2622 - val_mae: 0.3580\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9429 - mse: 35070509056.0000 - mae: 483.9427 - val_loss: 0.3580 - val_mse: 1259.2616 - val_mae: 0.3580\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 193.7207 - mse: 20040290304.0000 - mae: 193.7206 - val_loss: 0.3579 - val_mse: 1259.2645 - val_mae: 0.3579\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3779 - mse: 1060.4741 - mae: 0.3779 - val_loss: 0.3578 - val_mse: 1259.2629 - val_mae: 0.3578\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3455 - mse: 1007.0501 - mae: 0.3455 - val_loss: 0.3578 - val_mse: 1259.2622 - val_mae: 0.3578\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8397 - mse: 35070509056.0000 - mae: 483.8392 - val_loss: 0.3576 - val_mse: 1259.2625 - val_mae: 0.3576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5928 - mse: 40080580608.0000 - mae: 580.5922 - val_loss: 0.3577 - val_mse: 1259.2646 - val_mae: 0.3577\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3645 - mse: 984.5417 - mae: 0.3645 - val_loss: 0.3577 - val_mse: 1259.2625 - val_mae: 0.3577\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.2023 - mse: 30060439552.0000 - mae: 387.2022 - val_loss: 0.3575 - val_mse: 1259.2621 - val_mae: 0.3575\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2768 - mse: 659.1565 - mae: 0.2768 - val_loss: 0.3575 - val_mse: 1259.2600 - val_mae: 0.3575\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 677.3185 - mse: 45090652160.0000 - mae: 677.3184 - val_loss: 0.3575 - val_mse: 1259.2638 - val_mae: 0.3575\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3284 - mse: 918.8416 - mae: 0.3284 - val_loss: 0.3574 - val_mse: 1259.2612 - val_mae: 0.3574\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3483 - mse: 853.7863 - mae: 0.3483 - val_loss: 0.3575 - val_mse: 1259.2631 - val_mae: 0.3575\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2380 - mse: 30060435456.0000 - mae: 387.2381 - val_loss: 0.3573 - val_mse: 1259.2612 - val_mae: 0.3573\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 193.7365 - mse: 20040292352.0000 - mae: 193.7364 - val_loss: 0.3574 - val_mse: 1259.2604 - val_mae: 0.3574\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3662 - mse: 1170.4089 - mae: 0.3662 - val_loss: 0.3573 - val_mse: 1259.2637 - val_mae: 0.3573\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.4494 - mse: 25050363904.0000 - mae: 290.4494 - val_loss: 0.3573 - val_mse: 1259.2627 - val_mae: 0.3573\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3725 - mse: 1189.9058 - mae: 0.3725 - val_loss: 0.3572 - val_mse: 1259.2642 - val_mae: 0.3572\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 483.8124 - mse: 35070509056.0000 - mae: 483.8119 - val_loss: 0.3574 - val_mse: 1259.2603 - val_mae: 0.3574\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3423 - mse: 1122.0378 - mae: 0.3423 - val_loss: 0.3573 - val_mse: 1259.2601 - val_mae: 0.3573\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9708 - mse: 35070509056.0000 - mae: 483.9696 - val_loss: 0.3573 - val_mse: 1259.2604 - val_mae: 0.3573\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3376 - mse: 914.5663 - mae: 0.3376 - val_loss: 0.3573 - val_mse: 1259.2628 - val_mae: 0.3573\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5140 - mse: 25050365952.0000 - mae: 290.5139 - val_loss: 0.3573 - val_mse: 1259.2610 - val_mae: 0.3573\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2378 - mse: 454.8816 - mae: 0.2378 - val_loss: 0.3573 - val_mse: 1259.2639 - val_mae: 0.3573\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3511 - mse: 1138.4205 - mae: 0.3511 - val_loss: 0.3573 - val_mse: 1259.2629 - val_mae: 0.3573\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.1494 - mse: 30060435456.0000 - mae: 387.1494 - val_loss: 0.3573 - val_mse: 1259.2601 - val_mae: 0.3573\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5022 - mse: 25050363904.0000 - mae: 290.5025 - val_loss: 0.3572 - val_mse: 1259.2639 - val_mae: 0.3572\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3399 - mse: 1020.3816 - mae: 0.3399 - val_loss: 0.3572 - val_mse: 1259.2618 - val_mae: 0.3572\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3845 - mse: 1149.9048 - mae: 0.3845 - val_loss: 0.3573 - val_mse: 1259.2616 - val_mae: 0.3573\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4013 - mse: 25050363904.0000 - mae: 290.4014 - val_loss: 0.3573 - val_mse: 1259.2620 - val_mae: 0.3573\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2809 - mse: 30060435456.0000 - mae: 387.2806 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2538 - mse: 496.7490 - mae: 0.2538 - val_loss: 0.3571 - val_mse: 1259.2627 - val_mae: 0.3571\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3641 - mse: 1019.9661 - mae: 0.3641 - val_loss: 0.3573 - val_mse: 1259.2612 - val_mae: 0.3573\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4667 - mse: 25050363904.0000 - mae: 290.4668 - val_loss: 0.3571 - val_mse: 1259.2607 - val_mae: 0.3571\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3494 - mse: 967.6232 - mae: 0.3494 - val_loss: 0.3573 - val_mse: 1259.2629 - val_mae: 0.3573\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.2201 - mse: 30060435456.0000 - mae: 387.2202 - val_loss: 0.3573 - val_mse: 1259.2625 - val_mae: 0.3573\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4425 - mse: 1464.8682 - mae: 0.4425 - val_loss: 0.3572 - val_mse: 1259.2631 - val_mae: 0.3572\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3861 - mse: 25050365952.0000 - mae: 290.3860 - val_loss: 0.3572 - val_mse: 1259.2596 - val_mae: 0.3572\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1782 - mse: 30060439552.0000 - mae: 387.1781 - val_loss: 0.3574 - val_mse: 1259.2629 - val_mae: 0.3574\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3192 - mse: 871.8453 - mae: 0.3192 - val_loss: 0.3571 - val_mse: 1259.2644 - val_mae: 0.3571\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.4402 - mse: 25050365952.0000 - mae: 290.4401 - val_loss: 0.3573 - val_mse: 1259.2644 - val_mae: 0.3573\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3693 - mse: 1045.2197 - mae: 0.3693 - val_loss: 0.3572 - val_mse: 1259.2614 - val_mae: 0.3572\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3500 - mse: 940.3150 - mae: 0.3500 - val_loss: 0.3574 - val_mse: 1259.2618 - val_mae: 0.3574\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7769 - mse: 20040294400.0000 - mae: 193.7768 - val_loss: 0.3573 - val_mse: 1259.2644 - val_mae: 0.3573\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3861 - mse: 25050365952.0000 - mae: 290.3862 - val_loss: 0.3575 - val_mse: 1259.2648 - val_mae: 0.3575\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4245 - mse: 1365.0448 - mae: 0.4245 - val_loss: 0.3573 - val_mse: 1259.2571 - val_mae: 0.3573\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3545 - mse: 1057.6700 - mae: 0.3545 - val_loss: 0.3574 - val_mse: 1259.2621 - val_mae: 0.3574\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1153 - mse: 30060435456.0000 - mae: 387.1153 - val_loss: 0.3573 - val_mse: 1259.2645 - val_mae: 0.3573\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2572 - mse: 45090652160.0000 - mae: 677.2570 - val_loss: 0.3574 - val_mse: 1259.2649 - val_mae: 0.3574\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3654 - mse: 1067.3148 - mae: 0.3654 - val_loss: 0.3574 - val_mse: 1259.2618 - val_mae: 0.3574\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6965 - mse: 20040292352.0000 - mae: 193.6965 - val_loss: 0.3575 - val_mse: 1259.2655 - val_mae: 0.3575\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4128 - mse: 1301.0944 - mae: 0.4128 - val_loss: 0.3575 - val_mse: 1259.2651 - val_mae: 0.3575\n",
      "Epoch 77/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 9ms/step - loss: 290.3984 - mse: 25050363904.0000 - mae: 290.3985 - val_loss: 0.3574 - val_mse: 1259.2640 - val_mae: 0.3574\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3657 - mse: 941.4029 - mae: 0.3657 - val_loss: 0.3574 - val_mse: 1259.2631 - val_mae: 0.3574\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 387.1777 - mse: 30060435456.0000 - mae: 387.1777 - val_loss: 0.3575 - val_mse: 1259.2653 - val_mae: 0.3575\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3643 - mse: 1085.8453 - mae: 0.3643 - val_loss: 0.3574 - val_mse: 1259.2639 - val_mae: 0.3574\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9248 - mse: 35070509056.0000 - mae: 483.9244 - val_loss: 0.3577 - val_mse: 1259.2625 - val_mae: 0.3577\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3144 - mse: 933.2738 - mae: 0.3144 - val_loss: 0.3577 - val_mse: 1259.2667 - val_mae: 0.3577\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2073 - mse: 380.7933 - mae: 0.2073 - val_loss: 0.3576 - val_mse: 1259.2651 - val_mae: 0.3576\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.3104 - mse: 30060435456.0000 - mae: 387.3104 - val_loss: 0.3576 - val_mse: 1259.2639 - val_mae: 0.3576\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8844 - mse: 35070509056.0000 - mae: 483.8828 - val_loss: 0.3577 - val_mse: 1259.2643 - val_mae: 0.3577\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3353 - mse: 1008.2386 - mae: 0.3353 - val_loss: 0.3576 - val_mse: 1259.2646 - val_mae: 0.3576\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3001 - mse: 620.9846 - mae: 0.3001 - val_loss: 0.3578 - val_mse: 1259.2648 - val_mae: 0.3578\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 677.3824 - mse: 45090656256.0000 - mae: 677.3813 - val_loss: 0.3577 - val_mse: 1259.2627 - val_mae: 0.3577\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3365 - mse: 904.9186 - mae: 0.3365 - val_loss: 0.3578 - val_mse: 1259.2655 - val_mae: 0.3578\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4424 - mse: 25050365952.0000 - mae: 290.4424 - val_loss: 0.3577 - val_mse: 1259.2645 - val_mae: 0.3577\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3983 - mse: 1123.9302 - mae: 0.3983 - val_loss: 0.3577 - val_mse: 1259.2656 - val_mae: 0.3577\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8339 - mse: 35070509056.0000 - mae: 483.8319 - val_loss: 0.3578 - val_mse: 1259.2649 - val_mae: 0.3578\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3159 - mse: 741.1325 - mae: 0.3159 - val_loss: 0.3579 - val_mse: 1259.2642 - val_mae: 0.3579\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9502 - mse: 45090652160.0000 - mae: 483.9491 - val_loss: 0.3578 - val_mse: 1259.2672 - val_mae: 0.3578\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.3942 - mse: 25050365952.0000 - mae: 290.3942 - val_loss: 0.3578 - val_mse: 1259.2639 - val_mae: 0.3578\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3890 - mse: 1126.2798 - mae: 0.3890 - val_loss: 0.3578 - val_mse: 1259.2590 - val_mae: 0.3578\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3091 - mse: 799.2731 - mae: 0.3091 - val_loss: 0.3578 - val_mse: 1259.2650 - val_mae: 0.3578\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2828 - mse: 45090656256.0000 - mae: 677.2825 - val_loss: 0.3577 - val_mse: 1259.2621 - val_mae: 0.3577\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2962 - mse: 726.0665 - mae: 0.2962 - val_loss: 0.3580 - val_mse: 1259.2635 - val_mae: 0.3580\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4252 - mse: 25050365952.0000 - mae: 290.4251 - val_loss: 0.3577 - val_mse: 1259.2629 - val_mae: 0.3577\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5342 - mse: 25050365952.0000 - mae: 290.5342 - val_loss: 0.3646 - val_mse: 1259.3137 - val_mae: 0.3646\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3789 - mse: 1011.1746 - mae: 0.3789 - val_loss: 0.3620 - val_mse: 1259.2770 - val_mae: 0.3620\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3027 - mse: 596.1572 - mae: 0.3027 - val_loss: 0.3612 - val_mse: 1259.2734 - val_mae: 0.3612\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5169 - mse: 25050363904.0000 - mae: 290.5169 - val_loss: 0.3606 - val_mse: 1259.2659 - val_mae: 0.3606\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3984 - mse: 1214.5011 - mae: 0.3984 - val_loss: 0.3602 - val_mse: 1259.2667 - val_mae: 0.3602\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4163 - mse: 25050363904.0000 - mae: 290.4162 - val_loss: 0.3600 - val_mse: 1259.2642 - val_mae: 0.3600\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5056 - mse: 25050365952.0000 - mae: 290.5057 - val_loss: 0.3598 - val_mse: 1259.2633 - val_mae: 0.3598\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3497 - mse: 839.0465 - mae: 0.3497 - val_loss: 0.3595 - val_mse: 1259.2642 - val_mae: 0.3595\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9729 - mse: 35070509056.0000 - mae: 483.9729 - val_loss: 0.3595 - val_mse: 1259.2632 - val_mae: 0.3595\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3028 - mse: 735.7424 - mae: 0.3028 - val_loss: 0.3592 - val_mse: 1259.2638 - val_mae: 0.3592\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9674 - mse: 35070513152.0000 - mae: 483.9676 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2831 - mse: 829.6477 - mae: 0.2831 - val_loss: 0.3590 - val_mse: 1259.2637 - val_mae: 0.3590\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4324 - mse: 25050365952.0000 - mae: 290.4324 - val_loss: 0.3589 - val_mse: 1259.2631 - val_mae: 0.3589\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4039 - mse: 1155.9011 - mae: 0.4039 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3679 - mse: 980.9439 - mae: 0.3679 - val_loss: 0.3588 - val_mse: 1259.2637 - val_mae: 0.3588\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1384 - mse: 30060439552.0000 - mae: 387.1384 - val_loss: 0.3586 - val_mse: 1259.2648 - val_mae: 0.3586\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4440 - mse: 1307.5316 - mae: 0.4440 - val_loss: 0.3584 - val_mse: 1259.2627 - val_mae: 0.3584\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4061 - mse: 25050363904.0000 - mae: 290.4062 - val_loss: 0.3584 - val_mse: 1259.2638 - val_mae: 0.3584\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4172 - mse: 1132.3735 - mae: 0.4172 - val_loss: 0.3584 - val_mse: 1259.2633 - val_mae: 0.3584\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.1193 - mse: 30060435456.0000 - mae: 387.1194 - val_loss: 0.3583 - val_mse: 1259.2604 - val_mae: 0.3583\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4032 - mse: 1202.6455 - mae: 0.4032 - val_loss: 0.3582 - val_mse: 1259.2626 - val_mae: 0.3582\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 483.8362 - mse: 35070509056.0000 - mae: 483.8363 - val_loss: 0.3581 - val_mse: 1259.2667 - val_mae: 0.3581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0698 - mse: 30060435456.0000 - mae: 387.0697 - val_loss: 0.3581 - val_mse: 1259.2650 - val_mae: 0.3581\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4909 - mse: 1507.3528 - mae: 0.4909 - val_loss: 0.3580 - val_mse: 1259.2607 - val_mae: 0.3580\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3247 - mse: 750.9779 - mae: 0.3247 - val_loss: 0.3580 - val_mse: 1259.2614 - val_mae: 0.3580\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9061 - mse: 35070509056.0000 - mae: 483.9056 - val_loss: 0.3578 - val_mse: 1259.2616 - val_mae: 0.3578\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3216 - mse: 840.6025 - mae: 0.3216 - val_loss: 0.3579 - val_mse: 1259.2657 - val_mae: 0.3579\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9190 - mse: 35070509056.0000 - mae: 483.9184 - val_loss: 0.3577 - val_mse: 1259.2628 - val_mae: 0.3577\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 773.9259 - mse: 50100731904.0000 - mae: 773.9260 - val_loss: 0.3578 - val_mse: 1259.2639 - val_mae: 0.3578\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3832 - mse: 1091.5483 - mae: 0.3832 - val_loss: 0.3577 - val_mse: 1259.2638 - val_mae: 0.3577\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3606 - mse: 1017.2730 - mae: 0.3606 - val_loss: 0.3576 - val_mse: 1259.2585 - val_mae: 0.3576\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8283 - mse: 35070513152.0000 - mae: 483.8281 - val_loss: 0.3576 - val_mse: 1259.2629 - val_mae: 0.3576\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 484.0189 - mse: 35070509056.0000 - mae: 484.0184 - val_loss: 0.3577 - val_mse: 1259.2595 - val_mae: 0.3577\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3093 - mse: 656.2514 - mae: 0.3093 - val_loss: 0.3575 - val_mse: 1259.2621 - val_mae: 0.3575\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3417 - mse: 947.5125 - mae: 0.3417 - val_loss: 0.3575 - val_mse: 1259.2614 - val_mae: 0.3575\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 387.1752 - mse: 30060435456.0000 - mae: 387.1753 - val_loss: 0.3575 - val_mse: 1259.2611 - val_mae: 0.3575\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2076 - mse: 30060435456.0000 - mae: 387.2074 - val_loss: 0.3575 - val_mse: 1259.2634 - val_mae: 0.3575\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3491 - mse: 761.8770 - mae: 0.3491 - val_loss: 0.3574 - val_mse: 1259.2598 - val_mae: 0.3574\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3596 - mse: 1078.5649 - mae: 0.3596 - val_loss: 0.3574 - val_mse: 1259.2638 - val_mae: 0.3574\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4780 - mse: 25050363904.0000 - mae: 290.4779 - val_loss: 0.3575 - val_mse: 1259.2614 - val_mae: 0.3575\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7922 - mse: 20040290304.0000 - mae: 193.7922 - val_loss: 0.3574 - val_mse: 1259.2626 - val_mae: 0.3574\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3252 - mse: 845.9632 - mae: 0.3252 - val_loss: 0.3574 - val_mse: 1259.2607 - val_mae: 0.3574\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5371 - mse: 40080580608.0000 - mae: 580.5370 - val_loss: 0.3574 - val_mse: 1259.2617 - val_mae: 0.3574\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4439 - mse: 1369.4567 - mae: 0.4439 - val_loss: 0.3574 - val_mse: 1259.2621 - val_mae: 0.3574\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4066 - mse: 25050365952.0000 - mae: 290.4066 - val_loss: 0.3575 - val_mse: 1259.2598 - val_mae: 0.3575\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3515 - mse: 1011.3716 - mae: 0.3515 - val_loss: 0.3573 - val_mse: 1259.2621 - val_mae: 0.3573\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3804 - mse: 1113.1189 - mae: 0.3804 - val_loss: 0.3576 - val_mse: 1259.2618 - val_mae: 0.3576\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0969 - mse: 30060439552.0000 - mae: 387.0969 - val_loss: 0.3575 - val_mse: 1259.2634 - val_mae: 0.3575\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2004 - mse: 30060439552.0000 - mae: 387.2005 - val_loss: 0.3575 - val_mse: 1259.2640 - val_mae: 0.3575\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3714 - mse: 1056.8810 - mae: 0.3714 - val_loss: 0.3574 - val_mse: 1259.2635 - val_mae: 0.3574\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5187 - mse: 1676.1379 - mae: 0.5187 - val_loss: 0.3576 - val_mse: 1259.2592 - val_mae: 0.3576\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0092 - mse: 30060435456.0000 - mae: 387.0091 - val_loss: 0.3575 - val_mse: 1259.2640 - val_mae: 0.3575\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5181 - mse: 25050363904.0000 - mae: 290.5180 - val_loss: 0.3576 - val_mse: 1259.2612 - val_mae: 0.3576\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3749 - mse: 1110.4977 - mae: 0.3749 - val_loss: 0.3575 - val_mse: 1259.2582 - val_mae: 0.3575\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1737 - mse: 30060435456.0000 - mae: 387.1738 - val_loss: 0.3576 - val_mse: 1259.2643 - val_mae: 0.3576\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3751 - mse: 1181.3636 - mae: 0.3751 - val_loss: 0.3575 - val_mse: 1259.2646 - val_mae: 0.3575\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3447 - mse: 948.8301 - mae: 0.3447 - val_loss: 0.3576 - val_mse: 1259.2616 - val_mae: 0.3576\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2197 - mse: 30060435456.0000 - mae: 387.2198 - val_loss: 0.3574 - val_mse: 1259.2615 - val_mae: 0.3574\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4616 - mse: 1362.5948 - mae: 0.4616 - val_loss: 0.3578 - val_mse: 1259.2605 - val_mae: 0.3578\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3752 - mse: 25050365952.0000 - mae: 290.3755 - val_loss: 0.3577 - val_mse: 1259.2626 - val_mae: 0.3577\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5215 - mse: 25050363904.0000 - mae: 290.5212 - val_loss: 0.3579 - val_mse: 1259.2612 - val_mae: 0.3579\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3660 - mse: 945.0682 - mae: 0.3660 - val_loss: 0.3578 - val_mse: 1259.2626 - val_mae: 0.3578\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2611 - mse: 640.0107 - mae: 0.2611 - val_loss: 0.3579 - val_mse: 1259.2609 - val_mae: 0.3579\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7634 - mse: 20040292352.0000 - mae: 193.7632 - val_loss: 0.3577 - val_mse: 1259.2640 - val_mae: 0.3577\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4506 - mse: 1427.0485 - mae: 0.4506 - val_loss: 0.3580 - val_mse: 1259.2631 - val_mae: 0.3580\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 387.0595 - mse: 30060439552.0000 - mae: 387.0594 - val_loss: 0.3576 - val_mse: 1259.2635 - val_mae: 0.3576\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2822 - mse: 685.6330 - mae: 0.2822 - val_loss: 0.3579 - val_mse: 1259.2614 - val_mae: 0.3579\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5308 - mse: 25050363904.0000 - mae: 290.5305 - val_loss: 0.3579 - val_mse: 1259.2614 - val_mae: 0.3579\n",
      "Epoch 69/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2983 - mse: 45090652160.0000 - mae: 677.2976 - val_loss: 0.3580 - val_mse: 1259.2625 - val_mae: 0.3580\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3120 - mse: 799.1342 - mae: 0.3120 - val_loss: 0.3579 - val_mse: 1259.2614 - val_mae: 0.3579\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2601 - mse: 749.5610 - mae: 0.2601 - val_loss: 0.3580 - val_mse: 1259.2635 - val_mae: 0.3580\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9059 - mse: 45090660352.0000 - mae: 483.9059 - val_loss: 0.3580 - val_mse: 1259.2642 - val_mae: 0.3580\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3693 - mse: 1043.4156 - mae: 0.3693 - val_loss: 0.3581 - val_mse: 1259.2639 - val_mae: 0.3581\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3761 - mse: 989.8789 - mae: 0.3761 - val_loss: 0.3581 - val_mse: 1259.2631 - val_mae: 0.3581\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1400 - mse: 30060435456.0000 - mae: 387.1401 - val_loss: 0.3582 - val_mse: 1259.2582 - val_mae: 0.3582\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3592 - mse: 1091.2316 - mae: 0.3592 - val_loss: 0.3581 - val_mse: 1259.2648 - val_mae: 0.3581\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8653 - mse: 35070509056.0000 - mae: 483.8653 - val_loss: 0.3583 - val_mse: 1259.2650 - val_mae: 0.3583\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3791 - mse: 1058.8417 - mae: 0.3791 - val_loss: 0.3581 - val_mse: 1259.2615 - val_mae: 0.3581\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3733 - mse: 1222.0889 - mae: 0.3733 - val_loss: 0.3583 - val_mse: 1259.2625 - val_mae: 0.3583\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7836 - mse: 35070509056.0000 - mae: 483.7822 - val_loss: 0.3583 - val_mse: 1259.2648 - val_mae: 0.3583\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3491 - mse: 921.3319 - mae: 0.3491 - val_loss: 0.3584 - val_mse: 1259.2631 - val_mae: 0.3584\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4642 - mse: 25050365952.0000 - mae: 290.4639 - val_loss: 0.3584 - val_mse: 1259.2643 - val_mae: 0.3584\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3500 - mse: 1000.7445 - mae: 0.3500 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7555 - mse: 20040292352.0000 - mae: 193.7555 - val_loss: 0.3584 - val_mse: 1259.2639 - val_mae: 0.3584\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1685 - mse: 30060435456.0000 - mae: 387.1684 - val_loss: 0.3585 - val_mse: 1259.2638 - val_mae: 0.3585\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3414 - mse: 928.9495 - mae: 0.3414 - val_loss: 0.3584 - val_mse: 1259.2638 - val_mae: 0.3584\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6960 - mse: 20040292352.0000 - mae: 193.6960 - val_loss: 0.3585 - val_mse: 1259.2645 - val_mae: 0.3585\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3777 - mse: 1137.2692 - mae: 0.3777 - val_loss: 0.3583 - val_mse: 1259.2644 - val_mae: 0.3583\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2838 - mse: 720.3128 - mae: 0.2838 - val_loss: 0.3586 - val_mse: 1259.2590 - val_mae: 0.3586\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7384 - mse: 20040290304.0000 - mae: 193.7383 - val_loss: 0.3585 - val_mse: 1259.2620 - val_mae: 0.3585\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2750 - mse: 667.3276 - mae: 0.2750 - val_loss: 0.3589 - val_mse: 1259.2654 - val_mae: 0.3589\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2420 - mse: 30060435456.0000 - mae: 387.2422 - val_loss: 0.3585 - val_mse: 1259.2635 - val_mae: 0.3585\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3924 - mse: 25050365952.0000 - mae: 290.3925 - val_loss: 0.3585 - val_mse: 1259.2654 - val_mae: 0.3585\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4334 - mse: 1295.1906 - mae: 0.4334 - val_loss: 0.3584 - val_mse: 1259.2598 - val_mae: 0.3584\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3711 - mse: 1156.9261 - mae: 0.3711 - val_loss: 0.3587 - val_mse: 1259.2655 - val_mae: 0.3587\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 967.3611 - mse: 70141018112.0000 - mae: 967.3608 - val_loss: 0.3588 - val_mse: 1259.2661 - val_mae: 0.3588\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3336 - mse: 853.7691 - mae: 0.3336 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3802 - mse: 1111.6411 - mae: 0.3802 - val_loss: 0.3586 - val_mse: 1259.2617 - val_mae: 0.3586\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5575 - mse: 25050363904.0000 - mae: 290.5573 - val_loss: 0.3587 - val_mse: 1259.2612 - val_mae: 0.3587\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2133 - mse: 439.4869 - mae: 0.2133 - val_loss: 0.3587 - val_mse: 1259.2649 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1214 - mse: 30060435456.0000 - mae: 387.1212 - val_loss: 0.3646 - val_mse: 1259.3109 - val_mae: 0.3646\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4212 - mse: 1201.3914 - mae: 0.4212 - val_loss: 0.3614 - val_mse: 1259.2767 - val_mae: 0.3614\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4341 - mse: 1447.3955 - mae: 0.4341 - val_loss: 0.3605 - val_mse: 1259.2701 - val_mae: 0.3605\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5161 - mse: 40080580608.0000 - mae: 580.5164 - val_loss: 0.3602 - val_mse: 1259.2662 - val_mae: 0.3602\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3458 - mse: 975.8547 - mae: 0.3458 - val_loss: 0.3599 - val_mse: 1259.2638 - val_mae: 0.3599\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7470 - mse: 20040290304.0000 - mae: 193.7470 - val_loss: 0.3596 - val_mse: 1259.2629 - val_mae: 0.3596\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3485 - mse: 952.9734 - mae: 0.3485 - val_loss: 0.3595 - val_mse: 1259.2645 - val_mae: 0.3595\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6062 - mse: 40080580608.0000 - mae: 580.6061 - val_loss: 0.3593 - val_mse: 1259.2615 - val_mae: 0.3593\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8406 - mse: 35070513152.0000 - mae: 483.8407 - val_loss: 0.3592 - val_mse: 1259.2614 - val_mae: 0.3592\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3818 - mse: 1226.0500 - mae: 0.3818 - val_loss: 0.3590 - val_mse: 1259.2656 - val_mae: 0.3590\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5519 - mse: 40080580608.0000 - mae: 580.5519 - val_loss: 0.3589 - val_mse: 1259.2607 - val_mae: 0.3589\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4046 - mse: 1208.0583 - mae: 0.4046 - val_loss: 0.3588 - val_mse: 1259.2643 - val_mae: 0.3588\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7404 - mse: 20040290304.0000 - mae: 193.7405 - val_loss: 0.3587 - val_mse: 1259.2610 - val_mae: 0.3587\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3966 - mse: 1211.1418 - mae: 0.3966 - val_loss: 0.3586 - val_mse: 1259.2614 - val_mae: 0.3586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1873 - mse: 30060435456.0000 - mae: 387.1873 - val_loss: 0.3585 - val_mse: 1259.2598 - val_mae: 0.3585\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3389 - mse: 993.3187 - mae: 0.3389 - val_loss: 0.3584 - val_mse: 1259.2615 - val_mae: 0.3584\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9002 - mse: 35070509056.0000 - mae: 483.9001 - val_loss: 0.3583 - val_mse: 1259.2612 - val_mae: 0.3583\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2948 - mse: 681.7845 - mae: 0.2948 - val_loss: 0.3583 - val_mse: 1259.2627 - val_mae: 0.3583\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8492 - mse: 35070509056.0000 - mae: 483.8492 - val_loss: 0.3583 - val_mse: 1259.2643 - val_mae: 0.3583\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3471 - mse: 940.8577 - mae: 0.3471 - val_loss: 0.3581 - val_mse: 1259.2638 - val_mae: 0.3581\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3051 - mse: 675.0268 - mae: 0.3051 - val_loss: 0.3580 - val_mse: 1259.2627 - val_mae: 0.3580\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6126 - mse: 40080580608.0000 - mae: 580.6124 - val_loss: 0.3580 - val_mse: 1259.2614 - val_mae: 0.3580\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9916 - mse: 50100727808.0000 - mae: 773.9913 - val_loss: 0.3579 - val_mse: 1259.2611 - val_mae: 0.3579\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3994 - mse: 1277.9163 - mae: 0.3994 - val_loss: 0.3578 - val_mse: 1259.2631 - val_mae: 0.3578\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6114 - mse: 40080580608.0000 - mae: 580.6103 - val_loss: 0.3578 - val_mse: 1259.2629 - val_mae: 0.3578\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3609 - mse: 998.3653 - mae: 0.3609 - val_loss: 0.3578 - val_mse: 1259.2598 - val_mae: 0.3578\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8069 - mse: 20040292352.0000 - mae: 193.8069 - val_loss: 0.3578 - val_mse: 1259.2627 - val_mae: 0.3578\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3269 - mse: 798.7407 - mae: 0.3269 - val_loss: 0.3575 - val_mse: 1259.2612 - val_mae: 0.3575\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3608 - mse: 1165.7506 - mae: 0.3608 - val_loss: 0.3576 - val_mse: 1259.2578 - val_mae: 0.3576\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8364 - mse: 35070509056.0000 - mae: 483.8357 - val_loss: 0.3574 - val_mse: 1259.2623 - val_mae: 0.3574\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3927 - mse: 1097.1503 - mae: 0.3927 - val_loss: 0.3575 - val_mse: 1259.2614 - val_mae: 0.3575\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7421 - mse: 20040292352.0000 - mae: 193.7421 - val_loss: 0.3573 - val_mse: 1259.2643 - val_mae: 0.3573\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3818 - mse: 1196.7083 - mae: 0.3818 - val_loss: 0.3573 - val_mse: 1259.2621 - val_mae: 0.3573\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1169 - mse: 30060435456.0000 - mae: 387.1168 - val_loss: 0.3572 - val_mse: 1259.2623 - val_mae: 0.3572\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3108 - mse: 810.5366 - mae: 0.3108 - val_loss: 0.3573 - val_mse: 1259.2612 - val_mae: 0.3573\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1946 - mse: 30060439552.0000 - mae: 387.1949 - val_loss: 0.3572 - val_mse: 1259.2621 - val_mae: 0.3572\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4015 - mse: 1333.1079 - mae: 0.4015 - val_loss: 0.3572 - val_mse: 1259.2622 - val_mae: 0.3572\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1097 - mse: 30060435456.0000 - mae: 387.1096 - val_loss: 0.3572 - val_mse: 1259.2627 - val_mae: 0.3572\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5241 - mse: 25050365952.0000 - mae: 290.5241 - val_loss: 0.3571 - val_mse: 1259.2595 - val_mae: 0.3571\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1491 - mse: 30060435456.0000 - mae: 387.1491 - val_loss: 0.3571 - val_mse: 1259.2609 - val_mae: 0.3571\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3533 - mse: 1093.8556 - mae: 0.3533 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3180 - mse: 750.6368 - mae: 0.3180 - val_loss: 0.3571 - val_mse: 1259.2593 - val_mae: 0.3571\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8289 - mse: 20040294400.0000 - mae: 193.8289 - val_loss: 0.3572 - val_mse: 1259.2585 - val_mae: 0.3572\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2750 - mse: 651.4815 - mae: 0.2750 - val_loss: 0.3572 - val_mse: 1259.2612 - val_mae: 0.3572\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2198 - mse: 30060435456.0000 - mae: 387.2198 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2743 - mse: 619.7676 - mae: 0.2743 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3096 - mse: 783.6841 - mae: 0.3096 - val_loss: 0.3573 - val_mse: 1259.2605 - val_mae: 0.3573\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1930 - mse: 30060435456.0000 - mae: 387.1929 - val_loss: 0.3571 - val_mse: 1259.2614 - val_mae: 0.3571\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3809 - mse: 1133.8672 - mae: 0.3809 - val_loss: 0.3574 - val_mse: 1259.2616 - val_mae: 0.3574\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8175 - mse: 20040292352.0000 - mae: 193.8175 - val_loss: 0.3573 - val_mse: 1259.2604 - val_mae: 0.3573\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4640 - mse: 25050363904.0000 - mae: 290.4640 - val_loss: 0.3573 - val_mse: 1259.2601 - val_mae: 0.3573\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2919 - mse: 882.3691 - mae: 0.2919 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3141 - mse: 946.8394 - mae: 0.3141 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5186 - mse: 25050365952.0000 - mae: 290.5187 - val_loss: 0.3572 - val_mse: 1259.2643 - val_mae: 0.3572\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8102 - mse: 20040292352.0000 - mae: 193.8102 - val_loss: 0.3574 - val_mse: 1259.2599 - val_mae: 0.3574\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2835 - mse: 726.5759 - mae: 0.2835 - val_loss: 0.3575 - val_mse: 1259.2618 - val_mae: 0.3575\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3731 - mse: 1106.0112 - mae: 0.3731 - val_loss: 0.3575 - val_mse: 1259.2607 - val_mae: 0.3575\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4354 - mse: 25050363904.0000 - mae: 290.4353 - val_loss: 0.3574 - val_mse: 1259.2601 - val_mae: 0.3574\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1652 - mse: 30060435456.0000 - mae: 387.1653 - val_loss: 0.3575 - val_mse: 1259.2607 - val_mae: 0.3575\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4193 - mse: 1365.7833 - mae: 0.4193 - val_loss: 0.3575 - val_mse: 1259.2617 - val_mae: 0.3575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2780 - mse: 572.0295 - mae: 0.2780 - val_loss: 0.3576 - val_mse: 1259.2617 - val_mae: 0.3576\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5545 - mse: 25050365952.0000 - mae: 290.5544 - val_loss: 0.3576 - val_mse: 1259.2642 - val_mae: 0.3576\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7919 - mse: 20040290304.0000 - mae: 193.7920 - val_loss: 0.3577 - val_mse: 1259.2589 - val_mae: 0.3577\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3711 - mse: 1160.3483 - mae: 0.3711 - val_loss: 0.3575 - val_mse: 1259.2601 - val_mae: 0.3575\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4393 - mse: 1453.9164 - mae: 0.4393 - val_loss: 0.3578 - val_mse: 1259.2618 - val_mae: 0.3578\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5322 - mse: 40080580608.0000 - mae: 580.5322 - val_loss: 0.3576 - val_mse: 1259.2609 - val_mae: 0.3576\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9623 - mse: 35070509056.0000 - mae: 483.9613 - val_loss: 0.3577 - val_mse: 1259.2614 - val_mae: 0.3577\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2495 - mse: 553.4125 - mae: 0.2495 - val_loss: 0.3576 - val_mse: 1259.2606 - val_mae: 0.3576\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3254 - mse: 879.0086 - mae: 0.3254 - val_loss: 0.3578 - val_mse: 1259.2592 - val_mae: 0.3578\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2680 - mse: 30060439552.0000 - mae: 387.2679 - val_loss: 0.3577 - val_mse: 1259.2627 - val_mae: 0.3577\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3730 - mse: 1043.4481 - mae: 0.3730 - val_loss: 0.3577 - val_mse: 1259.2638 - val_mae: 0.3577\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1673 - mse: 30060435456.0000 - mae: 387.1673 - val_loss: 0.3578 - val_mse: 1259.2629 - val_mae: 0.3578\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9822 - mse: 50100727808.0000 - mae: 773.9813 - val_loss: 0.3580 - val_mse: 1259.2582 - val_mae: 0.3580\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3596 - mse: 978.4930 - mae: 0.3596 - val_loss: 0.3578 - val_mse: 1259.2582 - val_mae: 0.3578\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3955 - mse: 1149.7919 - mae: 0.3955 - val_loss: 0.3579 - val_mse: 1259.2603 - val_mae: 0.3579\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1257 - mse: 30060435456.0000 - mae: 387.1257 - val_loss: 0.3580 - val_mse: 1259.2601 - val_mae: 0.3580\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1406 - mse: 30060435456.0000 - mae: 387.1405 - val_loss: 0.3580 - val_mse: 1259.2605 - val_mae: 0.3580\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3569 - mse: 1061.4152 - mae: 0.3569 - val_loss: 0.3580 - val_mse: 1259.2598 - val_mae: 0.3580\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2903 - mse: 728.5113 - mae: 0.2903 - val_loss: 0.3579 - val_mse: 1259.2607 - val_mae: 0.3579\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1778 - mse: 30060435456.0000 - mae: 387.1778 - val_loss: 0.3580 - val_mse: 1259.2598 - val_mae: 0.3580\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8702 - mse: 35070509056.0000 - mae: 483.8686 - val_loss: 0.3583 - val_mse: 1259.2620 - val_mae: 0.3583\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3556 - mse: 1066.6464 - mae: 0.3556 - val_loss: 0.3579 - val_mse: 1259.2614 - val_mae: 0.3579\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3888 - mse: 1201.3866 - mae: 0.3888 - val_loss: 0.3580 - val_mse: 1259.2576 - val_mae: 0.3580\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4750 - mse: 25050365952.0000 - mae: 290.4750 - val_loss: 0.3580 - val_mse: 1259.2590 - val_mae: 0.3580\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9387 - mse: 35070509056.0000 - mae: 483.9375 - val_loss: 0.3580 - val_mse: 1259.2584 - val_mae: 0.3580\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2992 - mse: 841.1974 - mae: 0.2992 - val_loss: 0.3584 - val_mse: 1259.2588 - val_mae: 0.3584\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4632 - mse: 1436.3220 - mae: 0.4632 - val_loss: 0.3582 - val_mse: 1259.2572 - val_mae: 0.3582\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4471 - mse: 25050365952.0000 - mae: 290.4470 - val_loss: 0.3581 - val_mse: 1259.2561 - val_mae: 0.3581\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3155 - mse: 812.1396 - mae: 0.3155 - val_loss: 0.3581 - val_mse: 1259.2582 - val_mae: 0.3581\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1582 - mse: 30060435456.0000 - mae: 387.1581 - val_loss: 0.3581 - val_mse: 1259.2590 - val_mae: 0.3581\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4225 - mse: 25050365952.0000 - mae: 290.4224 - val_loss: 0.3583 - val_mse: 1259.2559 - val_mae: 0.3583\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3597 - mse: 1063.1711 - mae: 0.3597 - val_loss: 0.3583 - val_mse: 1259.2566 - val_mae: 0.3583\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4360 - mse: 1466.9418 - mae: 0.4360 - val_loss: 0.3583 - val_mse: 1259.2562 - val_mae: 0.3583\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.4413 - mse: 40080580608.0000 - mae: 580.4410 - val_loss: 0.3583 - val_mse: 1259.2629 - val_mae: 0.3583\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.4644 - mse: 25050363904.0000 - mae: 290.4643 - val_loss: 0.3585 - val_mse: 1259.2595 - val_mae: 0.3585\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3790 - mse: 1082.9792 - mae: 0.3790 - val_loss: 0.3584 - val_mse: 1259.2589 - val_mae: 0.3584\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9170 - mse: 35070517248.0000 - mae: 483.9146 - val_loss: 0.3583 - val_mse: 1259.2604 - val_mae: 0.3583\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2998 - mse: 845.8219 - mae: 0.2998 - val_loss: 0.3583 - val_mse: 1259.2596 - val_mae: 0.3583\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5015 - mse: 25050365952.0000 - mae: 290.5014 - val_loss: 0.3588 - val_mse: 1259.2584 - val_mae: 0.3588\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2390 - mse: 540.1653 - mae: 0.2390 - val_loss: 0.3585 - val_mse: 1259.2616 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 484.0329 - mse: 35070509056.0000 - mae: 484.0330 - val_loss: 0.3641 - val_mse: 1259.2852 - val_mae: 0.3641\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2956 - mse: 557.6392 - mae: 0.2956 - val_loss: 0.3614 - val_mse: 1259.2650 - val_mae: 0.3614\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2516 - mse: 30060439552.0000 - mae: 387.2516 - val_loss: 0.3607 - val_mse: 1259.2664 - val_mae: 0.3607\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3180 - mse: 768.4175 - mae: 0.3180 - val_loss: 0.3603 - val_mse: 1259.2655 - val_mae: 0.3603\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3556 - mse: 998.2086 - mae: 0.3556 - val_loss: 0.3601 - val_mse: 1259.2661 - val_mae: 0.3601\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0508 - mse: 50100727808.0000 - mae: 774.0511 - val_loss: 0.3598 - val_mse: 1259.2642 - val_mae: 0.3598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9566 - mse: 50100727808.0000 - mae: 773.9567 - val_loss: 0.3597 - val_mse: 1259.2633 - val_mae: 0.3597\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3590 - mse: 1047.8668 - mae: 0.3590 - val_loss: 0.3595 - val_mse: 1259.2640 - val_mae: 0.3595\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8612 - mse: 35070509056.0000 - mae: 483.8611 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3473 - mse: 1058.8097 - mae: 0.3473 - val_loss: 0.3592 - val_mse: 1259.2632 - val_mae: 0.3592\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7985 - mse: 20040292352.0000 - mae: 193.7984 - val_loss: 0.3591 - val_mse: 1259.2633 - val_mae: 0.3591\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3364 - mse: 909.3370 - mae: 0.3364 - val_loss: 0.3590 - val_mse: 1259.2639 - val_mae: 0.3590\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4993 - mse: 25050363904.0000 - mae: 290.4993 - val_loss: 0.3588 - val_mse: 1259.2631 - val_mae: 0.3588\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3356 - mse: 832.8292 - mae: 0.3356 - val_loss: 0.3587 - val_mse: 1259.2635 - val_mae: 0.3587\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3390 - mse: 919.1258 - mae: 0.3390 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5030 - mse: 25050365952.0000 - mae: 290.5030 - val_loss: 0.3585 - val_mse: 1259.2650 - val_mae: 0.3585\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2538 - mse: 30060439552.0000 - mae: 387.2537 - val_loss: 0.3584 - val_mse: 1259.2595 - val_mae: 0.3584\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2915 - mse: 601.5151 - mae: 0.2915 - val_loss: 0.3583 - val_mse: 1259.2625 - val_mae: 0.3583\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7444 - mse: 20040292352.0000 - mae: 193.7443 - val_loss: 0.3583 - val_mse: 1259.2656 - val_mae: 0.3583\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3722 - mse: 1063.3141 - mae: 0.3722 - val_loss: 0.3581 - val_mse: 1259.2615 - val_mae: 0.3581\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4861 - mse: 25050365952.0000 - mae: 290.4862 - val_loss: 0.3581 - val_mse: 1259.2633 - val_mae: 0.3581\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2860 - mse: 615.8988 - mae: 0.2860 - val_loss: 0.3579 - val_mse: 1259.2644 - val_mae: 0.3579\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2838 - mse: 521.4061 - mae: 0.2838 - val_loss: 0.3579 - val_mse: 1259.2631 - val_mae: 0.3579\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6177 - mse: 40080584704.0000 - mae: 580.6170 - val_loss: 0.3578 - val_mse: 1259.2616 - val_mae: 0.3578\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4588 - mse: 25050365952.0000 - mae: 290.4588 - val_loss: 0.3577 - val_mse: 1259.2596 - val_mae: 0.3577\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3492 - mse: 958.0915 - mae: 0.3492 - val_loss: 0.3577 - val_mse: 1259.2622 - val_mae: 0.3577\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4440 - mse: 25050365952.0000 - mae: 290.4440 - val_loss: 0.3576 - val_mse: 1259.2612 - val_mae: 0.3576\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3608 - mse: 1090.4819 - mae: 0.3608 - val_loss: 0.3576 - val_mse: 1259.2628 - val_mae: 0.3576\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2890 - mse: 30060435456.0000 - mae: 387.2889 - val_loss: 0.3575 - val_mse: 1259.2601 - val_mae: 0.3575\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2333 - mse: 416.3719 - mae: 0.2333 - val_loss: 0.3574 - val_mse: 1259.2640 - val_mae: 0.3574\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4690 - mse: 25050363904.0000 - mae: 290.4690 - val_loss: 0.3574 - val_mse: 1259.2634 - val_mae: 0.3574\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3229 - mse: 993.5601 - mae: 0.3229 - val_loss: 0.3574 - val_mse: 1259.2627 - val_mae: 0.3574\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4652 - mse: 1542.2478 - mae: 0.4652 - val_loss: 0.3574 - val_mse: 1259.2618 - val_mae: 0.3574\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3662 - mse: 25050365952.0000 - mae: 290.3661 - val_loss: 0.3574 - val_mse: 1259.2616 - val_mae: 0.3574\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9115 - mse: 35070509056.0000 - mae: 483.9114 - val_loss: 0.3573 - val_mse: 1259.2616 - val_mae: 0.3573\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3460 - mse: 904.2045 - mae: 0.3460 - val_loss: 0.3572 - val_mse: 1259.2637 - val_mae: 0.3572\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3005 - mse: 756.5280 - mae: 0.3005 - val_loss: 0.3573 - val_mse: 1259.2617 - val_mae: 0.3573\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5316 - mse: 25050365952.0000 - mae: 290.5316 - val_loss: 0.3572 - val_mse: 1259.2625 - val_mae: 0.3572\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3345 - mse: 994.4666 - mae: 0.3345 - val_loss: 0.3574 - val_mse: 1259.2610 - val_mae: 0.3574\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1515 - mse: 30060439552.0000 - mae: 387.1514 - val_loss: 0.3571 - val_mse: 1259.2614 - val_mae: 0.3571\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4031 - mse: 1223.6145 - mae: 0.4031 - val_loss: 0.3573 - val_mse: 1259.2631 - val_mae: 0.3573\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7762 - mse: 35070509056.0000 - mae: 483.7756 - val_loss: 0.3572 - val_mse: 1259.2601 - val_mae: 0.3572\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2485 - mse: 526.3556 - mae: 0.2485 - val_loss: 0.3573 - val_mse: 1259.2648 - val_mae: 0.3573\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2574 - mse: 30060435456.0000 - mae: 387.2573 - val_loss: 0.3572 - val_mse: 1259.2628 - val_mae: 0.3572\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6202 - mse: 40080580608.0000 - mae: 580.6191 - val_loss: 0.3572 - val_mse: 1259.2642 - val_mae: 0.3572\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3710 - mse: 1136.5339 - mae: 0.3710 - val_loss: 0.3570 - val_mse: 1259.2633 - val_mae: 0.3570\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3896 - mse: 1109.1906 - mae: 0.3896 - val_loss: 0.3572 - val_mse: 1259.2625 - val_mae: 0.3572\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 967.3309 - mse: 60120870912.0000 - mae: 967.3240 - val_loss: 0.3572 - val_mse: 1259.2635 - val_mae: 0.3572\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4581 - mse: 25050365952.0000 - mae: 290.4580 - val_loss: 0.3573 - val_mse: 1259.2635 - val_mae: 0.3573\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3703 - mse: 1076.1716 - mae: 0.3703 - val_loss: 0.3572 - val_mse: 1259.2625 - val_mae: 0.3572\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4157 - mse: 1259.0138 - mae: 0.4157 - val_loss: 0.3573 - val_mse: 1259.2645 - val_mae: 0.3573\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8230 - mse: 35070513152.0000 - mae: 483.8220 - val_loss: 0.3571 - val_mse: 1259.2618 - val_mae: 0.3571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1357 - mse: 30060435456.0000 - mae: 387.1357 - val_loss: 0.3573 - val_mse: 1259.2599 - val_mae: 0.3573\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4081 - mse: 1302.4595 - mae: 0.4081 - val_loss: 0.3572 - val_mse: 1259.2637 - val_mae: 0.3572\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2626 - mse: 584.1763 - mae: 0.2626 - val_loss: 0.3573 - val_mse: 1259.2651 - val_mae: 0.3573\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5796 - mse: 25050365952.0000 - mae: 290.5795 - val_loss: 0.3574 - val_mse: 1259.2644 - val_mae: 0.3574\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3108 - mse: 704.4935 - mae: 0.3108 - val_loss: 0.3574 - val_mse: 1259.2627 - val_mae: 0.3574\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5110 - mse: 25050365952.0000 - mae: 290.5112 - val_loss: 0.3573 - val_mse: 1259.2639 - val_mae: 0.3573\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4868 - mse: 25050365952.0000 - mae: 290.4868 - val_loss: 0.3574 - val_mse: 1259.2635 - val_mae: 0.3574\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2608 - mse: 714.0548 - mae: 0.2608 - val_loss: 0.3573 - val_mse: 1259.2618 - val_mae: 0.3573\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7672 - mse: 20040290304.0000 - mae: 193.7672 - val_loss: 0.3573 - val_mse: 1259.2632 - val_mae: 0.3573\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3077 - mse: 836.4581 - mae: 0.3077 - val_loss: 0.3575 - val_mse: 1259.2616 - val_mae: 0.3575\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3416 - mse: 947.6124 - mae: 0.3416 - val_loss: 0.3576 - val_mse: 1259.2617 - val_mae: 0.3576\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1211 - mse: 30060435456.0000 - mae: 387.1212 - val_loss: 0.3575 - val_mse: 1259.2618 - val_mae: 0.3575\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2938 - mse: 45090652160.0000 - mae: 677.2936 - val_loss: 0.3576 - val_mse: 1259.2596 - val_mae: 0.3576\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2936 - mse: 791.6347 - mae: 0.2936 - val_loss: 0.3576 - val_mse: 1259.2635 - val_mae: 0.3576\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2855 - mse: 754.2234 - mae: 0.2855 - val_loss: 0.3578 - val_mse: 1259.2637 - val_mae: 0.3578\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7999 - mse: 20040292352.0000 - mae: 193.7998 - val_loss: 0.3576 - val_mse: 1259.2614 - val_mae: 0.3576\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3072 - mse: 726.5958 - mae: 0.3072 - val_loss: 0.3578 - val_mse: 1259.2614 - val_mae: 0.3578\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2118 - mse: 30060435456.0000 - mae: 387.2117 - val_loss: 0.3577 - val_mse: 1259.2644 - val_mae: 0.3577\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7396 - mse: 20040292352.0000 - mae: 193.7396 - val_loss: 0.3579 - val_mse: 1259.2639 - val_mae: 0.3579\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3942 - mse: 1240.3654 - mae: 0.3942 - val_loss: 0.3578 - val_mse: 1259.2622 - val_mae: 0.3578\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5653 - mse: 25050363904.0000 - mae: 290.5653 - val_loss: 0.3581 - val_mse: 1259.2621 - val_mae: 0.3581\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2854 - mse: 616.4359 - mae: 0.2854 - val_loss: 0.3579 - val_mse: 1259.2628 - val_mae: 0.3579\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2404 - mse: 413.3664 - mae: 0.2404 - val_loss: 0.3578 - val_mse: 1259.2629 - val_mae: 0.3578\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2687 - mse: 30060435456.0000 - mae: 387.2686 - val_loss: 0.3581 - val_mse: 1259.2628 - val_mae: 0.3581\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3264 - mse: 928.8613 - mae: 0.3264 - val_loss: 0.3579 - val_mse: 1259.2639 - val_mae: 0.3579\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3166 - mse: 45090652160.0000 - mae: 677.3154 - val_loss: 0.3579 - val_mse: 1259.2656 - val_mae: 0.3579\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3285 - mse: 816.6203 - mae: 0.3285 - val_loss: 0.3581 - val_mse: 1259.2654 - val_mae: 0.3581\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7391 - mse: 20040292352.0000 - mae: 193.7393 - val_loss: 0.3580 - val_mse: 1259.2653 - val_mae: 0.3580\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3444 - mse: 931.6204 - mae: 0.3444 - val_loss: 0.3583 - val_mse: 1259.2611 - val_mae: 0.3583\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4720 - mse: 25050363904.0000 - mae: 290.4720 - val_loss: 0.3580 - val_mse: 1259.2638 - val_mae: 0.3580\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3561 - mse: 1047.6122 - mae: 0.3561 - val_loss: 0.3581 - val_mse: 1259.2645 - val_mae: 0.3581\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7331 - mse: 20040292352.0000 - mae: 193.7330 - val_loss: 0.3582 - val_mse: 1259.2649 - val_mae: 0.3582\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1768 - mse: 30060435456.0000 - mae: 387.1768 - val_loss: 0.3583 - val_mse: 1259.2648 - val_mae: 0.3583\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4075 - mse: 1123.7040 - mae: 0.4075 - val_loss: 0.3582 - val_mse: 1259.2631 - val_mae: 0.3582\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3053 - mse: 822.3279 - mae: 0.3053 - val_loss: 0.3583 - val_mse: 1259.2607 - val_mae: 0.3583\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9354 - mse: 35070509056.0000 - mae: 483.9331 - val_loss: 0.3582 - val_mse: 1259.2639 - val_mae: 0.3582\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4012 - mse: 25050365952.0000 - mae: 290.4012 - val_loss: 0.3585 - val_mse: 1259.2657 - val_mae: 0.3585\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3867 - mse: 1175.0875 - mae: 0.3867 - val_loss: 0.3582 - val_mse: 1259.2672 - val_mae: 0.3582\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3408 - mse: 1005.3928 - mae: 0.3408 - val_loss: 0.3585 - val_mse: 1259.2628 - val_mae: 0.3585\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7398 - mse: 20040292352.0000 - mae: 193.7398 - val_loss: 0.3583 - val_mse: 1259.2662 - val_mae: 0.3583\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8725 - mse: 35070509056.0000 - mae: 483.8705 - val_loss: 0.3584 - val_mse: 1259.2656 - val_mae: 0.3584\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2744 - mse: 806.5334 - mae: 0.2744 - val_loss: 0.3586 - val_mse: 1259.2655 - val_mae: 0.3586\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8347 - mse: 35070509056.0000 - mae: 483.8341 - val_loss: 0.3585 - val_mse: 1259.2651 - val_mae: 0.3585\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3113 - mse: 1024.3669 - mae: 0.3113 - val_loss: 0.3585 - val_mse: 1259.2621 - val_mae: 0.3585\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8529 - mse: 35070509056.0000 - mae: 483.8509 - val_loss: 0.3585 - val_mse: 1259.2646 - val_mae: 0.3585\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3344 - mse: 966.9985 - mae: 0.3344 - val_loss: 0.3584 - val_mse: 1259.2633 - val_mae: 0.3584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2776 - mse: 637.6114 - mae: 0.2776 - val_loss: 0.3586 - val_mse: 1259.2655 - val_mae: 0.3586\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8630 - mse: 35070509056.0000 - mae: 483.8618 - val_loss: 0.3588 - val_mse: 1259.2621 - val_mae: 0.3588\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.5054 - mse: 1421.8270 - mae: 0.5054 - val_loss: 0.3631 - val_mse: 1259.2979 - val_mae: 0.3631\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.4834 - mse: 40080580608.0000 - mae: 580.4843 - val_loss: 0.3617 - val_mse: 1259.2783 - val_mae: 0.3617\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2234 - mse: 30060435456.0000 - mae: 387.2235 - val_loss: 0.3608 - val_mse: 1259.2651 - val_mae: 0.3608\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3329 - mse: 844.3347 - mae: 0.3329 - val_loss: 0.3604 - val_mse: 1259.2648 - val_mae: 0.3604\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1933 - mse: 30060439552.0000 - mae: 387.1932 - val_loss: 0.3600 - val_mse: 1259.2632 - val_mae: 0.3600\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3622 - mse: 1050.1469 - mae: 0.3622 - val_loss: 0.3598 - val_mse: 1259.2627 - val_mae: 0.3598\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3885 - mse: 1205.2469 - mae: 0.3885 - val_loss: 0.3596 - val_mse: 1259.2655 - val_mae: 0.3596\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1401 - mse: 30060435456.0000 - mae: 387.1399 - val_loss: 0.3594 - val_mse: 1259.2650 - val_mae: 0.3594\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3656 - mse: 879.8411 - mae: 0.3656 - val_loss: 0.3593 - val_mse: 1259.2616 - val_mae: 0.3593\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1697 - mse: 30060435456.0000 - mae: 387.1697 - val_loss: 0.3592 - val_mse: 1259.2639 - val_mae: 0.3592\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4775 - mse: 25050363904.0000 - mae: 290.4775 - val_loss: 0.3591 - val_mse: 1259.2628 - val_mae: 0.3591\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3168 - mse: 904.6848 - mae: 0.3168 - val_loss: 0.3591 - val_mse: 1259.2626 - val_mae: 0.3591\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2258 - mse: 30060435456.0000 - mae: 387.2259 - val_loss: 0.3588 - val_mse: 1259.2625 - val_mae: 0.3588\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3073 - mse: 910.2076 - mae: 0.3073 - val_loss: 0.3588 - val_mse: 1259.2621 - val_mae: 0.3588\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2825 - mse: 738.5269 - mae: 0.2825 - val_loss: 0.3587 - val_mse: 1259.2611 - val_mae: 0.3587\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2158 - mse: 30060435456.0000 - mae: 387.2158 - val_loss: 0.3586 - val_mse: 1259.2605 - val_mae: 0.3586\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1582 - mse: 30060435456.0000 - mae: 387.1582 - val_loss: 0.3585 - val_mse: 1259.2649 - val_mae: 0.3585\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3596 - mse: 896.1072 - mae: 0.3596 - val_loss: 0.3584 - val_mse: 1259.2606 - val_mae: 0.3584\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3999 - mse: 1273.1315 - mae: 0.3999 - val_loss: 0.3583 - val_mse: 1259.2578 - val_mae: 0.3583\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9274 - mse: 50100727808.0000 - mae: 773.9275 - val_loss: 0.3582 - val_mse: 1259.2628 - val_mae: 0.3582\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3627 - mse: 1009.3105 - mae: 0.3627 - val_loss: 0.3581 - val_mse: 1259.2615 - val_mae: 0.3581\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4450 - mse: 25050365952.0000 - mae: 290.4450 - val_loss: 0.3581 - val_mse: 1259.2600 - val_mae: 0.3581\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8938 - mse: 35070509056.0000 - mae: 483.8936 - val_loss: 0.3580 - val_mse: 1259.2639 - val_mae: 0.3580\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2935 - mse: 754.7251 - mae: 0.2935 - val_loss: 0.3579 - val_mse: 1259.2604 - val_mae: 0.3579\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5129 - mse: 40080584704.0000 - mae: 580.5128 - val_loss: 0.3579 - val_mse: 1259.2611 - val_mae: 0.3579\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4791 - mse: 1569.3715 - mae: 0.4791 - val_loss: 0.3578 - val_mse: 1259.2633 - val_mae: 0.3578\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2649 - mse: 643.5576 - mae: 0.2649 - val_loss: 0.3578 - val_mse: 1259.2627 - val_mae: 0.3578\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5635 - mse: 25050365952.0000 - mae: 290.5635 - val_loss: 0.3577 - val_mse: 1259.2593 - val_mae: 0.3577\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6053 - mse: 50100727808.0000 - mae: 580.6048 - val_loss: 0.3577 - val_mse: 1259.2626 - val_mae: 0.3577\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3165 - mse: 862.3295 - mae: 0.3165 - val_loss: 0.3576 - val_mse: 1259.2590 - val_mae: 0.3576\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3312 - mse: 801.4069 - mae: 0.3312 - val_loss: 0.3576 - val_mse: 1259.2604 - val_mae: 0.3576\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9606 - mse: 35070509056.0000 - mae: 483.9605 - val_loss: 0.3574 - val_mse: 1259.2614 - val_mae: 0.3574\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2330 - mse: 30060435456.0000 - mae: 387.2332 - val_loss: 0.3574 - val_mse: 1259.2610 - val_mae: 0.3574\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2569 - mse: 514.6297 - mae: 0.2569 - val_loss: 0.3573 - val_mse: 1259.2639 - val_mae: 0.3573\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4643 - mse: 1514.8499 - mae: 0.4643 - val_loss: 0.3574 - val_mse: 1259.2642 - val_mae: 0.3574\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0374 - mse: 30060435456.0000 - mae: 387.0374 - val_loss: 0.3572 - val_mse: 1259.2625 - val_mae: 0.3572\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2629 - mse: 594.1045 - mae: 0.2629 - val_loss: 0.3573 - val_mse: 1259.2607 - val_mae: 0.3573\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.6420 - mse: 25050365952.0000 - mae: 290.6421 - val_loss: 0.3572 - val_mse: 1259.2570 - val_mae: 0.3572\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3258 - mse: 901.2976 - mae: 0.3258 - val_loss: 0.3572 - val_mse: 1259.2605 - val_mae: 0.3572\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1847 - mse: 30060435456.0000 - mae: 387.1847 - val_loss: 0.3571 - val_mse: 1259.2622 - val_mae: 0.3571\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2866 - mse: 740.7308 - mae: 0.2866 - val_loss: 0.3572 - val_mse: 1259.2616 - val_mae: 0.3572\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5145 - mse: 25050365952.0000 - mae: 290.5144 - val_loss: 0.3571 - val_mse: 1259.2623 - val_mae: 0.3571\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3290 - mse: 931.8738 - mae: 0.3290 - val_loss: 0.3573 - val_mse: 1259.2582 - val_mae: 0.3573\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9117 - mse: 35070513152.0000 - mae: 483.9115 - val_loss: 0.3570 - val_mse: 1259.2622 - val_mae: 0.3570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3255 - mse: 827.1442 - mae: 0.3255 - val_loss: 0.3571 - val_mse: 1259.2596 - val_mae: 0.3571\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2586 - mse: 30060435456.0000 - mae: 387.2583 - val_loss: 0.3571 - val_mse: 1259.2643 - val_mae: 0.3571\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2787 - mse: 652.8585 - mae: 0.2787 - val_loss: 0.3571 - val_mse: 1259.2604 - val_mae: 0.3571\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2004 - mse: 30060435456.0000 - mae: 387.2005 - val_loss: 0.3572 - val_mse: 1259.2626 - val_mae: 0.3572\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3132 - mse: 819.7562 - mae: 0.3132 - val_loss: 0.3571 - val_mse: 1259.2606 - val_mae: 0.3571\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2029 - mse: 30060435456.0000 - mae: 387.2030 - val_loss: 0.3571 - val_mse: 1259.2604 - val_mae: 0.3571\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3002 - mse: 817.2819 - mae: 0.3002 - val_loss: 0.3573 - val_mse: 1259.2617 - val_mae: 0.3573\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1953 - mse: 30060435456.0000 - mae: 387.1952 - val_loss: 0.3571 - val_mse: 1259.2601 - val_mae: 0.3571\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4423 - mse: 25050365952.0000 - mae: 290.4424 - val_loss: 0.3573 - val_mse: 1259.2639 - val_mae: 0.3573\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3833 - mse: 1072.3088 - mae: 0.3833 - val_loss: 0.3570 - val_mse: 1259.2616 - val_mae: 0.3570\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3662 - mse: 1018.9228 - mae: 0.3662 - val_loss: 0.3572 - val_mse: 1259.2623 - val_mae: 0.3572\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1589 - mse: 30060439552.0000 - mae: 387.1590 - val_loss: 0.3571 - val_mse: 1259.2563 - val_mae: 0.3571\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3163 - mse: 952.3875 - mae: 0.3163 - val_loss: 0.3573 - val_mse: 1259.2599 - val_mae: 0.3573\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4672 - mse: 25050365952.0000 - mae: 290.4670 - val_loss: 0.3572 - val_mse: 1259.2618 - val_mae: 0.3572\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4815 - mse: 1384.5894 - mae: 0.4815 - val_loss: 0.3570 - val_mse: 1259.2616 - val_mae: 0.3570\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8271 - mse: 35070509056.0000 - mae: 483.8258 - val_loss: 0.3571 - val_mse: 1259.2582 - val_mae: 0.3571\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4989 - mse: 25050363904.0000 - mae: 290.4989 - val_loss: 0.3572 - val_mse: 1259.2622 - val_mae: 0.3572\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3244 - mse: 831.3952 - mae: 0.3244 - val_loss: 0.3572 - val_mse: 1259.2637 - val_mae: 0.3572\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3888 - mse: 25050365952.0000 - mae: 290.3890 - val_loss: 0.3574 - val_mse: 1259.2629 - val_mae: 0.3574\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4014 - mse: 1174.0239 - mae: 0.4014 - val_loss: 0.3572 - val_mse: 1259.2603 - val_mae: 0.3572\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8648 - mse: 35070509056.0000 - mae: 483.8643 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4051 - mse: 1249.9302 - mae: 0.4051 - val_loss: 0.3573 - val_mse: 1259.2629 - val_mae: 0.3573\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3602 - mse: 1106.5039 - mae: 0.3602 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7084 - mse: 20040290304.0000 - mae: 193.7084 - val_loss: 0.3574 - val_mse: 1259.2633 - val_mae: 0.3574\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3705 - mse: 1205.7355 - mae: 0.3705 - val_loss: 0.3575 - val_mse: 1259.2610 - val_mae: 0.3575\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7371 - mse: 20040292352.0000 - mae: 193.7372 - val_loss: 0.3573 - val_mse: 1259.2631 - val_mae: 0.3573\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2770 - mse: 715.4827 - mae: 0.2770 - val_loss: 0.3574 - val_mse: 1259.2637 - val_mae: 0.3574\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2830 - mse: 55110799360.0000 - mae: 677.2830 - val_loss: 0.3573 - val_mse: 1259.2601 - val_mae: 0.3573\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3178 - mse: 829.7561 - mae: 0.3178 - val_loss: 0.3574 - val_mse: 1259.2633 - val_mae: 0.3574\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3661 - mse: 1076.4924 - mae: 0.3661 - val_loss: 0.3573 - val_mse: 1259.2622 - val_mae: 0.3573\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4342 - mse: 25050365952.0000 - mae: 290.4341 - val_loss: 0.3575 - val_mse: 1259.2621 - val_mae: 0.3575\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3477 - mse: 939.4987 - mae: 0.3477 - val_loss: 0.3574 - val_mse: 1259.2599 - val_mae: 0.3574\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7662 - mse: 20040290304.0000 - mae: 193.7662 - val_loss: 0.3576 - val_mse: 1259.2612 - val_mae: 0.3576\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3346 - mse: 957.4908 - mae: 0.3346 - val_loss: 0.3575 - val_mse: 1259.2635 - val_mae: 0.3575\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.1450 - mse: 30060435456.0000 - mae: 387.1448 - val_loss: 0.3576 - val_mse: 1259.2629 - val_mae: 0.3576\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3754 - mse: 1048.9749 - mae: 0.3754 - val_loss: 0.3576 - val_mse: 1259.2638 - val_mae: 0.3576\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2907 - mse: 787.0697 - mae: 0.2907 - val_loss: 0.3577 - val_mse: 1259.2621 - val_mae: 0.3577\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1963 - mse: 30060435456.0000 - mae: 387.1961 - val_loss: 0.3575 - val_mse: 1259.2620 - val_mae: 0.3575\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3037 - mse: 938.4974 - mae: 0.3037 - val_loss: 0.3576 - val_mse: 1259.2642 - val_mae: 0.3576\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4570 - mse: 25050365952.0000 - mae: 290.4570 - val_loss: 0.3576 - val_mse: 1259.2628 - val_mae: 0.3576\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1443 - mse: 30060435456.0000 - mae: 387.1442 - val_loss: 0.3579 - val_mse: 1259.2620 - val_mae: 0.3579\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3742 - mse: 1066.7953 - mae: 0.3742 - val_loss: 0.3576 - val_mse: 1259.2650 - val_mae: 0.3576\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3732 - mse: 1133.2416 - mae: 0.3732 - val_loss: 0.3579 - val_mse: 1259.2587 - val_mae: 0.3579\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5247 - mse: 40080580608.0000 - mae: 580.5233 - val_loss: 0.3578 - val_mse: 1259.2651 - val_mae: 0.3578\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9522 - mse: 35070509056.0000 - mae: 483.9503 - val_loss: 0.3580 - val_mse: 1259.2622 - val_mae: 0.3580\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2894 - mse: 686.1064 - mae: 0.2894 - val_loss: 0.3581 - val_mse: 1259.2631 - val_mae: 0.3581\n",
      "Epoch 91/105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4302 - mse: 1272.7756 - mae: 0.4302 - val_loss: 0.3579 - val_mse: 1259.2626 - val_mae: 0.3579\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8419 - mse: 35070509056.0000 - mae: 483.8388 - val_loss: 0.3579 - val_mse: 1259.2637 - val_mae: 0.3579\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1291 - mse: 30060435456.0000 - mae: 387.1290 - val_loss: 0.3580 - val_mse: 1259.2650 - val_mae: 0.3580\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4542 - mse: 1521.7356 - mae: 0.4542 - val_loss: 0.3577 - val_mse: 1259.2573 - val_mae: 0.3577\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9090 - mse: 35070509056.0000 - mae: 483.9080 - val_loss: 0.3582 - val_mse: 1259.2650 - val_mae: 0.3582\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2799 - mse: 597.4937 - mae: 0.2799 - val_loss: 0.3577 - val_mse: 1259.2631 - val_mae: 0.3577\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7203 - mse: 20040292352.0000 - mae: 193.7203 - val_loss: 0.3580 - val_mse: 1259.2570 - val_mae: 0.3580\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3340 - mse: 877.4031 - mae: 0.3340 - val_loss: 0.3580 - val_mse: 1259.2599 - val_mae: 0.3580\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4734 - mse: 25050365952.0000 - mae: 290.4733 - val_loss: 0.3580 - val_mse: 1259.2596 - val_mae: 0.3580\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3600 - mse: 995.4781 - mae: 0.3600 - val_loss: 0.3579 - val_mse: 1259.2601 - val_mae: 0.3579\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.4172 - mse: 1091.0336 - mae: 0.4172 - val_loss: 0.3639 - val_mse: 1259.2795 - val_mae: 0.3639\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4757 - mse: 25050363904.0000 - mae: 290.4760 - val_loss: 0.3615 - val_mse: 1259.2662 - val_mae: 0.3615\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8427 - mse: 20040292352.0000 - mae: 193.8427 - val_loss: 0.3607 - val_mse: 1259.2615 - val_mae: 0.3607\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3666 - mse: 888.5005 - mae: 0.3666 - val_loss: 0.3602 - val_mse: 1259.2635 - val_mae: 0.3602\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9667 - mse: 50100727808.0000 - mae: 773.9667 - val_loss: 0.3601 - val_mse: 1259.2648 - val_mae: 0.3601\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3811 - mse: 1052.1329 - mae: 0.3811 - val_loss: 0.3597 - val_mse: 1259.2642 - val_mae: 0.3597\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1973 - mse: 30060435456.0000 - mae: 387.1975 - val_loss: 0.3596 - val_mse: 1259.2660 - val_mae: 0.3596\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3276 - mse: 853.1927 - mae: 0.3276 - val_loss: 0.3594 - val_mse: 1259.2648 - val_mae: 0.3594\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0599 - mse: 30060435456.0000 - mae: 387.0598 - val_loss: 0.3593 - val_mse: 1259.2642 - val_mae: 0.3593\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4159 - mse: 1426.9745 - mae: 0.4159 - val_loss: 0.3591 - val_mse: 1259.2643 - val_mae: 0.3591\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3231 - mse: 813.1524 - mae: 0.3231 - val_loss: 0.3590 - val_mse: 1259.2656 - val_mae: 0.3590\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4921 - mse: 25050363904.0000 - mae: 290.4921 - val_loss: 0.3589 - val_mse: 1259.2623 - val_mae: 0.3589\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3758 - mse: 1058.9542 - mae: 0.3758 - val_loss: 0.3588 - val_mse: 1259.2656 - val_mae: 0.3588\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4504 - mse: 25050365952.0000 - mae: 290.4502 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3890 - mse: 1150.1237 - mae: 0.3890 - val_loss: 0.3586 - val_mse: 1259.2653 - val_mae: 0.3586\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1199 - mse: 30060439552.0000 - mae: 387.1199 - val_loss: 0.3585 - val_mse: 1259.2635 - val_mae: 0.3585\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8970 - mse: 35070509056.0000 - mae: 483.8968 - val_loss: 0.3584 - val_mse: 1259.2622 - val_mae: 0.3584\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3583 - mse: 1023.2722 - mae: 0.3583 - val_loss: 0.3583 - val_mse: 1259.2615 - val_mae: 0.3583\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3777 - mse: 885.0803 - mae: 0.3777 - val_loss: 0.3583 - val_mse: 1259.2648 - val_mae: 0.3583\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6421 - mse: 40080580608.0000 - mae: 580.6415 - val_loss: 0.3581 - val_mse: 1259.2607 - val_mae: 0.3581\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3009 - mse: 831.9722 - mae: 0.3009 - val_loss: 0.3581 - val_mse: 1259.2598 - val_mae: 0.3581\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4974 - mse: 25050365952.0000 - mae: 290.4975 - val_loss: 0.3579 - val_mse: 1259.2634 - val_mae: 0.3579\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4343 - mse: 25050363904.0000 - mae: 290.4344 - val_loss: 0.3579 - val_mse: 1259.2628 - val_mae: 0.3579\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4099 - mse: 1317.5505 - mae: 0.4099 - val_loss: 0.3578 - val_mse: 1259.2607 - val_mae: 0.3578\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4278 - mse: 1346.9678 - mae: 0.4278 - val_loss: 0.3579 - val_mse: 1259.2622 - val_mae: 0.3579\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7937 - mse: 35070509056.0000 - mae: 483.7934 - val_loss: 0.3578 - val_mse: 1259.2606 - val_mae: 0.3578\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2473 - mse: 606.1061 - mae: 0.2473 - val_loss: 0.3578 - val_mse: 1259.2633 - val_mae: 0.3578\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5433 - mse: 25050363904.0000 - mae: 290.5433 - val_loss: 0.3576 - val_mse: 1259.2614 - val_mae: 0.3576\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 580.6643 - mse: 40080580608.0000 - mae: 580.6639 - val_loss: 0.3577 - val_mse: 1259.2607 - val_mae: 0.3577\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3122 - mse: 684.2615 - mae: 0.3122 - val_loss: 0.3575 - val_mse: 1259.2625 - val_mae: 0.3575\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2292 - mse: 30060435456.0000 - mae: 387.2288 - val_loss: 0.3574 - val_mse: 1259.2616 - val_mae: 0.3574\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2556 - mse: 576.5577 - mae: 0.2556 - val_loss: 0.3574 - val_mse: 1259.2618 - val_mae: 0.3574\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4578 - mse: 25050363904.0000 - mae: 290.4578 - val_loss: 0.3575 - val_mse: 1259.2622 - val_mae: 0.3575\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3493 - mse: 1114.2096 - mae: 0.3493 - val_loss: 0.3573 - val_mse: 1259.2594 - val_mae: 0.3573\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3929 - mse: 1145.5939 - mae: 0.3929 - val_loss: 0.3574 - val_mse: 1259.2589 - val_mae: 0.3574\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8304 - mse: 35070509056.0000 - mae: 483.8302 - val_loss: 0.3573 - val_mse: 1259.2628 - val_mae: 0.3573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3000 - mse: 649.6412 - mae: 0.3000 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3650 - mse: 45090652160.0000 - mae: 677.3640 - val_loss: 0.3573 - val_mse: 1259.2628 - val_mae: 0.3573\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0259 - mse: 30060439552.0000 - mae: 387.0259 - val_loss: 0.3574 - val_mse: 1259.2638 - val_mae: 0.3574\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.5210 - mse: 1682.3940 - mae: 0.5210 - val_loss: 0.3571 - val_mse: 1259.2562 - val_mae: 0.3571\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4715 - mse: 25050365952.0000 - mae: 290.4715 - val_loss: 0.3573 - val_mse: 1259.2590 - val_mae: 0.3573\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3361 - mse: 945.2355 - mae: 0.3361 - val_loss: 0.3573 - val_mse: 1259.2605 - val_mae: 0.3573\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3689 - mse: 1221.9283 - mae: 0.3689 - val_loss: 0.3573 - val_mse: 1259.2601 - val_mae: 0.3573\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1201 - mse: 30060435456.0000 - mae: 387.1201 - val_loss: 0.3572 - val_mse: 1259.2584 - val_mae: 0.3572\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4636 - mse: 25050365952.0000 - mae: 290.4635 - val_loss: 0.3572 - val_mse: 1259.2595 - val_mae: 0.3572\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3009 - mse: 791.9167 - mae: 0.3009 - val_loss: 0.3572 - val_mse: 1259.2627 - val_mae: 0.3572\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4554 - mse: 1499.0089 - mae: 0.4554 - val_loss: 0.3575 - val_mse: 1259.2574 - val_mae: 0.3575\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8476 - mse: 35070509056.0000 - mae: 483.8473 - val_loss: 0.3572 - val_mse: 1259.2593 - val_mae: 0.3572\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3243 - mse: 889.1439 - mae: 0.3243 - val_loss: 0.3574 - val_mse: 1259.2611 - val_mae: 0.3574\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5158 - mse: 25050365952.0000 - mae: 290.5156 - val_loss: 0.3573 - val_mse: 1259.2571 - val_mae: 0.3573\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5248 - mse: 40080580608.0000 - mae: 580.5234 - val_loss: 0.3576 - val_mse: 1259.2581 - val_mae: 0.3576\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4126 - mse: 1149.9288 - mae: 0.4126 - val_loss: 0.3574 - val_mse: 1259.2590 - val_mae: 0.3574\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4131 - mse: 25050363904.0000 - mae: 290.4130 - val_loss: 0.3575 - val_mse: 1259.2589 - val_mae: 0.3575\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4075 - mse: 1163.3206 - mae: 0.4075 - val_loss: 0.3573 - val_mse: 1259.2563 - val_mae: 0.3573\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.3010 - mse: 30060435456.0000 - mae: 387.3010 - val_loss: 0.3575 - val_mse: 1259.2594 - val_mae: 0.3575\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2420 - mse: 499.4595 - mae: 0.2420 - val_loss: 0.3575 - val_mse: 1259.2590 - val_mae: 0.3575\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3149 - mse: 866.3277 - mae: 0.3149 - val_loss: 0.3575 - val_mse: 1259.2584 - val_mae: 0.3575\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 580.6203 - mse: 40080584704.0000 - mae: 580.6197 - val_loss: 0.3573 - val_mse: 1259.2593 - val_mae: 0.3573\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2626 - mse: 30060439552.0000 - mae: 387.2627 - val_loss: 0.3577 - val_mse: 1259.2587 - val_mae: 0.3577\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2613 - mse: 569.6669 - mae: 0.2613 - val_loss: 0.3575 - val_mse: 1259.2562 - val_mae: 0.3575\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1555 - mse: 30060435456.0000 - mae: 387.1557 - val_loss: 0.3576 - val_mse: 1259.2576 - val_mae: 0.3576\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3817 - mse: 1161.8115 - mae: 0.3817 - val_loss: 0.3575 - val_mse: 1259.2609 - val_mae: 0.3575\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3685 - mse: 1032.9043 - mae: 0.3685 - val_loss: 0.3576 - val_mse: 1259.2618 - val_mae: 0.3576\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5022 - mse: 25050363904.0000 - mae: 290.5022 - val_loss: 0.3576 - val_mse: 1259.2605 - val_mae: 0.3576\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3794 - mse: 1180.8394 - mae: 0.3794 - val_loss: 0.3576 - val_mse: 1259.2614 - val_mae: 0.3576\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1747 - mse: 30060435456.0000 - mae: 387.1746 - val_loss: 0.3576 - val_mse: 1259.2601 - val_mae: 0.3576\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4355 - mse: 1373.0719 - mae: 0.4355 - val_loss: 0.3577 - val_mse: 1259.2589 - val_mae: 0.3577\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5542 - mse: 40080580608.0000 - mae: 580.5525 - val_loss: 0.3577 - val_mse: 1259.2618 - val_mae: 0.3577\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3666 - mse: 1005.3660 - mae: 0.3666 - val_loss: 0.3576 - val_mse: 1259.2573 - val_mae: 0.3576\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9049 - mse: 35070509056.0000 - mae: 483.9048 - val_loss: 0.3576 - val_mse: 1259.2596 - val_mae: 0.3576\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4435 - mse: 25050363904.0000 - mae: 290.4434 - val_loss: 0.3577 - val_mse: 1259.2599 - val_mae: 0.3577\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3301 - mse: 1001.8630 - mae: 0.3301 - val_loss: 0.3577 - val_mse: 1259.2570 - val_mae: 0.3577\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4243 - mse: 25050363904.0000 - mae: 290.4243 - val_loss: 0.3579 - val_mse: 1259.2594 - val_mae: 0.3579\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4064 - mse: 1174.9165 - mae: 0.4064 - val_loss: 0.3578 - val_mse: 1259.2567 - val_mae: 0.3578\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3421 - mse: 924.9197 - mae: 0.3421 - val_loss: 0.3578 - val_mse: 1259.2621 - val_mae: 0.3578\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4751 - mse: 25050365952.0000 - mae: 290.4753 - val_loss: 0.3580 - val_mse: 1259.2577 - val_mae: 0.3580\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4611 - mse: 1543.3202 - mae: 0.4611 - val_loss: 0.3579 - val_mse: 1259.2533 - val_mae: 0.3579\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0521 - mse: 30060435456.0000 - mae: 387.0520 - val_loss: 0.3577 - val_mse: 1259.2607 - val_mae: 0.3577\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2721 - mse: 581.4362 - mae: 0.2721 - val_loss: 0.3580 - val_mse: 1259.2612 - val_mae: 0.3580\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5200 - mse: 25050365952.0000 - mae: 290.5200 - val_loss: 0.3578 - val_mse: 1259.2595 - val_mae: 0.3578\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3077 - mse: 831.1241 - mae: 0.3077 - val_loss: 0.3579 - val_mse: 1259.2615 - val_mae: 0.3579\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9160 - mse: 35070513152.0000 - mae: 483.9134 - val_loss: 0.3579 - val_mse: 1259.2606 - val_mae: 0.3579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4292 - mse: 1196.9745 - mae: 0.4292 - val_loss: 0.3579 - val_mse: 1259.2594 - val_mae: 0.3579\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1191 - mse: 30060435456.0000 - mae: 387.1191 - val_loss: 0.3579 - val_mse: 1259.2601 - val_mae: 0.3579\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7878 - mse: 35070509056.0000 - mae: 483.7861 - val_loss: 0.3581 - val_mse: 1259.2627 - val_mae: 0.3581\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4020 - mse: 1202.4355 - mae: 0.4020 - val_loss: 0.3579 - val_mse: 1259.2579 - val_mae: 0.3579\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2212 - mse: 495.4746 - mae: 0.2212 - val_loss: 0.3583 - val_mse: 1259.2559 - val_mae: 0.3583\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5490 - mse: 25050365952.0000 - mae: 290.5489 - val_loss: 0.3581 - val_mse: 1259.2578 - val_mae: 0.3581\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2382 - mse: 496.6072 - mae: 0.2382 - val_loss: 0.3580 - val_mse: 1259.2592 - val_mae: 0.3580\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6341 - mse: 40080580608.0000 - mae: 580.6326 - val_loss: 0.3581 - val_mse: 1259.2595 - val_mae: 0.3581\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5476 - mse: 25050365952.0000 - mae: 290.5476 - val_loss: 0.3583 - val_mse: 1259.2599 - val_mae: 0.3583\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2752 - mse: 656.0781 - mae: 0.2752 - val_loss: 0.3579 - val_mse: 1259.2576 - val_mae: 0.3579\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3149 - mse: 860.6842 - mae: 0.3149 - val_loss: 0.3581 - val_mse: 1259.2650 - val_mae: 0.3581\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1753 - mse: 30060435456.0000 - mae: 387.1753 - val_loss: 0.3581 - val_mse: 1259.2593 - val_mae: 0.3581\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9429 - mse: 35070509056.0000 - mae: 483.9409 - val_loss: 0.3583 - val_mse: 1259.2567 - val_mae: 0.3583\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2675 - mse: 616.0552 - mae: 0.2675 - val_loss: 0.3583 - val_mse: 1259.2604 - val_mae: 0.3583\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3397 - mse: 894.0468 - mae: 0.3397 - val_loss: 0.3582 - val_mse: 1259.2593 - val_mae: 0.3582\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4940 - mse: 25050365952.0000 - mae: 290.4941 - val_loss: 0.3582 - val_mse: 1259.2614 - val_mae: 0.3582\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3456 - mse: 25050365952.0000 - mae: 290.3455 - val_loss: 0.3584 - val_mse: 1259.2566 - val_mae: 0.3584\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4739 - mse: 1607.8235 - mae: 0.4739 - val_loss: 0.3584 - val_mse: 1259.2584 - val_mae: 0.3584\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4088 - mse: 25050363904.0000 - mae: 290.4088 - val_loss: 0.3642 - val_mse: 1259.2992 - val_mae: 0.3642\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4344 - mse: 1186.6172 - mae: 0.4344 - val_loss: 0.3611 - val_mse: 1259.2616 - val_mae: 0.3611\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8095 - mse: 20040292352.0000 - mae: 193.8096 - val_loss: 0.3606 - val_mse: 1259.2601 - val_mae: 0.3606\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2703 - mse: 546.1947 - mae: 0.2703 - val_loss: 0.3601 - val_mse: 1259.2650 - val_mae: 0.3601\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1298 - mse: 30060439552.0000 - mae: 387.1300 - val_loss: 0.3599 - val_mse: 1259.2635 - val_mae: 0.3599\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4121 - mse: 1147.2408 - mae: 0.4121 - val_loss: 0.3597 - val_mse: 1259.2643 - val_mae: 0.3597\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3857 - mse: 1102.0544 - mae: 0.3857 - val_loss: 0.3597 - val_mse: 1259.2815 - val_mae: 0.3597\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4568 - mse: 25050365952.0000 - mae: 290.4569 - val_loss: 0.3593 - val_mse: 1259.2603 - val_mae: 0.3593\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7108 - mse: 20040290304.0000 - mae: 193.7109 - val_loss: 0.3591 - val_mse: 1259.2633 - val_mae: 0.3591\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4126 - mse: 1041.9021 - mae: 0.4126 - val_loss: 0.3591 - val_mse: 1259.2614 - val_mae: 0.3591\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4320 - mse: 1368.0548 - mae: 0.4320 - val_loss: 0.3589 - val_mse: 1259.2601 - val_mae: 0.3589\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4207 - mse: 25050363904.0000 - mae: 290.4206 - val_loss: 0.3588 - val_mse: 1259.2637 - val_mae: 0.3588\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4230 - mse: 1281.8828 - mae: 0.4230 - val_loss: 0.3587 - val_mse: 1259.2612 - val_mae: 0.3587\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8523 - mse: 35070509056.0000 - mae: 483.8527 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4096 - mse: 1204.0835 - mae: 0.4096 - val_loss: 0.3585 - val_mse: 1259.2627 - val_mae: 0.3585\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7115 - mse: 20040290304.0000 - mae: 193.7116 - val_loss: 0.3583 - val_mse: 1259.2607 - val_mae: 0.3583\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 580.6328 - mse: 40080580608.0000 - mae: 580.6334 - val_loss: 0.3583 - val_mse: 1259.2604 - val_mae: 0.3583\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3091 - mse: 877.3297 - mae: 0.3091 - val_loss: 0.3582 - val_mse: 1259.2622 - val_mae: 0.3582\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.4062 - mse: 1198.3956 - mae: 0.4062 - val_loss: 0.3581 - val_mse: 1259.2631 - val_mae: 0.3581\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8115 - mse: 35070509056.0000 - mae: 483.8110 - val_loss: 0.3582 - val_mse: 1259.3202 - val_mae: 0.3582\n",
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3250 - mse: 831.8888 - mae: 0.3250 - val_loss: 0.3579 - val_mse: 1259.2625 - val_mae: 0.3579\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1880 - mse: 30060435456.0000 - mae: 387.1881 - val_loss: 0.3578 - val_mse: 1259.2588 - val_mae: 0.3578\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3053 - mse: 763.8992 - mae: 0.3053 - val_loss: 0.3577 - val_mse: 1259.2631 - val_mae: 0.3577\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8612 - mse: 20040290304.0000 - mae: 193.8613 - val_loss: 0.3578 - val_mse: 1259.2610 - val_mae: 0.3578\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 870.6502 - mse: 55110803456.0000 - mae: 870.6456 - val_loss: 0.3576 - val_mse: 1259.2625 - val_mae: 0.3576\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4586 - mse: 1504.8251 - mae: 0.4586 - val_loss: 0.3575 - val_mse: 1259.2611 - val_mae: 0.3575\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2878 - mse: 669.0697 - mae: 0.2878 - val_loss: 0.3575 - val_mse: 1259.2622 - val_mae: 0.3575\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9219 - mse: 35070509056.0000 - mae: 483.9218 - val_loss: 0.3574 - val_mse: 1259.2584 - val_mae: 0.3574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3478 - mse: 933.9170 - mae: 0.3478 - val_loss: 0.3574 - val_mse: 1259.2589 - val_mae: 0.3574\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1939 - mse: 30060435456.0000 - mae: 387.1940 - val_loss: 0.3573 - val_mse: 1259.2622 - val_mae: 0.3573\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4497 - mse: 1330.6555 - mae: 0.4497 - val_loss: 0.3573 - val_mse: 1259.2610 - val_mae: 0.3573\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3917 - mse: 25050365952.0000 - mae: 290.3917 - val_loss: 0.3571 - val_mse: 1259.2612 - val_mae: 0.3571\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3988 - mse: 1190.4705 - mae: 0.3988 - val_loss: 0.3571 - val_mse: 1259.2617 - val_mae: 0.3571\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4175 - mse: 25050365952.0000 - mae: 290.4175 - val_loss: 0.3571 - val_mse: 1259.2616 - val_mae: 0.3571\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4489 - mse: 25050363904.0000 - mae: 290.4490 - val_loss: 0.3570 - val_mse: 1259.2617 - val_mae: 0.3570\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3379 - mse: 816.1879 - mae: 0.3379 - val_loss: 0.3570 - val_mse: 1259.2599 - val_mae: 0.3570\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3312 - mse: 855.6207 - mae: 0.3312 - val_loss: 0.3570 - val_mse: 1259.2616 - val_mae: 0.3571\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7218 - mse: 20040292352.0000 - mae: 193.7217 - val_loss: 0.3570 - val_mse: 1259.2557 - val_mae: 0.3570\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3707 - mse: 993.6994 - mae: 0.3707 - val_loss: 0.3570 - val_mse: 1259.2604 - val_mae: 0.3570\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9062 - mse: 35070509056.0000 - mae: 483.9057 - val_loss: 0.3569 - val_mse: 1259.2587 - val_mae: 0.3569\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5446 - mse: 25050365952.0000 - mae: 290.5445 - val_loss: 0.3569 - val_mse: 1259.2603 - val_mae: 0.3569\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2666 - mse: 552.8773 - mae: 0.2666 - val_loss: 0.3569 - val_mse: 1259.2605 - val_mae: 0.3569\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3044 - mse: 757.5050 - mae: 0.3044 - val_loss: 0.3569 - val_mse: 1259.2593 - val_mae: 0.3569\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2279 - mse: 30060439552.0000 - mae: 387.2279 - val_loss: 0.3568 - val_mse: 1259.2607 - val_mae: 0.3568\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4289 - mse: 1171.6672 - mae: 0.4289 - val_loss: 0.3569 - val_mse: 1259.2607 - val_mae: 0.3569\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8123 - mse: 35070513152.0000 - mae: 483.8111 - val_loss: 0.3568 - val_mse: 1259.2622 - val_mae: 0.3568\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5048 - mse: 40080580608.0000 - mae: 580.5046 - val_loss: 0.3569 - val_mse: 1259.2607 - val_mae: 0.3569\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4200 - mse: 1344.7623 - mae: 0.4200 - val_loss: 0.3568 - val_mse: 1259.2637 - val_mae: 0.3568\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5166 - mse: 40080580608.0000 - mae: 580.5157 - val_loss: 0.3570 - val_mse: 1259.2693 - val_mae: 0.3570\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3724 - mse: 1216.9497 - mae: 0.3724 - val_loss: 0.3568 - val_mse: 1259.2605 - val_mae: 0.3568\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5256 - mse: 25050365952.0000 - mae: 290.5257 - val_loss: 0.3569 - val_mse: 1259.2572 - val_mae: 0.3569\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3400 - mse: 1046.3796 - mae: 0.3400 - val_loss: 0.3568 - val_mse: 1259.2607 - val_mae: 0.3568\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3005 - mse: 649.7211 - mae: 0.3005 - val_loss: 0.3569 - val_mse: 1259.2604 - val_mae: 0.3569\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2534 - mse: 30060435456.0000 - mae: 387.2536 - val_loss: 0.3569 - val_mse: 1259.2616 - val_mae: 0.3569\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3837 - mse: 1004.3391 - mae: 0.3837 - val_loss: 0.3570 - val_mse: 1259.2610 - val_mae: 0.3570\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8456 - mse: 35070509056.0000 - mae: 483.8456 - val_loss: 0.3568 - val_mse: 1259.2605 - val_mae: 0.3568\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4738 - mse: 25050363904.0000 - mae: 290.4740 - val_loss: 0.3570 - val_mse: 1259.2607 - val_mae: 0.3570\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2990 - mse: 763.0912 - mae: 0.2990 - val_loss: 0.3570 - val_mse: 1259.2617 - val_mae: 0.3570\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7013 - mse: 20040290304.0000 - mae: 193.7013 - val_loss: 0.3570 - val_mse: 1259.2616 - val_mae: 0.3570\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3628 - mse: 1127.6865 - mae: 0.3628 - val_loss: 0.3570 - val_mse: 1259.2622 - val_mae: 0.3570\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.4992 - mse: 25050363904.0000 - mae: 290.4992 - val_loss: 0.3571 - val_mse: 1259.2642 - val_mae: 0.3571\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2650 - mse: 685.2375 - mae: 0.2650 - val_loss: 0.3571 - val_mse: 1259.2629 - val_mae: 0.3571\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3487 - mse: 982.5738 - mae: 0.3487 - val_loss: 0.3572 - val_mse: 1259.2628 - val_mae: 0.3572\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4966 - mse: 25050363904.0000 - mae: 290.4966 - val_loss: 0.3571 - val_mse: 1259.2623 - val_mae: 0.3571\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5146 - mse: 40080580608.0000 - mae: 580.5147 - val_loss: 0.3573 - val_mse: 1259.2622 - val_mae: 0.3573\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3989 - mse: 1138.6816 - mae: 0.3989 - val_loss: 0.3571 - val_mse: 1259.2601 - val_mae: 0.3571\n",
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4676 - mse: 1499.0293 - mae: 0.4676 - val_loss: 0.3573 - val_mse: 1259.2603 - val_mae: 0.3573\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0997 - mse: 30060435456.0000 - mae: 387.0998 - val_loss: 0.3573 - val_mse: 1259.2603 - val_mae: 0.3573\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1838 - mse: 30060435456.0000 - mae: 387.1839 - val_loss: 0.3572 - val_mse: 1259.2609 - val_mae: 0.3572\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3074 - mse: 818.7042 - mae: 0.3074 - val_loss: 0.3570 - val_mse: 1259.2634 - val_mae: 0.3570\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2783 - mse: 668.8563 - mae: 0.2783 - val_loss: 0.3573 - val_mse: 1259.2607 - val_mae: 0.3573\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8189 - mse: 20040292352.0000 - mae: 193.8188 - val_loss: 0.3571 - val_mse: 1259.2618 - val_mae: 0.3571\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1277 - mse: 30060435456.0000 - mae: 387.1277 - val_loss: 0.3573 - val_mse: 1259.2622 - val_mae: 0.3573\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3667 - mse: 1095.6942 - mae: 0.3667 - val_loss: 0.3574 - val_mse: 1259.2629 - val_mae: 0.3574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4037 - mse: 1114.8236 - mae: 0.4037 - val_loss: 0.3574 - val_mse: 1259.2634 - val_mae: 0.3574\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1242 - mse: 30060435456.0000 - mae: 387.1241 - val_loss: 0.3573 - val_mse: 1259.2638 - val_mae: 0.3573\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3285 - mse: 880.7808 - mae: 0.3285 - val_loss: 0.3574 - val_mse: 1259.2628 - val_mae: 0.3574\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1882 - mse: 30060435456.0000 - mae: 387.1881 - val_loss: 0.3574 - val_mse: 1259.2633 - val_mae: 0.3574\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8457 - mse: 35070513152.0000 - mae: 483.8449 - val_loss: 0.3575 - val_mse: 1259.2610 - val_mae: 0.3575\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3482 - mse: 1012.1062 - mae: 0.3482 - val_loss: 0.3576 - val_mse: 1259.2614 - val_mae: 0.3576\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2482 - mse: 30060435456.0000 - mae: 387.2482 - val_loss: 0.3576 - val_mse: 1259.2618 - val_mae: 0.3576\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2415 - mse: 494.7296 - mae: 0.2415 - val_loss: 0.3575 - val_mse: 1259.2639 - val_mae: 0.3575\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3142 - mse: 760.1919 - mae: 0.3142 - val_loss: 0.3577 - val_mse: 1259.2629 - val_mae: 0.3577\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3043 - mse: 45090652160.0000 - mae: 677.3033 - val_loss: 0.3575 - val_mse: 1259.2620 - val_mae: 0.3575\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3966 - mse: 1157.5146 - mae: 0.3966 - val_loss: 0.3577 - val_mse: 1259.2620 - val_mae: 0.3577\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1588 - mse: 30060435456.0000 - mae: 387.1588 - val_loss: 0.3577 - val_mse: 1259.2559 - val_mae: 0.3577\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9463 - mse: 35070509056.0000 - mae: 483.9456 - val_loss: 0.3577 - val_mse: 1259.2631 - val_mae: 0.3577\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2162 - mse: 483.7003 - mae: 0.2162 - val_loss: 0.3574 - val_mse: 1259.2650 - val_mae: 0.3574\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3271 - mse: 977.6688 - mae: 0.3271 - val_loss: 0.3579 - val_mse: 1259.2633 - val_mae: 0.3579\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1589 - mse: 30060439552.0000 - mae: 387.1588 - val_loss: 0.3575 - val_mse: 1259.2631 - val_mae: 0.3575\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2969 - mse: 677.5928 - mae: 0.2969 - val_loss: 0.3579 - val_mse: 1259.2655 - val_mae: 0.3579\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5271 - mse: 25050363904.0000 - mae: 290.5270 - val_loss: 0.3576 - val_mse: 1259.2599 - val_mae: 0.3576\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1206 - mse: 30060435456.0000 - mae: 387.1205 - val_loss: 0.3579 - val_mse: 1259.2633 - val_mae: 0.3579\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3652 - mse: 1123.3082 - mae: 0.3652 - val_loss: 0.3578 - val_mse: 1259.2662 - val_mae: 0.3578\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3532 - mse: 1000.2778 - mae: 0.3532 - val_loss: 0.3579 - val_mse: 1259.2623 - val_mae: 0.3579\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4293 - mse: 25050365952.0000 - mae: 290.4296 - val_loss: 0.3578 - val_mse: 1259.2646 - val_mae: 0.3578\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2708 - mse: 45090652160.0000 - mae: 677.2686 - val_loss: 0.3579 - val_mse: 1259.2646 - val_mae: 0.3579\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3217 - mse: 815.2491 - mae: 0.3217 - val_loss: 0.3578 - val_mse: 1259.2638 - val_mae: 0.3578\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3152 - mse: 962.0842 - mae: 0.3152 - val_loss: 0.3580 - val_mse: 1259.2639 - val_mae: 0.3580\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4819 - mse: 25050363904.0000 - mae: 290.4821 - val_loss: 0.3580 - val_mse: 1259.2644 - val_mae: 0.3580\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/105\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4510 - mse: 1268.7078 - mae: 0.4510 - val_loss: 0.3630 - val_mse: 1259.2838 - val_mae: 0.3630\n",
      "Epoch 2/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8176 - mse: 35070509056.0000 - mae: 483.8175 - val_loss: 0.3615 - val_mse: 1259.2650 - val_mae: 0.3615\n",
      "Epoch 3/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8376 - mse: 35070509056.0000 - mae: 483.8387 - val_loss: 0.3608 - val_mse: 1259.2631 - val_mae: 0.3608\n",
      "Epoch 4/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4146 - mse: 1198.4200 - mae: 0.4146 - val_loss: 0.3604 - val_mse: 1259.2631 - val_mae: 0.3604\n",
      "Epoch 5/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6943 - mse: 20040290304.0000 - mae: 193.6943 - val_loss: 0.3601 - val_mse: 1259.2637 - val_mae: 0.3601\n",
      "Epoch 6/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3792 - mse: 1133.4738 - mae: 0.3792 - val_loss: 0.3598 - val_mse: 1259.2646 - val_mae: 0.3598\n",
      "Epoch 7/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2689 - mse: 534.0212 - mae: 0.2689 - val_loss: 0.3596 - val_mse: 1259.2629 - val_mae: 0.3596\n",
      "Epoch 8/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5356 - mse: 25050365952.0000 - mae: 290.5357 - val_loss: 0.3594 - val_mse: 1259.2648 - val_mae: 0.3594\n",
      "Epoch 9/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3762 - mse: 1029.3888 - mae: 0.3762 - val_loss: 0.3593 - val_mse: 1259.2632 - val_mae: 0.3593\n",
      "Epoch 10/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7601 - mse: 20040290304.0000 - mae: 193.7601 - val_loss: 0.3591 - val_mse: 1259.2645 - val_mae: 0.3591\n",
      "Epoch 11/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 290.4033 - mse: 25050365952.0000 - mae: 290.4032 - val_loss: 0.3590 - val_mse: 1259.2661 - val_mae: 0.3590\n",
      "Epoch 12/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3784 - mse: 954.0806 - mae: 0.3784 - val_loss: 0.3589 - val_mse: 1259.2605 - val_mae: 0.3589\n",
      "Epoch 13/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.1320 - mse: 30060435456.0000 - mae: 387.1320 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Epoch 14/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3771 - mse: 1284.8219 - mae: 0.3771 - val_loss: 0.3587 - val_mse: 1259.2627 - val_mae: 0.3587\n",
      "Epoch 15/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1624 - mse: 30060435456.0000 - mae: 387.1624 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 16/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3508 - mse: 955.7097 - mae: 0.3508 - val_loss: 0.3584 - val_mse: 1259.2635 - val_mae: 0.3584\n",
      "Epoch 17/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8311 - mse: 20040290304.0000 - mae: 193.8312 - val_loss: 0.3584 - val_mse: 1259.2605 - val_mae: 0.3584\n",
      "Epoch 18/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2884 - mse: 732.5942 - mae: 0.2884 - val_loss: 0.3583 - val_mse: 1259.2612 - val_mae: 0.3583\n",
      "Epoch 19/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4065 - mse: 25050363904.0000 - mae: 290.4065 - val_loss: 0.3581 - val_mse: 1259.2648 - val_mae: 0.3581\n",
      "Epoch 20/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3821 - mse: 1207.1345 - mae: 0.3821 - val_loss: 0.3581 - val_mse: 1259.2611 - val_mae: 0.3581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1968 - mse: 30060439552.0000 - mae: 387.1967 - val_loss: 0.3580 - val_mse: 1259.2598 - val_mae: 0.3580\n",
      "Epoch 22/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4015 - mse: 1115.6072 - mae: 0.4015 - val_loss: 0.3579 - val_mse: 1259.2668 - val_mae: 0.3579\n",
      "Epoch 23/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8736 - mse: 35070509056.0000 - mae: 483.8737 - val_loss: 0.3579 - val_mse: 1259.2618 - val_mae: 0.3579\n",
      "Epoch 24/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3505 - mse: 1078.0521 - mae: 0.3505 - val_loss: 0.3577 - val_mse: 1259.2638 - val_mae: 0.3577\n",
      "Epoch 25/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1478 - mse: 30060435456.0000 - mae: 387.1477 - val_loss: 0.3577 - val_mse: 1259.2598 - val_mae: 0.3577\n",
      "Epoch 26/105\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3472 - mse: 823.9562 - mae: 0.3472 - val_loss: 0.3576 - val_mse: 1259.2603 - val_mae: 0.3576\n",
      "Epoch 27/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.1247 - mse: 50100727808.0000 - mae: 774.1245 - val_loss: 0.3576 - val_mse: 1259.2607 - val_mae: 0.3576\n",
      "Epoch 28/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2524 - mse: 386.5208 - mae: 0.2524 - val_loss: 0.3575 - val_mse: 1259.2621 - val_mae: 0.3575\n",
      "Epoch 29/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4330 - mse: 1260.2739 - mae: 0.4330 - val_loss: 0.3575 - val_mse: 1259.2603 - val_mae: 0.3575\n",
      "Epoch 30/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6957 - mse: 20040292352.0000 - mae: 193.6957 - val_loss: 0.3574 - val_mse: 1259.2593 - val_mae: 0.3574\n",
      "Epoch 31/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4378 - mse: 1392.1361 - mae: 0.4378 - val_loss: 0.3575 - val_mse: 1259.2590 - val_mae: 0.3575\n",
      "Epoch 32/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1460 - mse: 30060435456.0000 - mae: 387.1460 - val_loss: 0.3573 - val_mse: 1259.2642 - val_mae: 0.3573\n",
      "Epoch 33/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4524 - mse: 25050365952.0000 - mae: 290.4524 - val_loss: 0.3573 - val_mse: 1259.2617 - val_mae: 0.3573\n",
      "Epoch 34/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3837 - mse: 1121.2596 - mae: 0.3837 - val_loss: 0.3572 - val_mse: 1259.2621 - val_mae: 0.3572\n",
      "Epoch 35/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3897 - mse: 1226.8148 - mae: 0.3897 - val_loss: 0.3572 - val_mse: 1259.2626 - val_mae: 0.3572\n",
      "Epoch 36/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8017 - mse: 35070509056.0000 - mae: 483.8014 - val_loss: 0.3571 - val_mse: 1259.2582 - val_mae: 0.3571\n",
      "Epoch 37/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3677 - mse: 1110.9222 - mae: 0.3677 - val_loss: 0.3572 - val_mse: 1259.2628 - val_mae: 0.3572\n",
      "Epoch 38/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9736 - mse: 50100727808.0000 - mae: 773.9728 - val_loss: 0.3569 - val_mse: 1259.2582 - val_mae: 0.3569\n",
      "Epoch 39/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8560 - mse: 35070509056.0000 - mae: 483.8558 - val_loss: 0.3571 - val_mse: 1259.2631 - val_mae: 0.3571\n",
      "Epoch 40/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3352 - mse: 940.7953 - mae: 0.3352 - val_loss: 0.3570 - val_mse: 1259.2625 - val_mae: 0.3570\n",
      "Epoch 41/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5451 - mse: 25050363904.0000 - mae: 290.5452 - val_loss: 0.3569 - val_mse: 1259.2625 - val_mae: 0.3569\n",
      "Epoch 42/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2448 - mse: 501.8647 - mae: 0.2448 - val_loss: 0.3568 - val_mse: 1259.2605 - val_mae: 0.3568\n",
      "Epoch 43/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4555 - mse: 1415.1660 - mae: 0.4555 - val_loss: 0.3569 - val_mse: 1259.2574 - val_mae: 0.3569\n",
      "Epoch 44/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3927 - mse: 25050365952.0000 - mae: 290.3927 - val_loss: 0.3568 - val_mse: 1259.2635 - val_mae: 0.3568\n",
      "Epoch 45/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1839 - mse: 30060435456.0000 - mae: 387.1840 - val_loss: 0.3569 - val_mse: 1259.2616 - val_mae: 0.3569\n",
      "Epoch 46/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3607 - mse: 959.9208 - mae: 0.3607 - val_loss: 0.3568 - val_mse: 1259.2598 - val_mae: 0.3568\n",
      "Epoch 47/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4217 - mse: 25050363904.0000 - mae: 290.4215 - val_loss: 0.3569 - val_mse: 1259.2623 - val_mae: 0.3569\n",
      "Epoch 48/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3872 - mse: 1234.5183 - mae: 0.3872 - val_loss: 0.3567 - val_mse: 1259.2577 - val_mae: 0.3567\n",
      "Epoch 49/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1639 - mse: 30060435456.0000 - mae: 387.1639 - val_loss: 0.3570 - val_mse: 1259.2626 - val_mae: 0.3570\n",
      "Epoch 50/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3324 - mse: 858.5831 - mae: 0.3324 - val_loss: 0.3568 - val_mse: 1259.2607 - val_mae: 0.3568\n",
      "Epoch 51/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5049 - mse: 25050363904.0000 - mae: 290.5052 - val_loss: 0.3570 - val_mse: 1259.2625 - val_mae: 0.3570\n",
      "Epoch 52/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3644 - mse: 884.3140 - mae: 0.3644 - val_loss: 0.3568 - val_mse: 1259.2616 - val_mae: 0.3568\n",
      "Epoch 53/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8710 - mse: 35070509056.0000 - mae: 483.8707 - val_loss: 0.3569 - val_mse: 1259.2631 - val_mae: 0.3569\n",
      "Epoch 54/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3816 - mse: 1059.1372 - mae: 0.3816 - val_loss: 0.3569 - val_mse: 1259.2622 - val_mae: 0.3569\n",
      "Epoch 55/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3364 - mse: 1059.7275 - mae: 0.3364 - val_loss: 0.3570 - val_mse: 1259.2646 - val_mae: 0.3570\n",
      "Epoch 56/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5663 - mse: 40080580608.0000 - mae: 580.5656 - val_loss: 0.3568 - val_mse: 1259.2590 - val_mae: 0.3568\n",
      "Epoch 57/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3113 - mse: 807.1232 - mae: 0.3113 - val_loss: 0.3569 - val_mse: 1259.2605 - val_mae: 0.3569\n",
      "Epoch 58/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7897 - mse: 20040292352.0000 - mae: 193.7898 - val_loss: 0.3570 - val_mse: 1259.2612 - val_mae: 0.3570\n",
      "Epoch 59/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3843 - mse: 1276.4644 - mae: 0.3843 - val_loss: 0.3570 - val_mse: 1259.2604 - val_mae: 0.3570\n",
      "Epoch 60/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3935 - mse: 25050363904.0000 - mae: 290.3938 - val_loss: 0.3568 - val_mse: 1259.2616 - val_mae: 0.3568\n",
      "Epoch 61/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3886 - mse: 1109.5759 - mae: 0.3886 - val_loss: 0.3570 - val_mse: 1259.2618 - val_mae: 0.3570\n",
      "Epoch 62/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4233 - mse: 25050363904.0000 - mae: 290.4231 - val_loss: 0.3569 - val_mse: 1259.2635 - val_mae: 0.3569\n",
      "Epoch 63/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8703 - mse: 35070509056.0000 - mae: 483.8685 - val_loss: 0.3571 - val_mse: 1259.2653 - val_mae: 0.3571\n",
      "Epoch 64/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3411 - mse: 1026.0004 - mae: 0.3411 - val_loss: 0.3569 - val_mse: 1259.2617 - val_mae: 0.3569\n",
      "Epoch 65/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5267 - mse: 25050363904.0000 - mae: 290.5267 - val_loss: 0.3570 - val_mse: 1259.2618 - val_mae: 0.3570\n",
      "Epoch 66/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3086 - mse: 860.3986 - mae: 0.3086 - val_loss: 0.3568 - val_mse: 1259.2627 - val_mae: 0.3568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6039 - mse: 40080580608.0000 - mae: 580.6030 - val_loss: 0.3570 - val_mse: 1259.2607 - val_mae: 0.3570\n",
      "Epoch 68/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3702 - mse: 1069.7572 - mae: 0.3702 - val_loss: 0.3571 - val_mse: 1259.2634 - val_mae: 0.3571\n",
      "Epoch 69/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2897 - mse: 621.3619 - mae: 0.2897 - val_loss: 0.3573 - val_mse: 1259.2607 - val_mae: 0.3573\n",
      "Epoch 70/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9521 - mse: 35070509056.0000 - mae: 483.9503 - val_loss: 0.3573 - val_mse: 1259.2625 - val_mae: 0.3573\n",
      "Epoch 71/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4371 - mse: 1431.5875 - mae: 0.4371 - val_loss: 0.3574 - val_mse: 1259.2640 - val_mae: 0.3574\n",
      "Epoch 72/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8098 - mse: 35070509056.0000 - mae: 483.8094 - val_loss: 0.3571 - val_mse: 1259.2646 - val_mae: 0.3571\n",
      "Epoch 73/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3417 - mse: 864.8735 - mae: 0.3417 - val_loss: 0.3572 - val_mse: 1259.2618 - val_mae: 0.3572\n",
      "Epoch 74/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4599 - mse: 25050363904.0000 - mae: 290.4603 - val_loss: 0.3573 - val_mse: 1259.2625 - val_mae: 0.3573\n",
      "Epoch 75/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6958 - mse: 20040292352.0000 - mae: 193.6960 - val_loss: 0.3574 - val_mse: 1259.2626 - val_mae: 0.3574\n",
      "Epoch 76/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3995 - mse: 1172.4426 - mae: 0.3995 - val_loss: 0.3573 - val_mse: 1259.2609 - val_mae: 0.3573\n",
      "Epoch 77/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3282 - mse: 854.9747 - mae: 0.3282 - val_loss: 0.3575 - val_mse: 1259.2642 - val_mae: 0.3575\n",
      "Epoch 78/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2280 - mse: 30060435456.0000 - mae: 387.2277 - val_loss: 0.3572 - val_mse: 1259.2642 - val_mae: 0.3572\n",
      "Epoch 79/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3453 - mse: 959.6242 - mae: 0.3453 - val_loss: 0.3575 - val_mse: 1259.2610 - val_mae: 0.3575\n",
      "Epoch 80/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7599 - mse: 20040292352.0000 - mae: 193.7600 - val_loss: 0.3574 - val_mse: 1259.2639 - val_mae: 0.3574\n",
      "Epoch 81/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3991 - mse: 1161.2277 - mae: 0.3991 - val_loss: 0.3575 - val_mse: 1259.2635 - val_mae: 0.3575\n",
      "Epoch 82/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1889 - mse: 30060435456.0000 - mae: 387.1889 - val_loss: 0.3575 - val_mse: 1259.2635 - val_mae: 0.3575\n",
      "Epoch 83/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4746 - mse: 25050363904.0000 - mae: 290.4746 - val_loss: 0.3576 - val_mse: 1259.2633 - val_mae: 0.3576\n",
      "Epoch 84/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3333 - mse: 882.6013 - mae: 0.3333 - val_loss: 0.3575 - val_mse: 1259.2617 - val_mae: 0.3575\n",
      "Epoch 85/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3282 - mse: 901.7252 - mae: 0.3282 - val_loss: 0.3577 - val_mse: 1259.2625 - val_mae: 0.3577\n",
      "Epoch 86/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9668 - mse: 35070509056.0000 - mae: 483.9643 - val_loss: 0.3574 - val_mse: 1259.2584 - val_mae: 0.3574\n",
      "Epoch 87/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3478 - mse: 970.9553 - mae: 0.3478 - val_loss: 0.3576 - val_mse: 1259.2633 - val_mae: 0.3576\n",
      "Epoch 88/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4638 - mse: 25050363904.0000 - mae: 290.4635 - val_loss: 0.3576 - val_mse: 1259.2611 - val_mae: 0.3576\n",
      "Epoch 89/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1721 - mse: 30060435456.0000 - mae: 387.1719 - val_loss: 0.3577 - val_mse: 1259.2627 - val_mae: 0.3577\n",
      "Epoch 90/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3982 - mse: 1237.1389 - mae: 0.3982 - val_loss: 0.3577 - val_mse: 1259.2616 - val_mae: 0.3577\n",
      "Epoch 91/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7763 - mse: 20040290304.0000 - mae: 193.7764 - val_loss: 0.3577 - val_mse: 1259.2643 - val_mae: 0.3577\n",
      "Epoch 92/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2831 - mse: 714.4460 - mae: 0.2831 - val_loss: 0.3578 - val_mse: 1259.2642 - val_mae: 0.3578\n",
      "Epoch 93/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2662 - mse: 647.0129 - mae: 0.2662 - val_loss: 0.3578 - val_mse: 1259.2598 - val_mae: 0.3578\n",
      "Epoch 94/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5102 - mse: 25050365952.0000 - mae: 290.5101 - val_loss: 0.3578 - val_mse: 1259.2654 - val_mae: 0.3578\n",
      "Epoch 95/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8840 - mse: 35070509056.0000 - mae: 483.8832 - val_loss: 0.3579 - val_mse: 1259.2605 - val_mae: 0.3579\n",
      "Epoch 96/105\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3437 - mse: 1035.0896 - mae: 0.3437 - val_loss: 0.3580 - val_mse: 1259.2610 - val_mae: 0.3580\n",
      "Epoch 97/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3449 - mse: 968.9626 - mae: 0.3449 - val_loss: 0.3581 - val_mse: 1259.2635 - val_mae: 0.3581\n",
      "Epoch 98/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2858 - mse: 45090652160.0000 - mae: 677.2848 - val_loss: 0.3579 - val_mse: 1259.2615 - val_mae: 0.3579\n",
      "Epoch 99/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7951 - mse: 35070513152.0000 - mae: 483.7927 - val_loss: 0.3579 - val_mse: 1259.2618 - val_mae: 0.3579\n",
      "Epoch 100/105\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4063 - mse: 1333.1285 - mae: 0.4063 - val_loss: 0.3581 - val_mse: 1259.2640 - val_mae: 0.3581\n"
     ]
    }
   ],
   "source": [
    "snap_dirs = ['/tmp/snapshot/snap_fixed_{}/'.format(i) for i in range(10)]\n",
    "\n",
    "for snap_dir in snap_dirs:\n",
    "    run_snapshot(snap_dir, num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/snapshot/snap_fixed_0/',\n",
       " '/tmp/snapshot/snap_fixed_1/',\n",
       " '/tmp/snapshot/snap_fixed_2/',\n",
       " '/tmp/snapshot/snap_fixed_3/',\n",
       " '/tmp/snapshot/snap_fixed_4/',\n",
       " '/tmp/snapshot/snap_fixed_5/',\n",
       " '/tmp/snapshot/snap_fixed_6/',\n",
       " '/tmp/snapshot/snap_fixed_7/',\n",
       " '/tmp/snapshot/snap_fixed_8/',\n",
       " '/tmp/snapshot/snap_fixed_9/']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:29<00:00,  1.11it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_snap_f = []\n",
    "for d in snap_dirs:\n",
    "    dirs = [d + '__{}/best_weights.h5'.format(i) for i in range(100)]\n",
    "    preds_snap_f.append(ensemble_preds(dirs, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_snap = [[evaluate_single(p, y_test) for p in preds] for preds in preds_snap_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s in single_snap:\n",
    "    plt.plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 23000, 14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_snap_f[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    add_snap = [evaluate_ensemble(preds_snap_f[i][:e+1], y_test) for e in range(100)]\n",
    "    \n",
    "    results_f.append(add_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8392c8d30>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for r in results_f:\n",
    "    plt.plot(r)\n",
    "\n",
    "plt.plot([10, 10], [13, 13.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc849005390>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([np.mean(r) for r in zip(*results_f)])\n",
    "plt.plot([np.median(r) for r in zip(*results_f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([np.mean(r) + np.median(r) for r in zip(*results_f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape(ind):\n",
    "    a = np.array(preds_snap_f)[ind, :15, ...]\n",
    "    return a.reshape((-1, a.shape[-2], a.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = np.random.permutation(10)\n",
    "i2 = np.random.permutation(10)\n",
    "i3 = np.random.permutation(10)\n",
    "i4 = np.random.permutation(10)\n",
    "i5 = np.random.permutation(10)\n",
    "\n",
    "results_f_cold_ensembles_1 = []\n",
    "results_f_cold_ensembles_2 = []\n",
    "results_f_cold_ensembles_3 = []\n",
    "results_f_cold_ensembles_4 = []\n",
    "results_f_cold_ensembles_5 = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "\n",
    "    results_f_cold_ensembles_1.append(evaluate_ensemble(change_shape(i1[:i]), y_test))\n",
    "    results_f_cold_ensembles_2.append(evaluate_ensemble(change_shape(i2[:i]), y_test))\n",
    "    results_f_cold_ensembles_3.append(evaluate_ensemble(change_shape(i3[:i]), y_test))\n",
    "    results_f_cold_ensembles_4.append(evaluate_ensemble(change_shape(i4[:i]), y_test))\n",
    "    results_f_cold_ensembles_5.append(evaluate_ensemble(change_shape(i5[:i]), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8741d0358>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results_f_cold_ensembles_1)\n",
    "plt.plot(results_f_cold_ensembles_2)\n",
    "plt.plot(results_f_cold_ensembles_3)s\n",
    "plt.plot(results_f_cold_ensembles_4)\n",
    "plt.plot(results_f_cold_ensembles_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc875ddd940>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = [results_f_cold_ensembles_1,\n",
    "       results_f_cold_ensembles_2,\n",
    "       results_f_cold_ensembles_3,\n",
    "       results_f_cold_ensembles_4,\n",
    "       results_f_cold_ensembles_5]\n",
    "\n",
    "plt.plot([np.mean(r) for r in zip(*tmp)])\n",
    "plt.plot([np.median(r) for r in zip(*tmp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '../utils/__init__.py'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snapshot(snap_dir='/tmp/snapshot/snap/', s=20, num=15, cold_rr=4):\n",
    "    \n",
    "    for run in range(cold_rr):\n",
    "    \n",
    "        for i in range(num):\n",
    "\n",
    "            run_dir = snap_dir + '__' + str(i)\n",
    "\n",
    "            if not os.path.isdir(run_dir):\n",
    "                os.makedirs(run_dir)\n",
    "\n",
    "            model = networks.convolutional_ae_4_layer(hparams, ['mse', 'mae'])\n",
    "\n",
    "        callbacks = [utils.callbacks.SnapshotWithAveraging(snap_dir, len(train_set)//batch_size+1, n_cycles=num,\n",
    "                                                           steps_to_average=s, max_epochs=num+5, cold_start_id=run)]\n",
    "\n",
    "        model.fit(train_set, epochs=num+5, steps_per_epoch=len(train_set)//batch_size+1,\n",
    "              validation_steps=len(test_set)//batch_size+1, validation_data=test_set,\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global run /tmp/snapshot/threshold_0/\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 387.1831 - mse: 30060435456.0000 - mae: 387.1829 - val_loss: 0.3637 - val_mse: 1259.2964 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3613 - mse: 1021.0028 - mae: 0.3613 - val_loss: 0.3613 - val_mse: 1259.2711 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5355 - mse: 25050365952.0000 - mae: 290.5357 - val_loss: 0.3608 - val_mse: 1259.2683 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2993 - mse: 693.7349 - mae: 0.2993 - val_loss: 0.3604 - val_mse: 1259.2648 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4623 - mse: 25050363904.0000 - mae: 290.4625 - val_loss: 0.3601 - val_mse: 1259.2644 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3704 - mse: 1086.0546 - mae: 0.3704 - val_loss: 0.3598 - val_mse: 1259.2607 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3845 - mse: 1193.5133 - mae: 0.3845 - val_loss: 0.3598 - val_mse: 1259.2612 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5445 - mse: 50100727808.0000 - mae: 580.5446 - val_loss: 0.3594 - val_mse: 1259.2651 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4765 - mse: 25050365952.0000 - mae: 290.4764 - val_loss: 0.3592 - val_mse: 1259.2644 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3896 - mse: 1180.7065 - mae: 0.3896 - val_loss: 0.3591 - val_mse: 1259.2634 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3938 - mse: 1099.2180 - mae: 0.3938 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4722 - mse: 25050363904.0000 - mae: 290.4723 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3048 - mse: 767.0829 - mae: 0.3048 - val_loss: 0.3587 - val_mse: 1259.2634 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2782 - mse: 30060439552.0000 - mae: 387.2783 - val_loss: 0.3586 - val_mse: 1259.2643 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3194 - mse: 665.0280 - mae: 0.3194 - val_loss: 0.3586 - val_mse: 1259.2633 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2658 - mse: 30060439552.0000 - mae: 387.2656 - val_loss: 0.3631 - val_mse: 1259.2659 - val_mae: 0.3631\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3110 - mse: 699.6729 - mae: 0.3110 - val_loss: 0.3614 - val_mse: 1259.2646 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3725 - mse: 1003.3207 - mae: 0.3725 - val_loss: 0.3608 - val_mse: 1259.2642 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7725 - mse: 20040292352.0000 - mae: 193.7725 - val_loss: 0.3605 - val_mse: 1259.2653 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5553 - mse: 25050365952.0000 - mae: 290.5554 - val_loss: 0.3602 - val_mse: 1259.2625 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3008 - mse: 677.9714 - mae: 0.3008 - val_loss: 0.3599 - val_mse: 1259.2642 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3194 - mse: 880.6953 - mae: 0.3194 - val_loss: 0.3596 - val_mse: 1259.2642 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1834 - mse: 30060439552.0000 - mae: 387.1834 - val_loss: 0.3595 - val_mse: 1259.2639 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2337 - mse: 30060439552.0000 - mae: 387.2338 - val_loss: 0.3594 - val_mse: 1259.2638 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3311 - mse: 823.9611 - mae: 0.3311 - val_loss: 0.3592 - val_mse: 1259.2610 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3612 - mse: 1145.7000 - mae: 0.3612 - val_loss: 0.3591 - val_mse: 1259.2649 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1646 - mse: 30060435456.0000 - mae: 387.1647 - val_loss: 0.3589 - val_mse: 1259.2620 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4522 - mse: 25050365952.0000 - mae: 290.4519 - val_loss: 0.3589 - val_mse: 1259.2631 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3204 - mse: 850.3831 - mae: 0.3204 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3281 - mse: 703.9251 - mae: 0.3281 - val_loss: 0.3586 - val_mse: 1259.2633 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3558 - mse: 840.1379 - mae: 0.3558 - val_loss: 0.3671 - val_mse: 1259.2853 - val_mae: 0.3671\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2999 - mse: 30060435456.0000 - mae: 387.2998 - val_loss: 0.3615 - val_mse: 1259.2631 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5247 - mse: 25050365952.0000 - mae: 290.5249 - val_loss: 0.3608 - val_mse: 1259.2657 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3191 - mse: 763.0270 - mae: 0.3191 - val_loss: 0.3604 - val_mse: 1259.2611 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2936 - mse: 753.9890 - mae: 0.2936 - val_loss: 0.3603 - val_mse: 1259.2637 - val_mae: 0.3603\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5262 - mse: 25050363904.0000 - mae: 290.5262 - val_loss: 0.3600 - val_mse: 1259.2632 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1404 - mse: 30060435456.0000 - mae: 387.1406 - val_loss: 0.3598 - val_mse: 1259.2654 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3635 - mse: 1134.2996 - mae: 0.3635 - val_loss: 0.3595 - val_mse: 1259.2633 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3393 - mse: 1024.3024 - mae: 0.3393 - val_loss: 0.3594 - val_mse: 1259.2632 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1922 - mse: 30060435456.0000 - mae: 387.1922 - val_loss: 0.3592 - val_mse: 1259.2639 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9117 - mse: 35070509056.0000 - mae: 483.9120 - val_loss: 0.3592 - val_mse: 1259.2634 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3324 - mse: 914.8653 - mae: 0.3324 - val_loss: 0.3590 - val_mse: 1259.2612 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3499 - mse: 816.1034 - mae: 0.3499 - val_loss: 0.3589 - val_mse: 1259.2612 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9352 - mse: 35070509056.0000 - mae: 483.9352 - val_loss: 0.3588 - val_mse: 1259.2587 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3418 - mse: 984.9918 - mae: 0.3418 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 193.8392 - mse: 20040294400.0000 - mae: 193.8392 - val_loss: 0.3633 - val_mse: 1259.2689 - val_mae: 0.3633\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3205 - mse: 870.3157 - mae: 0.3205 - val_loss: 0.3616 - val_mse: 1259.2644 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3719 - mse: 1236.5627 - mae: 0.3719 - val_loss: 0.3608 - val_mse: 1259.2648 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1440 - mse: 30060435456.0000 - mae: 387.1438 - val_loss: 0.3603 - val_mse: 1259.2616 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3497 - mse: 873.1834 - mae: 0.3497 - val_loss: 0.3623 - val_mse: 1263.2471 - val_mae: 0.3623\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2550 - mse: 30060439552.0000 - mae: 387.2552 - val_loss: 0.3599 - val_mse: 1259.2614 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4525 - mse: 25050365952.0000 - mae: 290.4525 - val_loss: 0.3596 - val_mse: 1259.2600 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3477 - mse: 1064.0723 - mae: 0.3477 - val_loss: 0.3594 - val_mse: 1259.2645 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4502 - mse: 25050365952.0000 - mae: 290.4503 - val_loss: 0.3593 - val_mse: 1259.2640 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3539 - mse: 1052.3918 - mae: 0.3539 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9198 - mse: 35070509056.0000 - mae: 483.9197 - val_loss: 0.3591 - val_mse: 1259.2635 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3483 - mse: 845.2533 - mae: 0.3483 - val_loss: 0.3589 - val_mse: 1259.2648 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.1742 - mse: 45090652160.0000 - mae: 677.1741 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4916 - mse: 1575.8148 - mae: 0.4916 - val_loss: 0.3585 - val_mse: 1259.2565 - val_mae: 0.3585\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3764 - mse: 958.6947 - mae: 0.3764 - val_loss: 0.3585 - val_mse: 1259.2633 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8648 - mse: 35070509056.0000 - mae: 483.8650 - val_loss: 0.3644 - val_mse: 1259.2902 - val_mae: 0.3644\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3959 - mse: 1056.2809 - mae: 0.3959 - val_loss: 0.3621 - val_mse: 1259.2759 - val_mae: 0.3621\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3465 - mse: 901.7836 - mae: 0.3465 - val_loss: 0.3613 - val_mse: 1259.2764 - val_mae: 0.3613\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2106 - mse: 30060439552.0000 - mae: 387.2106 - val_loss: 0.3608 - val_mse: 1259.2780 - val_mae: 0.3608\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5195 - mse: 25050365952.0000 - mae: 290.5195 - val_loss: 0.3602 - val_mse: 1259.2656 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2990 - mse: 744.8181 - mae: 0.2990 - val_loss: 0.3600 - val_mse: 1259.2625 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3980 - mse: 1139.0601 - mae: 0.3980 - val_loss: 0.3598 - val_mse: 1259.2648 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7724 - mse: 20040292352.0000 - mae: 193.7725 - val_loss: 0.3595 - val_mse: 1259.2611 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3255 - mse: 794.4137 - mae: 0.3255 - val_loss: 0.3594 - val_mse: 1259.2634 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5489 - mse: 25050365952.0000 - mae: 290.5488 - val_loss: 0.3592 - val_mse: 1259.2621 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1782 - mse: 30060435456.0000 - mae: 387.1779 - val_loss: 0.3590 - val_mse: 1259.2639 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2751 - mse: 593.8859 - mae: 0.2751 - val_loss: 0.3589 - val_mse: 1259.2610 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4420 - mse: 25050365952.0000 - mae: 290.4418 - val_loss: 0.3587 - val_mse: 1259.2634 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3683 - mse: 936.0635 - mae: 0.3683 - val_loss: 0.3587 - val_mse: 1259.2625 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4309 - mse: 1197.7108 - mae: 0.4309 - val_loss: 0.3587 - val_mse: 1259.2490 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4762 - mse: 1466.0443 - mae: 0.4762 - val_loss: 0.3628 - val_mse: 1259.2766 - val_mae: 0.3628\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6470 - mse: 20040292352.0000 - mae: 193.6470 - val_loss: 0.3613 - val_mse: 1259.2688 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2901 - mse: 630.4600 - mae: 0.2901 - val_loss: 0.3608 - val_mse: 1259.2659 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3766 - mse: 45090652160.0000 - mae: 677.3766 - val_loss: 0.3604 - val_mse: 1259.2659 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3963 - mse: 1211.5067 - mae: 0.3963 - val_loss: 0.3601 - val_mse: 1259.2621 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8873 - mse: 35070509056.0000 - mae: 483.8872 - val_loss: 0.3598 - val_mse: 1259.2627 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7444 - mse: 20040292352.0000 - mae: 193.7443 - val_loss: 0.3596 - val_mse: 1259.2646 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1565 - mse: 30060435456.0000 - mae: 387.1565 - val_loss: 0.3595 - val_mse: 1259.2618 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4156 - mse: 1307.7682 - mae: 0.4156 - val_loss: 0.3593 - val_mse: 1259.2618 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3309 - mse: 741.4924 - mae: 0.3309 - val_loss: 0.3592 - val_mse: 1259.2628 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8386 - mse: 45090652160.0000 - mae: 483.8387 - val_loss: 0.3591 - val_mse: 1259.2653 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4189 - mse: 1229.3053 - mae: 0.4189 - val_loss: 0.3589 - val_mse: 1259.2642 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3807 - mse: 1157.1465 - mae: 0.3807 - val_loss: 0.3589 - val_mse: 1259.2664 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6534 - mse: 20040292352.0000 - mae: 193.6535 - val_loss: 0.3587 - val_mse: 1259.2648 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1473 - mse: 30060435456.0000 - mae: 387.1473 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1398 - mse: 30060435456.0000 - mae: 387.1402 - val_loss: 0.3635 - val_mse: 1259.2927 - val_mae: 0.3635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4406 - mse: 1307.7612 - mae: 0.4406 - val_loss: 0.3615 - val_mse: 1259.2638 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2861 - mse: 682.8022 - mae: 0.2861 - val_loss: 0.3609 - val_mse: 1259.2655 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8618 - mse: 20040290304.0000 - mae: 193.8619 - val_loss: 0.3604 - val_mse: 1259.2622 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3525 - mse: 847.9840 - mae: 0.3525 - val_loss: 0.3600 - val_mse: 1259.2649 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9031 - mse: 35070509056.0000 - mae: 483.9034 - val_loss: 0.3598 - val_mse: 1259.2637 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4715 - mse: 25050363904.0000 - mae: 290.4714 - val_loss: 0.3595 - val_mse: 1259.2587 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3809 - mse: 1059.5771 - mae: 0.3809 - val_loss: 0.3594 - val_mse: 1259.2587 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8102 - mse: 20040290304.0000 - mae: 193.8102 - val_loss: 0.3592 - val_mse: 1259.2609 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3467 - mse: 902.1523 - mae: 0.3467 - val_loss: 0.3591 - val_mse: 1259.2631 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9116 - mse: 35070509056.0000 - mae: 483.9112 - val_loss: 0.3589 - val_mse: 1259.2606 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3080 - mse: 697.2502 - mae: 0.3080 - val_loss: 0.3589 - val_mse: 1259.2610 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1490 - mse: 30060435456.0000 - mae: 387.1491 - val_loss: 0.3587 - val_mse: 1259.2623 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3643 - mse: 1118.0328 - mae: 0.3643 - val_loss: 0.3587 - val_mse: 1259.2614 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1737 - mse: 30060435456.0000 - mae: 387.1738 - val_loss: 0.3585 - val_mse: 1259.2627 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7813 - mse: 20040294400.0000 - mae: 193.7812 - val_loss: 0.3635 - val_mse: 1259.2798 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3277 - mse: 779.2257 - mae: 0.3277 - val_loss: 0.3615 - val_mse: 1259.2648 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4459 - mse: 1340.1200 - mae: 0.4459 - val_loss: 0.3609 - val_mse: 1259.2625 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7207 - mse: 20040290304.0000 - mae: 193.7206 - val_loss: 0.3604 - val_mse: 1259.2620 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3075 - mse: 787.0283 - mae: 0.3075 - val_loss: 0.3601 - val_mse: 1259.2646 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2870 - mse: 30060435456.0000 - mae: 387.2870 - val_loss: 0.3598 - val_mse: 1259.2635 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3854 - mse: 1105.3572 - mae: 0.3854 - val_loss: 0.3597 - val_mse: 1259.2594 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8731 - mse: 35070509056.0000 - mae: 483.8734 - val_loss: 0.3594 - val_mse: 1259.2626 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2969 - mse: 702.1067 - mae: 0.2969 - val_loss: 0.3593 - val_mse: 1259.2621 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8700 - mse: 35070509056.0000 - mae: 483.8701 - val_loss: 0.3593 - val_mse: 1259.2629 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9244 - mse: 35070509056.0000 - mae: 483.9248 - val_loss: 0.3591 - val_mse: 1259.2650 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3074 - mse: 839.0096 - mae: 0.3074 - val_loss: 0.3589 - val_mse: 1259.2639 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3249 - mse: 831.2382 - mae: 0.3249 - val_loss: 0.3589 - val_mse: 1259.2623 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1640 - mse: 30060435456.0000 - mae: 387.1641 - val_loss: 0.3587 - val_mse: 1259.2612 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5014 - mse: 25050363904.0000 - mae: 290.5013 - val_loss: 0.3586 - val_mse: 1259.2616 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3430 - mse: 914.7209 - mae: 0.3430 - val_loss: 0.3692 - val_mse: 1259.2869 - val_mae: 0.3692\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4761 - mse: 25050363904.0000 - mae: 290.4761 - val_loss: 0.3616 - val_mse: 1259.2662 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4000 - mse: 1208.6370 - mae: 0.4000 - val_loss: 0.3609 - val_mse: 1259.2646 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 870.6868 - mse: 65130946560.0000 - mae: 870.6796 - val_loss: 0.3604 - val_mse: 1259.2622 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8114 - mse: 20040290304.0000 - mae: 193.8115 - val_loss: 0.3600 - val_mse: 1259.2637 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3287 - mse: 755.4190 - mae: 0.3287 - val_loss: 0.3599 - val_mse: 1259.2645 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3238 - mse: 958.3883 - mae: 0.3238 - val_loss: 0.3597 - val_mse: 1259.2623 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 870.6755 - mse: 55110799360.0000 - mae: 870.6683 - val_loss: 0.3594 - val_mse: 1259.2649 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2311 - mse: 455.8499 - mae: 0.2311 - val_loss: 0.3593 - val_mse: 1259.2643 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5865 - mse: 25050365952.0000 - mae: 290.5864 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3274 - mse: 995.2083 - mae: 0.3274 - val_loss: 0.3590 - val_mse: 1259.2642 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9058 - mse: 35070509056.0000 - mae: 483.9059 - val_loss: 0.3647 - val_mse: 1268.3184 - val_mae: 0.3647\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3010 - mse: 773.6578 - mae: 0.3010 - val_loss: 0.3589 - val_mse: 1259.2655 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4775 - mse: 25050365952.0000 - mae: 290.4775 - val_loss: 0.3587 - val_mse: 1259.2642 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3926 - mse: 1154.5161 - mae: 0.3926 - val_loss: 0.3586 - val_mse: 1259.2648 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9193 - mse: 35070509056.0000 - mae: 483.9203 - val_loss: 0.3669 - val_mse: 1259.2925 - val_mae: 0.3669\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 0.3509 - mse: 922.0599 - mae: 0.3509 - val_loss: 0.3616 - val_mse: 1259.2593 - val_mae: 0.3616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3421 - mse: 994.2018 - mae: 0.3421 - val_loss: 0.3607 - val_mse: 1259.2637 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8430 - mse: 35070509056.0000 - mae: 483.8433 - val_loss: 0.3604 - val_mse: 1259.2659 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2651 - mse: 45090652160.0000 - mae: 677.2654 - val_loss: 0.3601 - val_mse: 1259.2631 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3588 - mse: 911.4478 - mae: 0.3588 - val_loss: 0.3599 - val_mse: 1259.2646 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2174 - mse: 30060435456.0000 - mae: 387.2172 - val_loss: 0.3596 - val_mse: 1259.2653 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3231 - mse: 797.2960 - mae: 0.3231 - val_loss: 0.3595 - val_mse: 1259.2650 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2867 - mse: 674.9370 - mae: 0.2867 - val_loss: 0.3594 - val_mse: 1259.2649 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5753 - mse: 25050365952.0000 - mae: 290.5753 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6581 - mse: 40080580608.0000 - mae: 580.6579 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3012 - mse: 705.6279 - mae: 0.3012 - val_loss: 0.3590 - val_mse: 1259.2629 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4639 - mse: 1536.1622 - mae: 0.4639 - val_loss: 0.3589 - val_mse: 1259.2640 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7458 - mse: 35070509056.0000 - mae: 483.7459 - val_loss: 0.3588 - val_mse: 1259.2632 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1689 - mse: 30060435456.0000 - mae: 387.1689 - val_loss: 0.3587 - val_mse: 1259.2642 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3324 - mse: 701.1103 - mae: 0.3324 - val_loss: 0.3688 - val_mse: 1259.2755 - val_mae: 0.3688\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5760 - mse: 25050365952.0000 - mae: 290.5758 - val_loss: 0.3616 - val_mse: 1259.2627 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7799 - mse: 20040290304.0000 - mae: 193.7799 - val_loss: 0.3608 - val_mse: 1259.2645 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4011 - mse: 1045.0453 - mae: 0.4011 - val_loss: 0.3603 - val_mse: 1259.2653 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3114 - mse: 706.4512 - mae: 0.3114 - val_loss: 0.3601 - val_mse: 1259.2639 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3450 - mse: 45090656256.0000 - mae: 677.3467 - val_loss: 0.3598 - val_mse: 1259.2612 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3483 - mse: 958.6166 - mae: 0.3483 - val_loss: 0.3597 - val_mse: 1259.2616 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4383 - mse: 25050365952.0000 - mae: 290.4384 - val_loss: 0.3595 - val_mse: 1259.2621 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8108 - mse: 20040292352.0000 - mae: 193.8107 - val_loss: 0.3594 - val_mse: 1259.2666 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3435 - mse: 1015.6501 - mae: 0.3435 - val_loss: 0.3592 - val_mse: 1259.2654 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2196 - mse: 30060435456.0000 - mae: 387.2196 - val_loss: 0.3591 - val_mse: 1259.2635 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3249 - mse: 842.9907 - mae: 0.3249 - val_loss: 0.3590 - val_mse: 1259.2638 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 967.3881 - mse: 60120870912.0000 - mae: 967.3789 - val_loss: 0.3588 - val_mse: 1259.2646 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3478 - mse: 922.1142 - mae: 0.3478 - val_loss: 0.3587 - val_mse: 1259.2626 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8446 - mse: 35070509056.0000 - mae: 483.8450 - val_loss: 0.3586 - val_mse: 1259.2627 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9511 - mse: 35070509056.0000 - mae: 483.9510 - val_loss: 0.3636 - val_mse: 1259.2676 - val_mae: 0.3636\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3338 - mse: 755.0414 - mae: 0.3338 - val_loss: 0.3614 - val_mse: 1259.2653 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8560 - mse: 35070509056.0000 - mae: 483.8561 - val_loss: 0.3607 - val_mse: 1259.2659 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3615 - mse: 1062.9683 - mae: 0.3615 - val_loss: 0.3602 - val_mse: 1259.2627 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1998 - mse: 30060435456.0000 - mae: 387.1998 - val_loss: 0.3600 - val_mse: 1259.2633 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3490 - mse: 915.4756 - mae: 0.3490 - val_loss: 0.3598 - val_mse: 1259.2639 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3821 - mse: 1014.8049 - mae: 0.3821 - val_loss: 0.3595 - val_mse: 1259.2621 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5956 - mse: 50100727808.0000 - mae: 580.5960 - val_loss: 0.3593 - val_mse: 1259.2653 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5235 - mse: 25050365952.0000 - mae: 290.5236 - val_loss: 0.3591 - val_mse: 1259.2612 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2604 - mse: 554.3102 - mae: 0.2604 - val_loss: 0.3590 - val_mse: 1259.2648 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4117 - mse: 1351.9498 - mae: 0.4117 - val_loss: 0.3588 - val_mse: 1259.2614 - val_mae: 0.3588\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7967 - mse: 35070509056.0000 - mae: 483.7968 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4698 - mse: 1503.2302 - mae: 0.4698 - val_loss: 0.3587 - val_mse: 1259.2625 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7406 - mse: 20040290304.0000 - mae: 193.7406 - val_loss: 0.3584 - val_mse: 1259.2648 - val_mae: 0.3584\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4714 - mse: 25050365952.0000 - mae: 290.4716 - val_loss: 0.3584 - val_mse: 1259.2639 - val_mae: 0.3584\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3125 - mse: 693.3283 - mae: 0.3125 - val_loss: 0.3659 - val_mse: 1259.2964 - val_mae: 0.3659\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2153 - mse: 30060435456.0000 - mae: 387.2152 - val_loss: 0.3615 - val_mse: 1259.2693 - val_mae: 0.3615\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2271 - mse: 30060435456.0000 - mae: 387.2267 - val_loss: 0.3608 - val_mse: 1259.2656 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3532 - mse: 908.9084 - mae: 0.3532 - val_loss: 0.3604 - val_mse: 1259.2646 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5162 - mse: 25050363904.0000 - mae: 290.5159 - val_loss: 0.3601 - val_mse: 1259.2656 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3700 - mse: 849.9272 - mae: 0.3700 - val_loss: 0.3600 - val_mse: 1259.2609 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4512 - mse: 25050365952.0000 - mae: 290.4510 - val_loss: 0.3597 - val_mse: 1259.2648 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3548 - mse: 1083.0823 - mae: 0.3548 - val_loss: 0.3595 - val_mse: 1259.2649 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4388 - mse: 1432.9209 - mae: 0.4388 - val_loss: 0.3593 - val_mse: 1259.2625 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4107 - mse: 25050363904.0000 - mae: 290.4105 - val_loss: 0.3592 - val_mse: 1259.2649 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9370 - mse: 35070509056.0000 - mae: 483.9367 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3154 - mse: 790.6027 - mae: 0.3154 - val_loss: 0.3589 - val_mse: 1259.2642 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1765 - mse: 30060435456.0000 - mae: 387.1765 - val_loss: 0.3588 - val_mse: 1259.2628 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3324 - mse: 743.7219 - mae: 0.3324 - val_loss: 0.3588 - val_mse: 1259.2665 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7115 - mse: 20040292352.0000 - mae: 193.7116 - val_loss: 0.3586 - val_mse: 1259.2650 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3338 - mse: 710.2913 - mae: 0.3338 - val_loss: 0.3649 - val_mse: 1259.2793 - val_mae: 0.3649\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4886 - mse: 25050363904.0000 - mae: 290.4887 - val_loss: 0.3614 - val_mse: 1259.2673 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3172 - mse: 779.8549 - mae: 0.3172 - val_loss: 0.3607 - val_mse: 1259.2635 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5654 - mse: 25050363904.0000 - mae: 290.5655 - val_loss: 0.3603 - val_mse: 1259.2642 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7407 - mse: 20040292352.0000 - mae: 193.7406 - val_loss: 0.3600 - val_mse: 1259.2644 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3503 - mse: 1017.7100 - mae: 0.3503 - val_loss: 0.3597 - val_mse: 1259.2635 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2118 - mse: 30060439552.0000 - mae: 387.2118 - val_loss: 0.3596 - val_mse: 1259.2631 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2795 - mse: 581.3445 - mae: 0.2795 - val_loss: 0.3594 - val_mse: 1259.2650 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2309 - mse: 30060435456.0000 - mae: 387.2309 - val_loss: 0.3593 - val_mse: 1259.2570 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2982 - mse: 660.5081 - mae: 0.2982 - val_loss: 0.3590 - val_mse: 1259.2656 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3874 - mse: 1154.6727 - mae: 0.3874 - val_loss: 0.3590 - val_mse: 1259.2640 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0914 - mse: 30060435456.0000 - mae: 387.0918 - val_loss: 0.3588 - val_mse: 1259.2646 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5039 - mse: 25050363904.0000 - mae: 290.5038 - val_loss: 0.3588 - val_mse: 1259.2622 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3204 - mse: 691.9787 - mae: 0.3204 - val_loss: 0.3587 - val_mse: 1259.2644 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 773.9788 - mse: 50100727808.0000 - mae: 773.9788 - val_loss: 0.3586 - val_mse: 1259.2585 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4359 - mse: 1121.6274 - mae: 0.4359 - val_loss: 0.3629 - val_mse: 1259.2908 - val_mae: 0.3629\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7696 - mse: 20040292352.0000 - mae: 193.7696 - val_loss: 0.3613 - val_mse: 1259.2665 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8103 - mse: 35070509056.0000 - mae: 483.8107 - val_loss: 0.3607 - val_mse: 1259.2634 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4185 - mse: 1198.7587 - mae: 0.4185 - val_loss: 0.3602 - val_mse: 1259.2633 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.9081 - mse: 20040292352.0000 - mae: 193.9082 - val_loss: 0.3601 - val_mse: 1259.2629 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2976 - mse: 652.5446 - mae: 0.2976 - val_loss: 0.3603 - val_mse: 1259.3817 - val_mae: 0.3603\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2531 - mse: 30060435456.0000 - mae: 387.2530 - val_loss: 0.3597 - val_mse: 1259.2627 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2951 - mse: 739.4910 - mae: 0.2951 - val_loss: 0.3594 - val_mse: 1259.2604 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5950 - mse: 25050365952.0000 - mae: 290.5951 - val_loss: 0.3594 - val_mse: 1259.2644 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2737 - mse: 529.9026 - mae: 0.2737 - val_loss: 0.3591 - val_mse: 1259.2638 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4380 - mse: 25050365952.0000 - mae: 290.4382 - val_loss: 0.3590 - val_mse: 1259.2642 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4250 - mse: 1347.9297 - mae: 0.4250 - val_loss: 0.3588 - val_mse: 1259.2634 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1554 - mse: 30060435456.0000 - mae: 387.1555 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3628 - mse: 1022.9942 - mae: 0.3628 - val_loss: 0.3586 - val_mse: 1259.2627 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3379 - mse: 880.1422 - mae: 0.3379 - val_loss: 0.3586 - val_mse: 1259.2634 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.5568 - mse: 25050363904.0000 - mae: 290.5567 - val_loss: 0.3639 - val_mse: 1259.2804 - val_mae: 0.3639\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3465 - mse: 922.8932 - mae: 0.3465 - val_loss: 0.3614 - val_mse: 1259.2661 - val_mae: 0.3614\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4690 - mse: 25050365952.0000 - mae: 290.4690 - val_loss: 0.3608 - val_mse: 1259.2644 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3042 - mse: 807.1761 - mae: 0.3042 - val_loss: 0.3604 - val_mse: 1259.2650 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3640 - mse: 1104.6056 - mae: 0.3640 - val_loss: 0.3600 - val_mse: 1259.2637 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2013 - mse: 30060435456.0000 - mae: 387.2012 - val_loss: 0.3599 - val_mse: 1259.2644 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3781 - mse: 1068.7068 - mae: 0.3781 - val_loss: 0.3597 - val_mse: 1259.2604 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 677.2762 - mse: 45090652160.0000 - mae: 677.2766 - val_loss: 0.3595 - val_mse: 1259.2650 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3793 - mse: 1189.1143 - mae: 0.3793 - val_loss: 0.3593 - val_mse: 1259.2634 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 773.9715 - mse: 50100727808.0000 - mae: 773.9713 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.5527 - mse: 40080580608.0000 - mae: 580.5528 - val_loss: 0.3591 - val_mse: 1259.2654 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4210 - mse: 1362.6769 - mae: 0.4210 - val_loss: 0.3590 - val_mse: 1259.2635 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3063 - mse: 805.0754 - mae: 0.3063 - val_loss: 0.3588 - val_mse: 1259.2629 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7988 - mse: 20040290304.0000 - mae: 193.7988 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4143 - mse: 25050365952.0000 - mae: 290.4143 - val_loss: 0.3586 - val_mse: 1259.2616 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4842 - mse: 1560.8843 - mae: 0.4842 - val_loss: 0.3630 - val_mse: 1259.2861 - val_mae: 0.3630\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4332 - mse: 25050363904.0000 - mae: 290.4333 - val_loss: 0.3613 - val_mse: 1259.2737 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2607 - mse: 560.4338 - mae: 0.2607 - val_loss: 0.3606 - val_mse: 1259.2719 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8347 - mse: 20040292352.0000 - mae: 193.8346 - val_loss: 0.3602 - val_mse: 1259.2640 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4866 - mse: 1550.5795 - mae: 0.4866 - val_loss: 0.3600 - val_mse: 1259.2644 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8347 - mse: 35070509056.0000 - mae: 483.8342 - val_loss: 0.3596 - val_mse: 1259.2632 - val_mae: 0.3596\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9012 - mse: 35070513152.0000 - mae: 483.9012 - val_loss: 0.3594 - val_mse: 1259.2625 - val_mae: 0.3594\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3428 - mse: 1035.3868 - mae: 0.3428 - val_loss: 0.3593 - val_mse: 1259.2642 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3326 - mse: 769.5134 - mae: 0.3326 - val_loss: 0.3592 - val_mse: 1259.2639 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8764 - mse: 20040294400.0000 - mae: 193.8764 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4675 - mse: 25050365952.0000 - mae: 290.4677 - val_loss: 0.3589 - val_mse: 1259.2640 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3687 - mse: 1115.7272 - mae: 0.3687 - val_loss: 0.3588 - val_mse: 1259.2623 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3406 - mse: 815.3799 - mae: 0.3406 - val_loss: 0.3587 - val_mse: 1259.2614 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8802 - mse: 35070509056.0000 - mae: 483.8802 - val_loss: 0.3775 - val_mse: 1321.4189 - val_mae: 0.3775\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4083 - mse: 1238.9806 - mae: 0.4083 - val_loss: 0.3584 - val_mse: 1259.2616 - val_mae: 0.3584\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9557 - mse: 35070513152.0000 - mae: 483.9561 - val_loss: 0.3631 - val_mse: 1259.2812 - val_mae: 0.3631\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3013 - mse: 771.8906 - mae: 0.3013 - val_loss: 0.3613 - val_mse: 1259.2634 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2956 - mse: 641.2438 - mae: 0.2956 - val_loss: 0.3607 - val_mse: 1259.2634 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.0102 - mse: 50100727808.0000 - mae: 774.0109 - val_loss: 0.3603 - val_mse: 1259.2645 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3681 - mse: 1049.1039 - mae: 0.3681 - val_loss: 0.3600 - val_mse: 1259.2638 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4827 - mse: 25050365952.0000 - mae: 290.4827 - val_loss: 0.3598 - val_mse: 1259.2637 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3298 - mse: 948.7535 - mae: 0.3298 - val_loss: 0.3596 - val_mse: 1259.2646 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4634 - mse: 25050363904.0000 - mae: 290.4633 - val_loss: 0.3594 - val_mse: 1259.2642 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4437 - mse: 25050365952.0000 - mae: 290.4438 - val_loss: 0.3592 - val_mse: 1259.2635 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4590 - mse: 1319.5881 - mae: 0.4590 - val_loss: 0.3590 - val_mse: 1259.2637 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3959 - mse: 25050363904.0000 - mae: 290.3960 - val_loss: 0.3590 - val_mse: 1259.2621 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4455 - mse: 1304.0939 - mae: 0.4455 - val_loss: 0.3589 - val_mse: 1259.2622 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2453 - mse: 30060439552.0000 - mae: 387.2453 - val_loss: 0.3588 - val_mse: 1259.2618 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2967 - mse: 565.6616 - mae: 0.2967 - val_loss: 0.3587 - val_mse: 1259.2622 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4339 - mse: 1233.2792 - mae: 0.4339 - val_loss: 0.3586 - val_mse: 1259.2642 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 0.3974 - mse: 1022.4731 - mae: 0.3974 - val_loss: 0.3634 - val_mse: 1259.2816 - val_mae: 0.3634\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4525 - mse: 25050363904.0000 - mae: 290.4526 - val_loss: 0.3613 - val_mse: 1259.2672 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4406 - mse: 25050363904.0000 - mae: 290.4406 - val_loss: 0.3607 - val_mse: 1259.2660 - val_mae: 0.3607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3731 - mse: 992.0345 - mae: 0.3731 - val_loss: 0.3603 - val_mse: 1259.2640 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2980 - mse: 858.8839 - mae: 0.2980 - val_loss: 0.3600 - val_mse: 1259.2637 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9387 - mse: 35070509056.0000 - mae: 483.9388 - val_loss: 0.3598 - val_mse: 1259.2617 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3521 - mse: 974.2343 - mae: 0.3521 - val_loss: 0.3597 - val_mse: 1259.2625 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1253 - mse: 30060439552.0000 - mae: 387.1252 - val_loss: 0.3595 - val_mse: 1259.2605 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4370 - mse: 25050365952.0000 - mae: 290.4371 - val_loss: 0.3593 - val_mse: 1259.2645 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4388 - mse: 1257.1718 - mae: 0.4388 - val_loss: 0.3592 - val_mse: 1259.2638 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4972 - mse: 25050365952.0000 - mae: 290.4972 - val_loss: 0.3590 - val_mse: 1259.2637 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3438 - mse: 898.9966 - mae: 0.3438 - val_loss: 0.3589 - val_mse: 1259.2607 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7303 - mse: 20040290304.0000 - mae: 193.7303 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3840 - mse: 1124.7634 - mae: 0.3840 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 870.8222 - mse: 55110799360.0000 - mae: 870.8140 - val_loss: 0.3585 - val_mse: 1259.2635 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3825 - mse: 951.8458 - mae: 0.3825 - val_loss: 0.3638 - val_mse: 1259.2823 - val_mae: 0.3638\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1887 - mse: 30060435456.0000 - mae: 387.1886 - val_loss: 0.3614 - val_mse: 1259.2688 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7064 - mse: 20040290304.0000 - mae: 193.7063 - val_loss: 0.3606 - val_mse: 1259.2655 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4378 - mse: 1380.2406 - mae: 0.4378 - val_loss: 0.3653 - val_mse: 1279.0820 - val_mae: 0.3653\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4967 - mse: 25050363904.0000 - mae: 290.4966 - val_loss: 0.3600 - val_mse: 1259.2646 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3308 - mse: 865.8852 - mae: 0.3308 - val_loss: 0.3596 - val_mse: 1259.2649 - val_mae: 0.3596\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3525 - mse: 1040.2533 - mae: 0.3525 - val_loss: 0.3595 - val_mse: 1259.2644 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7446 - mse: 20040290304.0000 - mae: 193.7445 - val_loss: 0.3593 - val_mse: 1259.2650 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2219 - mse: 30060435456.0000 - mae: 387.2217 - val_loss: 0.3591 - val_mse: 1259.2623 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3658 - mse: 1039.7351 - mae: 0.3658 - val_loss: 0.3590 - val_mse: 1259.2644 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5381 - mse: 25050365952.0000 - mae: 290.5380 - val_loss: 0.3589 - val_mse: 1259.2645 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3282 - mse: 763.7535 - mae: 0.3282 - val_loss: 0.3587 - val_mse: 1259.2650 - val_mae: 0.3587\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1742 - mse: 30060435456.0000 - mae: 387.1742 - val_loss: 0.3586 - val_mse: 1259.2629 - val_mae: 0.3586\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3753 - mse: 1163.7130 - mae: 0.3753 - val_loss: 0.3585 - val_mse: 1259.2627 - val_mae: 0.3585\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4159 - mse: 1242.0626 - mae: 0.4159 - val_loss: 0.3585 - val_mse: 1259.2644 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 15ms/step - loss: 387.1549 - mse: 30060435456.0000 - mae: 387.1548 - val_loss: 0.3637 - val_mse: 1259.2915 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3834 - mse: 1174.5105 - mae: 0.3834 - val_loss: 0.3614 - val_mse: 1259.2655 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3749 - mse: 985.7967 - mae: 0.3749 - val_loss: 0.3607 - val_mse: 1259.2651 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8410 - mse: 35070509056.0000 - mae: 483.8421 - val_loss: 0.3603 - val_mse: 1259.2637 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9917 - mse: 35070509056.0000 - mae: 483.9927 - val_loss: 0.3601 - val_mse: 1259.2654 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2807 - mse: 540.4257 - mae: 0.2807 - val_loss: 0.3599 - val_mse: 1259.2651 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.6866 - mse: 20040292352.0000 - mae: 193.6865 - val_loss: 0.3596 - val_mse: 1259.2638 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4018 - mse: 1222.5787 - mae: 0.4018 - val_loss: 0.3595 - val_mse: 1259.2598 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1889 - mse: 30060435456.0000 - mae: 387.1889 - val_loss: 0.3593 - val_mse: 1259.2635 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3403 - mse: 939.7970 - mae: 0.3403 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5745 - mse: 40080580608.0000 - mae: 580.5745 - val_loss: 0.3591 - val_mse: 1259.2616 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 0.4446 - mse: 1239.7657 - mae: 0.4446 - val_loss: 0.3590 - val_mse: 1259.2600 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8379 - mse: 35070509056.0000 - mae: 483.8383 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.35896\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3658 - mse: 966.8795 - mae: 0.3658 - val_loss: 0.3589 - val_mse: 1259.2606 - val_mae: 0.3589\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.4618 - mse: 1386.8208 - mae: 0.4618 - val_loss: 0.3587 - val_mse: 1259.2617 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 387.2390 - mse: 30060439552.0000 - mae: 387.2390 - val_loss: 0.3661 - val_mse: 1259.3109 - val_mae: 0.3661\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3382 - mse: 837.3602 - mae: 0.3382 - val_loss: 0.3616 - val_mse: 1259.2698 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3389 - mse: 847.0593 - mae: 0.3389 - val_loss: 0.3607 - val_mse: 1259.2637 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8266 - mse: 20040292352.0000 - mae: 193.8266 - val_loss: 0.3603 - val_mse: 1259.2589 - val_mae: 0.3603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3972 - mse: 1205.7855 - mae: 0.3972 - val_loss: 0.3600 - val_mse: 1259.2618 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8788 - mse: 35070509056.0000 - mae: 483.8791 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3077 - mse: 751.7567 - mae: 0.3077 - val_loss: 0.3595 - val_mse: 1259.2618 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.6082 - mse: 40080580608.0000 - mae: 580.6088 - val_loss: 0.3594 - val_mse: 1259.2632 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2814 - mse: 30060439552.0000 - mae: 387.2813 - val_loss: 0.3592 - val_mse: 1259.2616 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.2821 - mse: 675.2626 - mae: 0.2821 - val_loss: 0.3591 - val_mse: 1259.2643 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2353 - mse: 566.2610 - mae: 0.2353 - val_loss: 0.3590 - val_mse: 1259.2633 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.8590 - mse: 20040294400.0000 - mae: 193.8590 - val_loss: 0.3589 - val_mse: 1259.2638 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2734 - mse: 660.8616 - mae: 0.2734 - val_loss: 0.3588 - val_mse: 1259.2627 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9803 - mse: 35070509056.0000 - mae: 483.9803 - val_loss: 0.3586 - val_mse: 1259.2620 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7719 - mse: 20040294400.0000 - mae: 193.7719 - val_loss: 0.3585 - val_mse: 1259.2638 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 0.4874 - mse: 1500.1536 - mae: 0.4874 - val_loss: 0.3635 - val_mse: 1259.2860 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 193.7288 - mse: 20040292352.0000 - mae: 193.7289 - val_loss: 0.3711 - val_mse: 1278.6750 - val_mae: 0.3711\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9042 - mse: 35070513152.0000 - mae: 483.9048 - val_loss: 0.3606 - val_mse: 1259.2642 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3205 - mse: 750.4778 - mae: 0.3205 - val_loss: 0.3603 - val_mse: 1259.2653 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3448 - mse: 969.7516 - mae: 0.3448 - val_loss: 0.3601 - val_mse: 1259.2635 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4266 - mse: 25050363904.0000 - mae: 290.4265 - val_loss: 0.3598 - val_mse: 1259.2645 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3326 - mse: 907.7442 - mae: 0.3326 - val_loss: 0.3596 - val_mse: 1259.2654 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2115 - mse: 30060439552.0000 - mae: 387.2116 - val_loss: 0.3594 - val_mse: 1259.2629 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3485 - mse: 987.8019 - mae: 0.3485 - val_loss: 0.3592 - val_mse: 1259.2629 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5820 - mse: 40080580608.0000 - mae: 580.5819 - val_loss: 0.3591 - val_mse: 1259.2639 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3122 - mse: 793.3231 - mae: 0.3122 - val_loss: 0.3590 - val_mse: 1259.2621 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8126 - mse: 20040290304.0000 - mae: 193.8125 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.4668 - mse: 40080580608.0000 - mae: 580.4666 - val_loss: 0.3588 - val_mse: 1259.2650 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4956 - mse: 1581.3823 - mae: 0.4956 - val_loss: 0.3587 - val_mse: 1259.2611 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2101 - mse: 30060435456.0000 - mae: 387.2104 - val_loss: 0.3586 - val_mse: 1259.2617 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 15ms/step - loss: 387.1357 - mse: 30060435456.0000 - mae: 387.1357 - val_loss: 0.3635 - val_mse: 1259.2944 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4591 - mse: 1476.7026 - mae: 0.4591 - val_loss: 0.3612 - val_mse: 1259.2681 - val_mae: 0.3612\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3983 - mse: 1188.9495 - mae: 0.3983 - val_loss: 0.3608 - val_mse: 1259.2695 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1481 - mse: 30060435456.0000 - mae: 387.1482 - val_loss: 0.3605 - val_mse: 1259.2676 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1213 - mse: 30060435456.0000 - mae: 387.1213 - val_loss: 0.3602 - val_mse: 1259.2651 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4545 - mse: 1382.8654 - mae: 0.4545 - val_loss: 0.3598 - val_mse: 1259.2603 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3317 - mse: 824.7018 - mae: 0.3317 - val_loss: 0.3596 - val_mse: 1259.2599 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.6148 - mse: 40080580608.0000 - mae: 580.6144 - val_loss: 0.3595 - val_mse: 1259.2626 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3497 - mse: 861.5152 - mae: 0.3497 - val_loss: 0.3592 - val_mse: 1259.2621 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1634 - mse: 30060435456.0000 - mae: 387.1634 - val_loss: 0.3592 - val_mse: 1259.2642 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3937 - mse: 1152.5693 - mae: 0.3937 - val_loss: 0.3590 - val_mse: 1259.2616 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5293 - mse: 40080580608.0000 - mae: 580.5299 - val_loss: 0.3588 - val_mse: 1259.2634 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3764 - mse: 1130.4854 - mae: 0.3764 - val_loss: 0.3588 - val_mse: 1259.2632 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8259 - mse: 35070509056.0000 - mae: 483.8261 - val_loss: 0.3587 - val_mse: 1259.2639 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 580.5340 - mse: 40080580608.0000 - mae: 580.5345 - val_loss: 0.3587 - val_mse: 1259.2653 - val_mae: 0.3587\n",
      "Global run /tmp/snapshot/threshold_1/\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1083 - mse: 30060435456.0000 - mae: 387.1083 - val_loss: 0.3704 - val_mse: 1259.3087 - val_mae: 0.3704\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4127 - mse: 1371.0084 - mae: 0.4127 - val_loss: 0.3616 - val_mse: 1259.2644 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4831 - mse: 1538.6479 - mae: 0.4831 - val_loss: 0.3608 - val_mse: 1259.2644 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6801 - mse: 20040290304.0000 - mae: 193.6801 - val_loss: 0.3604 - val_mse: 1259.2633 - val_mae: 0.3604\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3207 - mse: 823.5790 - mae: 0.3207 - val_loss: 0.3602 - val_mse: 1259.2650 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1932 - mse: 30060435456.0000 - mae: 387.1932 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5529 - mse: 40080580608.0000 - mae: 580.5530 - val_loss: 0.3596 - val_mse: 1259.2614 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3660 - mse: 1007.4821 - mae: 0.3660 - val_loss: 0.3595 - val_mse: 1259.2645 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3721 - mse: 985.3521 - mae: 0.3721 - val_loss: 0.3593 - val_mse: 1259.2629 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2040 - mse: 30060435456.0000 - mae: 387.2039 - val_loss: 0.3591 - val_mse: 1259.2646 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3732 - mse: 1037.6340 - mae: 0.3732 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 193.7580 - mse: 20040292352.0000 - mae: 193.7580 - val_loss: 0.3589 - val_mse: 1259.2625 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8558 - mse: 35070509056.0000 - mae: 483.8557 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4158 - mse: 1175.3666 - mae: 0.4158 - val_loss: 0.3586 - val_mse: 1259.2629 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4728 - mse: 1472.4539 - mae: 0.4728 - val_loss: 0.3585 - val_mse: 1259.2614 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9446 - mse: 35070509056.0000 - mae: 483.9449 - val_loss: 0.3678 - val_mse: 1259.2935 - val_mae: 0.3678\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3497 - mse: 818.4777 - mae: 0.3497 - val_loss: 0.3614 - val_mse: 1259.2656 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1596 - mse: 30060435456.0000 - mae: 387.1595 - val_loss: 0.3608 - val_mse: 1259.2627 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3251 - mse: 920.0189 - mae: 0.3251 - val_loss: 0.3661 - val_mse: 1268.3186 - val_mae: 0.3661\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3871 - mse: 25050365952.0000 - mae: 290.3873 - val_loss: 0.3601 - val_mse: 1259.2627 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4543 - mse: 1362.6176 - mae: 0.4543 - val_loss: 0.3599 - val_mse: 1259.2642 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3429 - mse: 977.3535 - mae: 0.3429 - val_loss: 0.3595 - val_mse: 1259.2629 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8676 - mse: 35070509056.0000 - mae: 483.8677 - val_loss: 0.3594 - val_mse: 1259.2638 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1830 - mse: 30060435456.0000 - mae: 387.1830 - val_loss: 0.3593 - val_mse: 1259.2607 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3587 - mse: 930.2445 - mae: 0.3587 - val_loss: 0.3592 - val_mse: 1259.2640 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9827 - mse: 50100727808.0000 - mae: 773.9825 - val_loss: 0.3589 - val_mse: 1259.2651 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3032 - mse: 817.9944 - mae: 0.3032 - val_loss: 0.3589 - val_mse: 1259.2589 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6621 - mse: 40080580608.0000 - mae: 580.6624 - val_loss: 0.3587 - val_mse: 1259.2627 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3439 - mse: 832.7457 - mae: 0.3439 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7782 - mse: 20040292352.0000 - mae: 193.7782 - val_loss: 0.3585 - val_mse: 1259.2567 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.3311 - mse: 30060439552.0000 - mae: 387.3310 - val_loss: 0.3698 - val_mse: 1259.2804 - val_mae: 0.3698\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.2548 - mse: 419.6910 - mae: 0.2548 - val_loss: 0.3617 - val_mse: 1259.2618 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3024 - mse: 773.3174 - mae: 0.3024 - val_loss: 0.3607 - val_mse: 1259.2656 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2117 - mse: 30060435456.0000 - mae: 387.2114 - val_loss: 0.3603 - val_mse: 1259.2622 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2766 - mse: 630.0296 - mae: 0.2766 - val_loss: 0.3599 - val_mse: 1259.2614 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9604 - mse: 35070513152.0000 - mae: 483.9602 - val_loss: 0.3597 - val_mse: 1259.2627 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3255 - mse: 743.0355 - mae: 0.3255 - val_loss: 0.3595 - val_mse: 1259.2640 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8983 - mse: 35070509056.0000 - mae: 483.8980 - val_loss: 0.3592 - val_mse: 1259.2621 - val_mae: 0.3592\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3932 - mse: 1164.2666 - mae: 0.3932 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7535 - mse: 20040292352.0000 - mae: 193.7534 - val_loss: 0.3591 - val_mse: 1259.2638 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1554 - mse: 30060435456.0000 - mae: 387.1555 - val_loss: 0.3589 - val_mse: 1259.2622 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3717 - mse: 1134.9729 - mae: 0.3717 - val_loss: 0.3588 - val_mse: 1259.2616 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4715 - mse: 25050363904.0000 - mae: 290.4715 - val_loss: 0.3586 - val_mse: 1259.2570 - val_mae: 0.3586\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3077 - mse: 745.9705 - mae: 0.3077 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3687 - mse: 1020.3554 - mae: 0.3687 - val_loss: 0.3585 - val_mse: 1259.2627 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9328 - mse: 35070509056.0000 - mae: 483.9331 - val_loss: 0.3662 - val_mse: 1259.2821 - val_mae: 0.3662\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3413 - mse: 967.6968 - mae: 0.3413 - val_loss: 0.3614 - val_mse: 1259.2662 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3024 - mse: 693.8384 - mae: 0.3024 - val_loss: 0.3607 - val_mse: 1259.2648 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5388 - mse: 25050365952.0000 - mae: 290.5388 - val_loss: 0.3603 - val_mse: 1259.2650 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3512 - mse: 960.7029 - mae: 0.3512 - val_loss: 0.3601 - val_mse: 1259.2642 - val_mae: 0.3601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4730 - mse: 25050363904.0000 - mae: 290.4731 - val_loss: 0.3597 - val_mse: 1259.2629 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1665 - mse: 30060435456.0000 - mae: 387.1664 - val_loss: 0.3595 - val_mse: 1259.2631 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3163 - mse: 790.9072 - mae: 0.3163 - val_loss: 0.3593 - val_mse: 1259.2650 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4385 - mse: 1244.1963 - mae: 0.4385 - val_loss: 0.3592 - val_mse: 1259.2648 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4511 - mse: 25050363904.0000 - mae: 290.4511 - val_loss: 0.3591 - val_mse: 1259.2648 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3849 - mse: 1209.7386 - mae: 0.3849 - val_loss: 0.3590 - val_mse: 1259.2607 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8321 - mse: 35070509056.0000 - mae: 483.8323 - val_loss: 0.3588 - val_mse: 1259.2605 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4625 - mse: 1339.4513 - mae: 0.4625 - val_loss: 0.3588 - val_mse: 1259.2625 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 773.9305 - mse: 50100727808.0000 - mae: 773.9301 - val_loss: 0.3586 - val_mse: 1259.2644 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4180 - mse: 1342.1321 - mae: 0.4180 - val_loss: 0.3586 - val_mse: 1259.2644 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8601 - mse: 35070513152.0000 - mae: 483.8607 - val_loss: 0.3665 - val_mse: 1259.2843 - val_mae: 0.3665\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4414 - mse: 1268.9177 - mae: 0.4414 - val_loss: 0.3614 - val_mse: 1259.2655 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3415 - mse: 802.2552 - mae: 0.3415 - val_loss: 0.3606 - val_mse: 1259.2651 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2054 - mse: 30060435456.0000 - mae: 387.2053 - val_loss: 0.3602 - val_mse: 1259.2650 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3275 - mse: 901.2288 - mae: 0.3275 - val_loss: 0.3600 - val_mse: 1259.2638 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8774 - mse: 35070509056.0000 - mae: 483.8774 - val_loss: 0.3598 - val_mse: 1259.2637 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3637 - mse: 920.6688 - mae: 0.3637 - val_loss: 0.3595 - val_mse: 1259.2644 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7793 - mse: 20040290304.0000 - mae: 193.7792 - val_loss: 0.3593 - val_mse: 1259.2637 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9824 - mse: 35070509056.0000 - mae: 483.9822 - val_loss: 0.3591 - val_mse: 1259.2633 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3110 - mse: 729.3268 - mae: 0.3110 - val_loss: 0.3591 - val_mse: 1259.2617 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3382 - mse: 861.6738 - mae: 0.3382 - val_loss: 0.3590 - val_mse: 1259.2633 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8783 - mse: 35070509056.0000 - mae: 483.8783 - val_loss: 0.3588 - val_mse: 1259.2629 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3175 - mse: 883.6129 - mae: 0.3175 - val_loss: 0.3587 - val_mse: 1259.2618 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1863 - mse: 30060439552.0000 - mae: 387.1860 - val_loss: 0.3586 - val_mse: 1259.2633 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.1991 - mse: 45090656256.0000 - mae: 677.1988 - val_loss: 0.3585 - val_mse: 1259.2594 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.6349 - mse: 40080580608.0000 - mae: 580.6349 - val_loss: 0.3633 - val_mse: 1259.2732 - val_mae: 0.3633\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3323 - mse: 735.5316 - mae: 0.3323 - val_loss: 0.3615 - val_mse: 1259.2616 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2964 - mse: 678.0946 - mae: 0.2964 - val_loss: 0.3607 - val_mse: 1259.2644 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5400 - mse: 25050365952.0000 - mae: 290.5401 - val_loss: 0.3604 - val_mse: 1259.2655 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7043 - mse: 20040292352.0000 - mae: 193.7043 - val_loss: 0.3601 - val_mse: 1259.2621 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3830 - mse: 1009.1206 - mae: 0.3830 - val_loss: 0.3599 - val_mse: 1259.2618 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4519 - mse: 25050363904.0000 - mae: 290.4519 - val_loss: 0.3595 - val_mse: 1259.2634 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3823 - mse: 1128.0446 - mae: 0.3823 - val_loss: 0.3594 - val_mse: 1259.2650 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3436 - mse: 1016.1545 - mae: 0.3436 - val_loss: 0.3594 - val_mse: 1259.2643 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1651 - mse: 30060435456.0000 - mae: 387.1651 - val_loss: 0.3591 - val_mse: 1259.2653 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3984 - mse: 1081.5065 - mae: 0.3984 - val_loss: 0.3590 - val_mse: 1259.2642 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1103 - mse: 30060435456.0000 - mae: 387.1103 - val_loss: 0.3588 - val_mse: 1259.2649 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3800 - mse: 1066.9603 - mae: 0.3800 - val_loss: 0.3587 - val_mse: 1259.2626 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7250 - mse: 20040290304.0000 - mae: 193.7249 - val_loss: 0.3586 - val_mse: 1259.2618 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3073 - mse: 705.1303 - mae: 0.3073 - val_loss: 0.3586 - val_mse: 1259.2639 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3963 - mse: 985.7631 - mae: 0.3963 - val_loss: 0.3629 - val_mse: 1259.2993 - val_mae: 0.3629\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2693 - mse: 45090652160.0000 - mae: 677.2704 - val_loss: 0.3616 - val_mse: 1259.2750 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.7088 - mse: 40080580608.0000 - mae: 580.7089 - val_loss: 0.3610 - val_mse: 1259.2607 - val_mae: 0.3610\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2657 - mse: 460.8482 - mae: 0.2657 - val_loss: 0.3603 - val_mse: 1259.2631 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7125 - mse: 20040292352.0000 - mae: 193.7124 - val_loss: 0.3600 - val_mse: 1259.2620 - val_mae: 0.3600\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3628 - mse: 1026.1942 - mae: 0.3628 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8918 - mse: 35070509056.0000 - mae: 483.8916 - val_loss: 0.3597 - val_mse: 1259.2631 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3632 - mse: 1005.3583 - mae: 0.3632 - val_loss: 0.3594 - val_mse: 1259.2633 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0108 - mse: 50100727808.0000 - mae: 774.0106 - val_loss: 0.3593 - val_mse: 1259.2643 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3530 - mse: 962.2106 - mae: 0.3530 - val_loss: 0.3591 - val_mse: 1259.2614 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6099 - mse: 40080580608.0000 - mae: 580.6102 - val_loss: 0.3589 - val_mse: 1259.2644 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3775 - mse: 1033.1100 - mae: 0.3775 - val_loss: 0.3588 - val_mse: 1259.2660 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3256 - mse: 45090652160.0000 - mae: 677.3256 - val_loss: 0.3587 - val_mse: 1259.2607 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3093 - mse: 742.1171 - mae: 0.3093 - val_loss: 0.3586 - val_mse: 1259.2655 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4959 - mse: 1606.3373 - mae: 0.4959 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4630 - mse: 1315.2754 - mae: 0.4630 - val_loss: 0.3634 - val_mse: 1259.2947 - val_mae: 0.3634\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4077 - mse: 25050365952.0000 - mae: 290.4076 - val_loss: 0.3613 - val_mse: 1259.2634 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3268 - mse: 811.2723 - mae: 0.3268 - val_loss: 0.3607 - val_mse: 1259.2642 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8685 - mse: 35070509056.0000 - mae: 483.8687 - val_loss: 0.3603 - val_mse: 1259.2616 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4312 - mse: 1279.1003 - mae: 0.4312 - val_loss: 0.3601 - val_mse: 1259.2616 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5422 - mse: 40080580608.0000 - mae: 580.5422 - val_loss: 0.3599 - val_mse: 1259.2638 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4738 - mse: 25050365952.0000 - mae: 290.4738 - val_loss: 0.3597 - val_mse: 1259.2633 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3989 - mse: 1158.9647 - mae: 0.3989 - val_loss: 0.3596 - val_mse: 1259.2629 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8581 - mse: 35070509056.0000 - mae: 483.8584 - val_loss: 0.3593 - val_mse: 1259.2631 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4221 - mse: 1280.5294 - mae: 0.4221 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4365 - mse: 25050363904.0000 - mae: 290.4363 - val_loss: 0.3591 - val_mse: 1259.2648 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4264 - mse: 1336.6422 - mae: 0.4264 - val_loss: 0.3589 - val_mse: 1259.2579 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3050 - mse: 768.5665 - mae: 0.3050 - val_loss: 0.3588 - val_mse: 1259.2607 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6319 - mse: 40080580608.0000 - mae: 580.6325 - val_loss: 0.3588 - val_mse: 1259.2657 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4957 - mse: 25050365952.0000 - mae: 290.4956 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1655 - mse: 30060435456.0000 - mae: 387.1656 - val_loss: 0.3653 - val_mse: 1259.2809 - val_mae: 0.3653\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3896 - mse: 973.2516 - mae: 0.3896 - val_loss: 0.3616 - val_mse: 1259.2634 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8191 - mse: 35070509056.0000 - mae: 483.8192 - val_loss: 0.3607 - val_mse: 1259.2622 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4862 - mse: 1514.7876 - mae: 0.4862 - val_loss: 0.3604 - val_mse: 1259.2634 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2990 - mse: 649.6570 - mae: 0.2990 - val_loss: 0.3601 - val_mse: 1259.2644 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 6s 9ms/step - loss: 290.5343 - mse: 25050363904.0000 - mae: 290.5340 - val_loss: 0.3597 - val_mse: 1259.2631 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3504 - mse: 880.1166 - mae: 0.3504 - val_loss: 0.3596 - val_mse: 1259.2621 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4237 - mse: 25050365952.0000 - mae: 290.4240 - val_loss: 0.3593 - val_mse: 1259.2631 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1819 - mse: 30060435456.0000 - mae: 387.1818 - val_loss: 0.3593 - val_mse: 1259.2631 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3382 - mse: 974.8599 - mae: 0.3382 - val_loss: 0.3591 - val_mse: 1259.2639 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4774 - mse: 25050365952.0000 - mae: 290.4774 - val_loss: 0.3590 - val_mse: 1259.2629 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3371 - mse: 853.2569 - mae: 0.3371 - val_loss: 0.3588 - val_mse: 1259.2620 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2707 - mse: 561.7963 - mae: 0.2707 - val_loss: 0.3588 - val_mse: 1259.2644 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.9073 - mse: 20040292352.0000 - mae: 193.9074 - val_loss: 0.3587 - val_mse: 1259.2626 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.3298 - mse: 30060435456.0000 - mae: 387.3298 - val_loss: 0.3586 - val_mse: 1259.2623 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1808 - mse: 30060435456.0000 - mae: 387.1808 - val_loss: 0.3655 - val_mse: 1259.3101 - val_mae: 0.3655\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4330 - mse: 1134.2633 - mae: 0.4330 - val_loss: 0.3616 - val_mse: 1259.2725 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4737 - mse: 25050363904.0000 - mae: 290.4737 - val_loss: 0.3609 - val_mse: 1259.2609 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3822 - mse: 1003.0833 - mae: 0.3822 - val_loss: 0.3604 - val_mse: 1259.2621 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4984 - mse: 25050365952.0000 - mae: 290.4983 - val_loss: 0.3601 - val_mse: 1259.2611 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3545 - mse: 1064.7391 - mae: 0.3545 - val_loss: 0.3598 - val_mse: 1259.2599 - val_mae: 0.3598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.8021 - mse: 20040294400.0000 - mae: 193.8021 - val_loss: 0.3596 - val_mse: 1259.2639 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3150 - mse: 759.4687 - mae: 0.3150 - val_loss: 0.3594 - val_mse: 1259.2604 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1947 - mse: 30060439552.0000 - mae: 387.1949 - val_loss: 0.3593 - val_mse: 1259.2628 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3257 - mse: 824.7774 - mae: 0.3257 - val_loss: 0.3591 - val_mse: 1259.2644 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3392 - mse: 924.4887 - mae: 0.3392 - val_loss: 0.3590 - val_mse: 1259.2617 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1681 - mse: 30060435456.0000 - mae: 387.1681 - val_loss: 0.3588 - val_mse: 1259.2634 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4359 - mse: 1245.5339 - mae: 0.4359 - val_loss: 0.3588 - val_mse: 1259.2621 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3721 - mse: 25050365952.0000 - mae: 290.3722 - val_loss: 0.3586 - val_mse: 1259.2598 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3372 - mse: 953.1157 - mae: 0.3372 - val_loss: 0.3586 - val_mse: 1259.2609 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3123 - mse: 722.8449 - mae: 0.3123 - val_loss: 0.3652 - val_mse: 1259.3038 - val_mae: 0.3652\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4892 - mse: 25050365952.0000 - mae: 290.4891 - val_loss: 0.3614 - val_mse: 1259.2648 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3462 - mse: 1000.8735 - mae: 0.3462 - val_loss: 0.3608 - val_mse: 1259.2640 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8701 - mse: 35070509056.0000 - mae: 483.8702 - val_loss: 0.3603 - val_mse: 1259.2635 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4360 - mse: 1190.0858 - mae: 0.4360 - val_loss: 0.3600 - val_mse: 1259.2633 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1307 - mse: 30060435456.0000 - mae: 387.1312 - val_loss: 0.3597 - val_mse: 1259.2644 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8965 - mse: 35070509056.0000 - mae: 483.8965 - val_loss: 0.3595 - val_mse: 1259.2633 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3407 - mse: 872.2390 - mae: 0.3407 - val_loss: 0.3594 - val_mse: 1259.2638 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3887 - mse: 25050365952.0000 - mae: 290.3885 - val_loss: 0.3592 - val_mse: 1259.2642 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4207 - mse: 1218.2592 - mae: 0.4207 - val_loss: 0.3590 - val_mse: 1259.2653 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6343 - mse: 40080584704.0000 - mae: 580.6342 - val_loss: 0.3589 - val_mse: 1259.2617 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2480 - mse: 527.4810 - mae: 0.2480 - val_loss: 0.3588 - val_mse: 1259.2642 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3388 - mse: 911.3919 - mae: 0.3388 - val_loss: 0.3587 - val_mse: 1259.2639 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1532 - mse: 30060435456.0000 - mae: 387.1534 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3711 - mse: 1081.2441 - mae: 0.3711 - val_loss: 0.3585 - val_mse: 1259.2638 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9464 - mse: 35070509056.0000 - mae: 483.9464 - val_loss: 0.3659 - val_mse: 1259.2916 - val_mae: 0.3659\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2907 - mse: 700.6222 - mae: 0.2907 - val_loss: 0.3613 - val_mse: 1259.2675 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3375 - mse: 997.9450 - mae: 0.3375 - val_loss: 0.3606 - val_mse: 1259.2643 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1545 - mse: 30060435456.0000 - mae: 387.1549 - val_loss: 0.3603 - val_mse: 1259.2648 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8529 - mse: 20040292352.0000 - mae: 193.8528 - val_loss: 0.3599 - val_mse: 1259.2640 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2063 - mse: 325.9171 - mae: 0.2063 - val_loss: 0.3596 - val_mse: 1259.2633 - val_mae: 0.3596\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7959 - mse: 20040292352.0000 - mae: 193.7959 - val_loss: 0.3595 - val_mse: 1259.2632 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2841 - mse: 752.7824 - mae: 0.2841 - val_loss: 0.3593 - val_mse: 1259.2625 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4667 - mse: 1559.0552 - mae: 0.4667 - val_loss: 0.3592 - val_mse: 1259.2620 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7373 - mse: 35070509056.0000 - mae: 483.7372 - val_loss: 0.3590 - val_mse: 1259.2648 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3102 - mse: 880.7372 - mae: 0.3102 - val_loss: 0.3589 - val_mse: 1259.2633 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7895 - mse: 20040292352.0000 - mae: 193.7895 - val_loss: 0.3588 - val_mse: 1259.2637 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3466 - mse: 45090652160.0000 - mae: 677.3469 - val_loss: 0.3587 - val_mse: 1259.2617 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3014 - mse: 756.6402 - mae: 0.3014 - val_loss: 0.3586 - val_mse: 1259.2588 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4300 - mse: 1392.3982 - mae: 0.4300 - val_loss: 0.3585 - val_mse: 1259.2638 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3282 - mse: 878.4476 - mae: 0.3282 - val_loss: 0.3712 - val_mse: 1259.2992 - val_mae: 0.3712\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2186 - mse: 30060435456.0000 - mae: 387.2187 - val_loss: 0.3617 - val_mse: 1259.2661 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9035 - mse: 35070509056.0000 - mae: 483.9036 - val_loss: 0.3608 - val_mse: 1259.2595 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3416 - mse: 928.8498 - mae: 0.3416 - val_loss: 0.3603 - val_mse: 1259.2656 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 773.9818 - mse: 50100727808.0000 - mae: 773.9818 - val_loss: 0.3600 - val_mse: 1259.2644 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3280 - mse: 799.7814 - mae: 0.3280 - val_loss: 0.3597 - val_mse: 1259.2616 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7344 - mse: 20040290304.0000 - mae: 193.7344 - val_loss: 0.3596 - val_mse: 1259.2633 - val_mae: 0.3596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3638 - mse: 962.4695 - mae: 0.3638 - val_loss: 0.3593 - val_mse: 1259.2616 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4062 - mse: 1194.1066 - mae: 0.4062 - val_loss: 0.3592 - val_mse: 1259.2631 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1729 - mse: 30060435456.0000 - mae: 387.1728 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4258 - mse: 1337.4233 - mae: 0.4258 - val_loss: 0.3589 - val_mse: 1259.2648 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3803 - mse: 25050363904.0000 - mae: 290.3804 - val_loss: 0.3588 - val_mse: 1259.2610 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6636 - mse: 20040290304.0000 - mae: 193.6636 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4108 - mse: 1232.7728 - mae: 0.4108 - val_loss: 0.3586 - val_mse: 1259.2628 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3989 - mse: 1174.7881 - mae: 0.3989 - val_loss: 0.3585 - val_mse: 1259.2612 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3897 - mse: 1069.1763 - mae: 0.3897 - val_loss: 0.3679 - val_mse: 1259.2830 - val_mae: 0.3679\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2238 - mse: 30060439552.0000 - mae: 387.2239 - val_loss: 0.3616 - val_mse: 1259.2656 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3292 - mse: 847.4130 - mae: 0.3292 - val_loss: 0.3608 - val_mse: 1259.2646 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1841 - mse: 30060435456.0000 - mae: 387.1840 - val_loss: 0.3605 - val_mse: 1259.2648 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3262 - mse: 768.3575 - mae: 0.3262 - val_loss: 0.3601 - val_mse: 1259.2643 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9249 - mse: 35070509056.0000 - mae: 483.9253 - val_loss: 0.3599 - val_mse: 1259.2649 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1930 - mse: 30060435456.0000 - mae: 387.1931 - val_loss: 0.3597 - val_mse: 1259.2650 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3113 - mse: 768.2187 - mae: 0.3113 - val_loss: 0.3595 - val_mse: 1259.2640 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1802 - mse: 30060435456.0000 - mae: 387.1801 - val_loss: 0.3594 - val_mse: 1259.2640 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4213 - mse: 1185.1515 - mae: 0.4213 - val_loss: 0.3592 - val_mse: 1259.2642 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2974 - mse: 658.9987 - mae: 0.2974 - val_loss: 0.3591 - val_mse: 1259.2628 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5451 - mse: 25050363904.0000 - mae: 290.5453 - val_loss: 0.3589 - val_mse: 1259.2639 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3443 - mse: 761.3358 - mae: 0.3443 - val_loss: 0.3588 - val_mse: 1259.2635 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1497 - mse: 30060435456.0000 - mae: 387.1497 - val_loss: 0.3588 - val_mse: 1259.2640 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3570 - mse: 1031.2433 - mae: 0.3570 - val_loss: 0.3587 - val_mse: 1259.2627 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5416 - mse: 25050363904.0000 - mae: 290.5414 - val_loss: 0.3641 - val_mse: 1259.2949 - val_mae: 0.3641\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3549 - mse: 819.0369 - mae: 0.3549 - val_loss: 0.3614 - val_mse: 1259.2709 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5057 - mse: 25050365952.0000 - mae: 290.5056 - val_loss: 0.3608 - val_mse: 1259.2655 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3075 - mse: 705.6004 - mae: 0.3075 - val_loss: 0.3604 - val_mse: 1259.2638 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3639 - mse: 949.3476 - mae: 0.3639 - val_loss: 0.3601 - val_mse: 1259.2653 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5158 - mse: 25050365952.0000 - mae: 290.5161 - val_loss: 0.3598 - val_mse: 1259.2604 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 677.3295 - mse: 45090652160.0000 - mae: 677.3298 - val_loss: 0.3597 - val_mse: 1259.2644 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3076 - mse: 676.9704 - mae: 0.3076 - val_loss: 0.3594 - val_mse: 1259.2635 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2736 - mse: 616.9014 - mae: 0.2736 - val_loss: 0.3592 - val_mse: 1259.2629 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.6724 - mse: 40080580608.0000 - mae: 580.6725 - val_loss: 0.3591 - val_mse: 1259.2617 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3634 - mse: 986.6664 - mae: 0.3634 - val_loss: 0.3591 - val_mse: 1259.2616 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.5804 - mse: 40080580608.0000 - mae: 580.5804 - val_loss: 0.3589 - val_mse: 1259.2629 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3226 - mse: 852.8345 - mae: 0.3226 - val_loss: 0.3587 - val_mse: 1259.2631 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8975 - mse: 35070509056.0000 - mae: 483.8972 - val_loss: 0.3586 - val_mse: 1259.2634 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4032 - mse: 1172.8041 - mae: 0.4032 - val_loss: 0.3586 - val_mse: 1259.2607 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3233 - mse: 834.9282 - mae: 0.3233 - val_loss: 0.3636 - val_mse: 1259.2759 - val_mae: 0.3636\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.6607 - mse: 40080584704.0000 - mae: 580.6608 - val_loss: 0.3619 - val_mse: 1259.2664 - val_mae: 0.3619\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1121 - mse: 30060439552.0000 - mae: 387.1121 - val_loss: 0.3611 - val_mse: 1259.2668 - val_mae: 0.3611\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3641 - mse: 1039.6924 - mae: 0.3641 - val_loss: 0.3607 - val_mse: 1259.2635 - val_mae: 0.3607\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5255 - mse: 25050363904.0000 - mae: 290.5258 - val_loss: 0.3602 - val_mse: 1259.2593 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3337 - mse: 926.2200 - mae: 0.3337 - val_loss: 0.3598 - val_mse: 1259.2626 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4986 - mse: 25050365952.0000 - mae: 290.4989 - val_loss: 0.3596 - val_mse: 1259.2618 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3514 - mse: 1024.0010 - mae: 0.3514 - val_loss: 0.3594 - val_mse: 1259.2626 - val_mae: 0.3594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8935 - mse: 35070509056.0000 - mae: 483.8935 - val_loss: 0.3593 - val_mse: 1259.2646 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3732 - mse: 968.5009 - mae: 0.3732 - val_loss: 0.3592 - val_mse: 1259.2618 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.5734 - mse: 40080580608.0000 - mae: 580.5734 - val_loss: 0.3590 - val_mse: 1259.2650 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4445 - mse: 1477.8339 - mae: 0.4445 - val_loss: 0.3589 - val_mse: 1259.2653 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4310 - mse: 1273.2590 - mae: 0.4310 - val_loss: 0.3589 - val_mse: 1259.2616 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1220 - mse: 30060439552.0000 - mae: 387.1220 - val_loss: 0.3586 - val_mse: 1259.2638 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3855 - mse: 1012.4838 - mae: 0.3855 - val_loss: 0.3586 - val_mse: 1259.2587 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 15ms/step - loss: 290.4828 - mse: 25050363904.0000 - mae: 290.4832 - val_loss: 0.3634 - val_mse: 1259.2767 - val_mae: 0.3634\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4011 - mse: 1209.1912 - mae: 0.4011 - val_loss: 0.3615 - val_mse: 1259.2632 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3847 - mse: 1136.6405 - mae: 0.3847 - val_loss: 0.3608 - val_mse: 1259.2631 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2032 - mse: 30060435456.0000 - mae: 387.2032 - val_loss: 0.3605 - val_mse: 1259.2644 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4208 - mse: 1256.8014 - mae: 0.4208 - val_loss: 0.3601 - val_mse: 1259.2638 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4443 - mse: 25050365952.0000 - mae: 290.4442 - val_loss: 0.3598 - val_mse: 1259.2642 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9483 - mse: 35070509056.0000 - mae: 483.9485 - val_loss: 0.3596 - val_mse: 1259.2616 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3404 - mse: 921.6681 - mae: 0.3404 - val_loss: 0.3594 - val_mse: 1259.2626 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3764 - mse: 1035.7784 - mae: 0.3764 - val_loss: 0.3593 - val_mse: 1259.2618 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1593 - mse: 30060435456.0000 - mae: 387.1591 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.6405 - mse: 40080580608.0000 - mae: 580.6404 - val_loss: 0.3590 - val_mse: 1259.2628 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2827 - mse: 767.8372 - mae: 0.2827 - val_loss: 0.3589 - val_mse: 1259.2599 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1604 - mse: 30060435456.0000 - mae: 387.1605 - val_loss: 0.3588 - val_mse: 1259.2627 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3678 - mse: 957.2037 - mae: 0.3678 - val_loss: 0.3586 - val_mse: 1259.2603 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5017 - mse: 40080580608.0000 - mae: 580.5021 - val_loss: 0.3586 - val_mse: 1259.2640 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5091 - mse: 40080580608.0000 - mae: 580.5090 - val_loss: 0.3630 - val_mse: 1259.2906 - val_mae: 0.3630\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4712 - mse: 1445.5629 - mae: 0.4712 - val_loss: 0.3614 - val_mse: 1259.2859 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2366 - mse: 30060435456.0000 - mae: 387.2367 - val_loss: 0.3607 - val_mse: 1259.2653 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3068 - mse: 708.2699 - mae: 0.3068 - val_loss: 0.3602 - val_mse: 1259.2644 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3529 - mse: 973.9880 - mae: 0.3529 - val_loss: 0.3600 - val_mse: 1259.2635 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8598 - mse: 35070509056.0000 - mae: 483.8603 - val_loss: 0.3598 - val_mse: 1259.2657 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4813 - mse: 25050363904.0000 - mae: 290.4811 - val_loss: 0.3596 - val_mse: 1259.2629 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4481 - mse: 1352.6088 - mae: 0.4481 - val_loss: 0.3594 - val_mse: 1259.2610 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2368 - mse: 30060435456.0000 - mae: 387.2368 - val_loss: 0.3593 - val_mse: 1259.2584 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3048 - mse: 730.3799 - mae: 0.3048 - val_loss: 0.3591 - val_mse: 1259.2576 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3424 - mse: 917.9988 - mae: 0.3424 - val_loss: 0.3590 - val_mse: 1259.2646 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9129 - mse: 35070509056.0000 - mae: 483.9131 - val_loss: 0.3588 - val_mse: 1259.2657 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2161 - mse: 30060435456.0000 - mae: 387.2162 - val_loss: 0.3588 - val_mse: 1259.2604 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3535 - mse: 988.4194 - mae: 0.3535 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3592 - mse: 950.8257 - mae: 0.3592 - val_loss: 0.3585 - val_mse: 1259.2616 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2872 - mse: 30060439552.0000 - mae: 387.2871 - val_loss: 0.3696 - val_mse: 1259.2804 - val_mae: 0.3696\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3465 - mse: 882.6676 - mae: 0.3465 - val_loss: 0.3615 - val_mse: 1259.2672 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3000 - mse: 765.4755 - mae: 0.3000 - val_loss: 0.3607 - val_mse: 1259.2664 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2735 - mse: 30060435456.0000 - mae: 387.2735 - val_loss: 0.3604 - val_mse: 1259.2665 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3301 - mse: 769.7112 - mae: 0.3301 - val_loss: 0.3601 - val_mse: 1259.2629 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2266 - mse: 30060435456.0000 - mae: 387.2266 - val_loss: 0.3598 - val_mse: 1259.2612 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3824 - mse: 952.3761 - mae: 0.3824 - val_loss: 0.3597 - val_mse: 1259.2628 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8328 - mse: 35070513152.0000 - mae: 483.8329 - val_loss: 0.3595 - val_mse: 1259.2679 - val_mae: 0.3595\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1130 - mse: 30060439552.0000 - mae: 387.1132 - val_loss: 0.3593 - val_mse: 1259.2590 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4762 - mse: 1484.1149 - mae: 0.4762 - val_loss: 0.3591 - val_mse: 1259.2607 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.8224 - mse: 20040292352.0000 - mae: 193.8223 - val_loss: 0.3590 - val_mse: 1259.2635 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3092 - mse: 630.9131 - mae: 0.3092 - val_loss: 0.3589 - val_mse: 1259.2621 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8592 - mse: 35070509056.0000 - mae: 483.8586 - val_loss: 0.3587 - val_mse: 1259.2601 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3457 - mse: 1034.3115 - mae: 0.3457 - val_loss: 0.3586 - val_mse: 1259.2640 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3390 - mse: 955.3521 - mae: 0.3390 - val_loss: 0.3585 - val_mse: 1259.2614 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4161 - mse: 1087.2417 - mae: 0.4161 - val_loss: 0.3634 - val_mse: 1259.2750 - val_mae: 0.3634\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4260 - mse: 25050365952.0000 - mae: 290.4261 - val_loss: 0.3614 - val_mse: 1259.2721 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4161 - mse: 1208.6720 - mae: 0.4161 - val_loss: 0.3608 - val_mse: 1259.2642 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8835 - mse: 35070513152.0000 - mae: 483.8838 - val_loss: 0.3603 - val_mse: 1259.2653 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3447 - mse: 923.3715 - mae: 0.3447 - val_loss: 0.3601 - val_mse: 1259.2620 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8599 - mse: 35070509056.0000 - mae: 483.8606 - val_loss: 0.3598 - val_mse: 1259.2648 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4164 - mse: 1248.5662 - mae: 0.4164 - val_loss: 0.3595 - val_mse: 1259.2656 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1264 - mse: 30060435456.0000 - mae: 387.1265 - val_loss: 0.3594 - val_mse: 1259.2642 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4103 - mse: 1074.7771 - mae: 0.4103 - val_loss: 0.3592 - val_mse: 1259.2633 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.5674 - mse: 40080580608.0000 - mae: 580.5673 - val_loss: 0.3591 - val_mse: 1259.2651 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.7437 - mse: 20040290304.0000 - mae: 193.7437 - val_loss: 0.3590 - val_mse: 1259.2638 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3275 - mse: 866.5618 - mae: 0.3275 - val_loss: 0.3589 - val_mse: 1259.2621 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3108 - mse: 801.0728 - mae: 0.3108 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2420 - mse: 30060435456.0000 - mae: 387.2422 - val_loss: 0.3587 - val_mse: 1259.2628 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2675 - mse: 536.5213 - mae: 0.2675 - val_loss: 0.3586 - val_mse: 1259.2601 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4304 - mse: 1204.4608 - mae: 0.4304 - val_loss: 0.3635 - val_mse: 1259.2896 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1509 - mse: 30060435456.0000 - mae: 387.1508 - val_loss: 0.3615 - val_mse: 1259.2643 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3242 - mse: 782.1952 - mae: 0.3242 - val_loss: 0.3608 - val_mse: 1259.2634 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9921 - mse: 35070509056.0000 - mae: 483.9924 - val_loss: 0.3605 - val_mse: 1259.2631 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3513 - mse: 905.9246 - mae: 0.3513 - val_loss: 0.3601 - val_mse: 1259.2640 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1832 - mse: 30060435456.0000 - mae: 387.1833 - val_loss: 0.3598 - val_mse: 1259.2650 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3754 - mse: 1139.8794 - mae: 0.3754 - val_loss: 0.3596 - val_mse: 1259.2633 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8835 - mse: 35070513152.0000 - mae: 483.8840 - val_loss: 0.3594 - val_mse: 1259.2635 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3502 - mse: 879.0744 - mae: 0.3502 - val_loss: 0.3593 - val_mse: 1259.2639 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 483.8968 - mse: 35070509056.0000 - mae: 483.8967 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.2662 - mse: 30060435456.0000 - mae: 387.2662 - val_loss: 0.3591 - val_mse: 1259.2667 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3137 - mse: 731.0687 - mae: 0.3137 - val_loss: 0.3589 - val_mse: 1259.2628 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3385 - mse: 991.4611 - mae: 0.3385 - val_loss: 0.3588 - val_mse: 1259.2651 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4702 - mse: 25050363904.0000 - mae: 290.4706 - val_loss: 0.3587 - val_mse: 1259.2631 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.0937 - mse: 30060435456.0000 - mae: 387.0936 - val_loss: 0.3586 - val_mse: 1259.2637 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 0.3907 - mse: 1076.2092 - mae: 0.3907 - val_loss: 0.3689 - val_mse: 1259.2996 - val_mae: 0.3689\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8531 - mse: 35070509056.0000 - mae: 483.8540 - val_loss: 0.3615 - val_mse: 1259.2655 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3525 - mse: 845.3990 - mae: 0.3525 - val_loss: 0.3608 - val_mse: 1259.2650 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8978 - mse: 35070509056.0000 - mae: 483.8984 - val_loss: 0.3603 - val_mse: 1259.2621 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1688 - mse: 30060435456.0000 - mae: 387.1688 - val_loss: 0.3600 - val_mse: 1259.2646 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3742 - mse: 867.4967 - mae: 0.3742 - val_loss: 0.3598 - val_mse: 1259.2627 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1327 - mse: 30060439552.0000 - mae: 387.1325 - val_loss: 0.3597 - val_mse: 1259.2642 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3578 - mse: 855.3638 - mae: 0.3578 - val_loss: 0.3595 - val_mse: 1259.2616 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3690 - mse: 1088.8351 - mae: 0.3690 - val_loss: 0.3593 - val_mse: 1259.2622 - val_mae: 0.3593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4545 - mse: 25050363904.0000 - mae: 290.4543 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3475 - mse: 870.0298 - mae: 0.3475 - val_loss: 0.3590 - val_mse: 1259.2637 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2352 - mse: 30060435456.0000 - mae: 387.2354 - val_loss: 0.3589 - val_mse: 1259.2623 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3913 - mse: 1112.2875 - mae: 0.3913 - val_loss: 0.3587 - val_mse: 1259.2590 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8807 - mse: 35070509056.0000 - mae: 483.8807 - val_loss: 0.3586 - val_mse: 1259.2635 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2134 - mse: 30060439552.0000 - mae: 387.2133 - val_loss: 0.3586 - val_mse: 1259.2633 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 15ms/step - loss: 290.5118 - mse: 25050365952.0000 - mae: 290.5118 - val_loss: 0.3637 - val_mse: 1259.2809 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3587 - mse: 861.0140 - mae: 0.3587 - val_loss: 0.3615 - val_mse: 1259.2666 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.4310 - mse: 25050363904.0000 - mae: 290.4308 - val_loss: 0.3608 - val_mse: 1259.2633 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4060 - mse: 1158.1041 - mae: 0.4060 - val_loss: 0.3603 - val_mse: 1259.2672 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3040 - mse: 797.7813 - mae: 0.3040 - val_loss: 0.3599 - val_mse: 1259.2646 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8187 - mse: 20040290304.0000 - mae: 193.8186 - val_loss: 0.3597 - val_mse: 1259.2644 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 774.0970 - mse: 50100727808.0000 - mae: 774.0969 - val_loss: 0.3596 - val_mse: 1259.2644 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2957 - mse: 743.6367 - mae: 0.2957 - val_loss: 0.3593 - val_mse: 1259.2648 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2444 - mse: 420.4333 - mae: 0.2444 - val_loss: 0.3592 - val_mse: 1259.2621 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8371 - mse: 20040290304.0000 - mae: 193.8370 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3052 - mse: 766.3799 - mae: 0.3052 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1733 - mse: 30060435456.0000 - mae: 387.1735 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4031 - mse: 1277.3661 - mae: 0.4031 - val_loss: 0.3588 - val_mse: 1259.2646 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8167 - mse: 35070509056.0000 - mae: 483.8163 - val_loss: 0.3586 - val_mse: 1259.2639 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1819 - mse: 30060439552.0000 - mae: 387.1819 - val_loss: 0.3586 - val_mse: 1259.2639 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 290.4738 - mse: 25050365952.0000 - mae: 290.4737 - val_loss: 0.3677 - val_mse: 1259.2712 - val_mae: 0.3677\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3398 - mse: 965.5536 - mae: 0.3398 - val_loss: 0.3616 - val_mse: 1259.2649 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4111 - mse: 1325.8928 - mae: 0.4111 - val_loss: 0.3609 - val_mse: 1259.2638 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1649 - mse: 30060439552.0000 - mae: 387.1648 - val_loss: 0.3605 - val_mse: 1259.2642 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3579 - mse: 892.3640 - mae: 0.3579 - val_loss: 0.3601 - val_mse: 1259.2625 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 193.7362 - mse: 20040292352.0000 - mae: 193.7361 - val_loss: 0.3599 - val_mse: 1259.2639 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3189 - mse: 631.4188 - mae: 0.3189 - val_loss: 0.3597 - val_mse: 1259.2629 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8876 - mse: 35070509056.0000 - mae: 483.8881 - val_loss: 0.3595 - val_mse: 1259.2644 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3583 - mse: 1043.7803 - mae: 0.3583 - val_loss: 0.3594 - val_mse: 1259.2632 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8765 - mse: 35070509056.0000 - mae: 483.8766 - val_loss: 0.3592 - val_mse: 1259.2659 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4183 - mse: 1134.9962 - mae: 0.4183 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8787 - mse: 35070509056.0000 - mae: 483.8790 - val_loss: 0.3591 - val_mse: 1259.2644 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3509 - mse: 1032.5579 - mae: 0.3509 - val_loss: 0.3590 - val_mse: 1259.2620 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8613 - mse: 35070509056.0000 - mae: 483.8614 - val_loss: 0.3587 - val_mse: 1259.2634 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4081 - mse: 25050363904.0000 - mae: 290.4082 - val_loss: 0.3587 - val_mse: 1259.2616 - val_mae: 0.3587\n",
      "Global run /tmp/snapshot/threshold_2/\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3704 - mse: 1044.0889 - mae: 0.3704 - val_loss: 0.3670 - val_mse: 1259.2980 - val_mae: 0.3670\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1929 - mse: 30060439552.0000 - mae: 387.1927 - val_loss: 0.3618 - val_mse: 1259.2701 - val_mae: 0.3618\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3647 - mse: 962.8150 - mae: 0.3647 - val_loss: 0.3610 - val_mse: 1259.2650 - val_mae: 0.3610\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8788 - mse: 35070509056.0000 - mae: 483.8791 - val_loss: 0.3605 - val_mse: 1259.2631 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3518 - mse: 919.0770 - mae: 0.3518 - val_loss: 0.3602 - val_mse: 1259.2642 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4253 - mse: 25050365952.0000 - mae: 290.4255 - val_loss: 0.3600 - val_mse: 1259.2611 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2697 - mse: 30060435456.0000 - mae: 387.2696 - val_loss: 0.3597 - val_mse: 1259.2633 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2528 - mse: 424.1174 - mae: 0.2528 - val_loss: 0.3596 - val_mse: 1259.2642 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3054 - mse: 706.7404 - mae: 0.3054 - val_loss: 0.3594 - val_mse: 1259.2618 - val_mae: 0.3594\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9108 - mse: 35070513152.0000 - mae: 483.9107 - val_loss: 0.3592 - val_mse: 1259.2632 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3736 - mse: 968.8144 - mae: 0.3736 - val_loss: 0.3591 - val_mse: 1259.2644 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1249 - mse: 30060435456.0000 - mae: 387.1249 - val_loss: 0.3589 - val_mse: 1259.2639 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 387.1497 - mse: 30060439552.0000 - mae: 387.1500 - val_loss: 0.3588 - val_mse: 1259.2629 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3882 - mse: 1094.1995 - mae: 0.3882 - val_loss: 0.3587 - val_mse: 1259.2606 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4248 - mse: 1274.4468 - mae: 0.4248 - val_loss: 0.3586 - val_mse: 1259.2618 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4474 - mse: 1104.4681 - mae: 0.4474 - val_loss: 0.3679 - val_mse: 1259.2804 - val_mae: 0.3679\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7377 - mse: 20040290304.0000 - mae: 193.7377 - val_loss: 0.3616 - val_mse: 1259.2677 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2887 - mse: 677.6556 - mae: 0.2887 - val_loss: 0.3607 - val_mse: 1259.2607 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6328 - mse: 40080584704.0000 - mae: 580.6338 - val_loss: 0.3604 - val_mse: 1259.2650 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8624 - mse: 35070509056.0000 - mae: 483.8626 - val_loss: 0.3601 - val_mse: 1259.2639 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3942 - mse: 1055.8959 - mae: 0.3942 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3802 - mse: 1085.3119 - mae: 0.3802 - val_loss: 0.3597 - val_mse: 1259.2639 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4420 - mse: 25050363904.0000 - mae: 290.4418 - val_loss: 0.3594 - val_mse: 1259.2637 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8661 - mse: 35070509056.0000 - mae: 483.8668 - val_loss: 0.3593 - val_mse: 1259.2637 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3300 - mse: 928.6306 - mae: 0.3300 - val_loss: 0.3591 - val_mse: 1259.2639 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2489 - mse: 476.5534 - mae: 0.2489 - val_loss: 0.3589 - val_mse: 1259.2601 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9370 - mse: 35070509056.0000 - mae: 483.9370 - val_loss: 0.3589 - val_mse: 1259.2625 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5160 - mse: 25050365952.0000 - mae: 290.5159 - val_loss: 0.3588 - val_mse: 1259.2631 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2954 - mse: 671.6131 - mae: 0.2954 - val_loss: 0.3587 - val_mse: 1259.2601 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3128 - mse: 830.3968 - mae: 0.3128 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7974 - mse: 20040292352.0000 - mae: 193.7973 - val_loss: 0.3706 - val_mse: 1259.2889 - val_mae: 0.3706\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3645 - mse: 1102.3715 - mae: 0.3645 - val_loss: 0.3617 - val_mse: 1259.2642 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4267 - mse: 1263.7512 - mae: 0.4267 - val_loss: 0.3609 - val_mse: 1259.2646 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1204 - mse: 30060435456.0000 - mae: 387.1203 - val_loss: 0.3605 - val_mse: 1259.2659 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3590 - mse: 1050.5260 - mae: 0.3590 - val_loss: 0.3601 - val_mse: 1259.2598 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8776 - mse: 35070509056.0000 - mae: 483.8776 - val_loss: 0.3598 - val_mse: 1259.2639 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3154 - mse: 858.0506 - mae: 0.3154 - val_loss: 0.3597 - val_mse: 1259.2643 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7531 - mse: 20040290304.0000 - mae: 193.7531 - val_loss: 0.3596 - val_mse: 1259.2642 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2933 - mse: 613.2004 - mae: 0.2933 - val_loss: 0.3594 - val_mse: 1259.2649 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5714 - mse: 25050365952.0000 - mae: 290.5714 - val_loss: 0.3593 - val_mse: 1259.2612 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4909 - mse: 25050365952.0000 - mae: 290.4912 - val_loss: 0.3592 - val_mse: 1259.2625 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3358 - mse: 928.1392 - mae: 0.3358 - val_loss: 0.3589 - val_mse: 1259.2607 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2377 - mse: 30060435456.0000 - mae: 387.2377 - val_loss: 0.3589 - val_mse: 1259.2607 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3046 - mse: 751.4731 - mae: 0.3046 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3752 - mse: 929.6730 - mae: 0.3752 - val_loss: 0.3588 - val_mse: 1259.2644 - val_mae: 0.3588\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1684 - mse: 30060439552.0000 - mae: 387.1683 - val_loss: 0.3641 - val_mse: 1259.3107 - val_mae: 0.3641\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.4136 - mse: 1188.9323 - mae: 0.4136 - val_loss: 0.3614 - val_mse: 1259.2664 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3380 - mse: 842.5068 - mae: 0.3380 - val_loss: 0.3607 - val_mse: 1259.2639 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0673 - mse: 50100731904.0000 - mae: 774.0676 - val_loss: 0.3604 - val_mse: 1259.2637 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8136 - mse: 20040292352.0000 - mae: 193.8136 - val_loss: 0.3599 - val_mse: 1259.2644 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3250 - mse: 813.2560 - mae: 0.3250 - val_loss: 0.3598 - val_mse: 1259.2618 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3500 - mse: 1029.4169 - mae: 0.3500 - val_loss: 0.3596 - val_mse: 1259.2648 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2654 - mse: 45090660352.0000 - mae: 677.2655 - val_loss: 0.3596 - val_mse: 1259.2626 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0517 - mse: 30060435456.0000 - mae: 387.0519 - val_loss: 0.3593 - val_mse: 1259.2644 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4162 - mse: 1289.0153 - mae: 0.4162 - val_loss: 0.3591 - val_mse: 1259.2648 - val_mae: 0.3591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5520 - mse: 40080580608.0000 - mae: 580.5519 - val_loss: 0.3591 - val_mse: 1259.2646 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3133 - mse: 800.9128 - mae: 0.3133 - val_loss: 0.3590 - val_mse: 1259.2614 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2064 - mse: 30060439552.0000 - mae: 387.2067 - val_loss: 0.3588 - val_mse: 1259.2618 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3724 - mse: 877.5876 - mae: 0.3724 - val_loss: 0.3587 - val_mse: 1259.2635 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1980 - mse: 30060435456.0000 - mae: 387.1980 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3531 - mse: 1018.9164 - mae: 0.3531 - val_loss: 0.3719 - val_mse: 1259.3220 - val_mae: 0.3719\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2092 - mse: 30060435456.0000 - mae: 387.2095 - val_loss: 0.3621 - val_mse: 1259.2686 - val_mae: 0.3621\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5957 - mse: 25050365952.0000 - mae: 290.5957 - val_loss: 0.3611 - val_mse: 1259.2650 - val_mae: 0.3611\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2564 - mse: 421.2139 - mae: 0.2564 - val_loss: 0.3606 - val_mse: 1259.2621 - val_mae: 0.3606\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3378 - mse: 934.4858 - mae: 0.3378 - val_loss: 0.3603 - val_mse: 1259.2642 - val_mae: 0.3603\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4889 - mse: 25050365952.0000 - mae: 290.4888 - val_loss: 0.3600 - val_mse: 1259.2644 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1926 - mse: 30060435456.0000 - mae: 387.1927 - val_loss: 0.3599 - val_mse: 1259.2631 - val_mae: 0.3599\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3854 - mse: 1026.0896 - mae: 0.3854 - val_loss: 0.3597 - val_mse: 1259.2638 - val_mae: 0.3597\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2641 - mse: 45090652160.0000 - mae: 677.2640 - val_loss: 0.3595 - val_mse: 1259.2633 - val_mae: 0.3595\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3945 - mse: 1145.4985 - mae: 0.3945 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1097 - mse: 30060435456.0000 - mae: 387.1099 - val_loss: 0.3593 - val_mse: 1259.2648 - val_mae: 0.3593\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4029 - mse: 1195.6746 - mae: 0.4029 - val_loss: 0.3592 - val_mse: 1259.2607 - val_mae: 0.3592\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3101 - mse: 872.4371 - mae: 0.3101 - val_loss: 0.3590 - val_mse: 1259.2629 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4812 - mse: 25050365952.0000 - mae: 290.4812 - val_loss: 0.3589 - val_mse: 1259.2633 - val_mae: 0.3589\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5049 - mse: 25050365952.0000 - mae: 290.5049 - val_loss: 0.3589 - val_mse: 1259.2625 - val_mae: 0.3589\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2140 - mse: 30060439552.0000 - mae: 387.2140 - val_loss: 0.3658 - val_mse: 1259.2755 - val_mae: 0.3658\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3774 - mse: 1044.1057 - mae: 0.3774 - val_loss: 0.3617 - val_mse: 1259.2656 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2554 - mse: 30060435456.0000 - mae: 387.2554 - val_loss: 0.3610 - val_mse: 1259.2632 - val_mae: 0.3610\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3290 - mse: 701.7162 - mae: 0.3290 - val_loss: 0.3606 - val_mse: 1259.2615 - val_mae: 0.3606\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3315 - mse: 719.5858 - mae: 0.3315 - val_loss: 0.3603 - val_mse: 1259.2620 - val_mae: 0.3603\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4612 - mse: 25050363904.0000 - mae: 290.4609 - val_loss: 0.3600 - val_mse: 1259.2642 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3608 - mse: 952.4957 - mae: 0.3608 - val_loss: 0.3598 - val_mse: 1259.2644 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7063 - mse: 20040290304.0000 - mae: 193.7062 - val_loss: 0.3597 - val_mse: 1259.2635 - val_mae: 0.3597\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3337 - mse: 854.5550 - mae: 0.3337 - val_loss: 0.3595 - val_mse: 1259.2667 - val_mae: 0.3595\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1783 - mse: 30060435456.0000 - mae: 387.1783 - val_loss: 0.3593 - val_mse: 1259.2644 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3215 - mse: 846.5476 - mae: 0.3215 - val_loss: 0.3592 - val_mse: 1259.2644 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1877 - mse: 30060439552.0000 - mae: 387.1877 - val_loss: 0.3591 - val_mse: 1259.2628 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4063 - mse: 25050365952.0000 - mae: 290.4064 - val_loss: 0.3590 - val_mse: 1259.2635 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4203 - mse: 1285.8291 - mae: 0.4203 - val_loss: 0.3588 - val_mse: 1259.2615 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3418 - mse: 930.1892 - mae: 0.3418 - val_loss: 0.3587 - val_mse: 1259.2610 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2072 - mse: 30060435456.0000 - mae: 387.2072 - val_loss: 0.3637 - val_mse: 1259.2855 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3301 - mse: 872.0901 - mae: 0.3301 - val_loss: 0.3615 - val_mse: 1259.2665 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2200 - mse: 368.9141 - mae: 0.2200 - val_loss: 0.3610 - val_mse: 1259.2661 - val_mae: 0.3610\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.9180 - mse: 20040294400.0000 - mae: 193.9179 - val_loss: 0.3605 - val_mse: 1259.2635 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2697 - mse: 476.7514 - mae: 0.2697 - val_loss: 0.3602 - val_mse: 1259.2623 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9748 - mse: 35070509056.0000 - mae: 483.9749 - val_loss: 0.3600 - val_mse: 1259.2654 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2078 - mse: 30060435456.0000 - mae: 387.2078 - val_loss: 0.3597 - val_mse: 1259.2638 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2994 - mse: 752.2866 - mae: 0.2994 - val_loss: 0.3596 - val_mse: 1259.2664 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3395 - mse: 870.0312 - mae: 0.3395 - val_loss: 0.3594 - val_mse: 1259.2642 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1894 - mse: 30060435456.0000 - mae: 387.1894 - val_loss: 0.3592 - val_mse: 1259.2621 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3863 - mse: 1090.6449 - mae: 0.3863 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4177 - mse: 25050365952.0000 - mae: 290.4175 - val_loss: 0.3590 - val_mse: 1259.2640 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3201 - mse: 842.7711 - mae: 0.3201 - val_loss: 0.3590 - val_mse: 1259.2655 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9053 - mse: 35070513152.0000 - mae: 483.9052 - val_loss: 0.3588 - val_mse: 1259.2635 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4712 - mse: 1457.2535 - mae: 0.4712 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3683 - mse: 901.4932 - mae: 0.3683 - val_loss: 0.3655 - val_mse: 1259.2855 - val_mae: 0.3655\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2296 - mse: 30060435456.0000 - mae: 387.2295 - val_loss: 0.3613 - val_mse: 1259.2637 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8966 - mse: 35070509056.0000 - mae: 483.8972 - val_loss: 0.3607 - val_mse: 1259.2648 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 9ms/step - loss: 0.3498 - mse: 924.8123 - mae: 0.3498 - val_loss: 0.3603 - val_mse: 1259.2628 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3945 - mse: 1171.5208 - mae: 0.3945 - val_loss: 0.3601 - val_mse: 1259.2661 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2073 - mse: 30060435456.0000 - mae: 387.2073 - val_loss: 0.3598 - val_mse: 1259.2651 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3961 - mse: 1138.9025 - mae: 0.3961 - val_loss: 0.3596 - val_mse: 1259.2573 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8824 - mse: 35070509056.0000 - mae: 483.8820 - val_loss: 0.3594 - val_mse: 1259.2635 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1686 - mse: 30060435456.0000 - mae: 387.1684 - val_loss: 0.3592 - val_mse: 1259.2643 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4062 - mse: 1228.1284 - mae: 0.4062 - val_loss: 0.3591 - val_mse: 1259.2605 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1706 - mse: 30060439552.0000 - mae: 387.1706 - val_loss: 0.3590 - val_mse: 1259.2653 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3118 - mse: 725.2327 - mae: 0.3118 - val_loss: 0.3590 - val_mse: 1259.2644 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4046 - mse: 25050365952.0000 - mae: 290.4047 - val_loss: 0.3588 - val_mse: 1259.2644 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4525 - mse: 1307.9547 - mae: 0.4525 - val_loss: 0.3587 - val_mse: 1259.2642 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4274 - mse: 25050365952.0000 - mae: 290.4273 - val_loss: 0.3585 - val_mse: 1259.2616 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5390 - mse: 25050363904.0000 - mae: 290.5388 - val_loss: 0.3662 - val_mse: 1259.2841 - val_mae: 0.3662\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3652 - mse: 929.1198 - mae: 0.3652 - val_loss: 0.3616 - val_mse: 1259.2656 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4335 - mse: 25050363904.0000 - mae: 290.4336 - val_loss: 0.3609 - val_mse: 1259.2656 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3854 - mse: 1144.3556 - mae: 0.3854 - val_loss: 0.3605 - val_mse: 1259.2645 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4014 - mse: 1176.6018 - mae: 0.4014 - val_loss: 0.3603 - val_mse: 1259.2638 - val_mae: 0.3603\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4460 - mse: 25050363904.0000 - mae: 290.4460 - val_loss: 0.3600 - val_mse: 1259.2625 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4026 - mse: 1177.3162 - mae: 0.4026 - val_loss: 0.3599 - val_mse: 1259.2579 - val_mae: 0.3599\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5627 - mse: 40080580608.0000 - mae: 580.5624 - val_loss: 0.3597 - val_mse: 1259.2639 - val_mae: 0.3597\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4023 - mse: 1172.3792 - mae: 0.4023 - val_loss: 0.3594 - val_mse: 1259.2595 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1684 - mse: 30060439552.0000 - mae: 387.1685 - val_loss: 0.3594 - val_mse: 1259.2634 - val_mae: 0.3594\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4776 - mse: 25050363904.0000 - mae: 290.4774 - val_loss: 0.3592 - val_mse: 1259.2620 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3380 - mse: 1043.5806 - mae: 0.3380 - val_loss: 0.3590 - val_mse: 1259.2625 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8498 - mse: 20040292352.0000 - mae: 193.8498 - val_loss: 0.3590 - val_mse: 1259.2634 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2840 - mse: 611.2150 - mae: 0.2840 - val_loss: 0.3589 - val_mse: 1259.2656 - val_mae: 0.3589\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7871 - mse: 20040290304.0000 - mae: 193.7871 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.6155 - mse: 25050365952.0000 - mae: 290.6155 - val_loss: 0.3632 - val_mse: 1259.2854 - val_mae: 0.3632\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2923 - mse: 643.0094 - mae: 0.2923 - val_loss: 0.3613 - val_mse: 1259.2656 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1713 - mse: 30060435456.0000 - mae: 387.1713 - val_loss: 0.3608 - val_mse: 1259.2638 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3995 - mse: 1206.6106 - mae: 0.3995 - val_loss: 0.3605 - val_mse: 1259.2621 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3975 - mse: 1032.8046 - mae: 0.3975 - val_loss: 0.3602 - val_mse: 1259.2638 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1715 - mse: 30060435456.0000 - mae: 387.1712 - val_loss: 0.3599 - val_mse: 1259.2631 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.7092 - mse: 40080580608.0000 - mae: 580.7092 - val_loss: 0.3597 - val_mse: 1259.2637 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2663 - mse: 495.7610 - mae: 0.2663 - val_loss: 0.3594 - val_mse: 1259.2639 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1890 - mse: 30060435456.0000 - mae: 387.1891 - val_loss: 0.3593 - val_mse: 1259.2635 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4198 - mse: 1216.9867 - mae: 0.4198 - val_loss: 0.3592 - val_mse: 1259.2631 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2855 - mse: 587.3578 - mae: 0.2855 - val_loss: 0.3591 - val_mse: 1259.2649 - val_mae: 0.3591\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2357 - mse: 30060435456.0000 - mae: 387.2357 - val_loss: 0.3590 - val_mse: 1259.2642 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3053 - mse: 752.7278 - mae: 0.3053 - val_loss: 0.3588 - val_mse: 1259.2618 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8301 - mse: 20040292352.0000 - mae: 193.8302 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3284 - mse: 938.5959 - mae: 0.3284 - val_loss: 0.3587 - val_mse: 1259.2639 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9069 - mse: 35070509056.0000 - mae: 483.9079 - val_loss: 0.3702 - val_mse: 1259.2670 - val_mae: 0.3702\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3899 - mse: 1092.6954 - mae: 0.3899 - val_loss: 0.3615 - val_mse: 1259.2638 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3277 - mse: 843.1883 - mae: 0.3277 - val_loss: 0.3609 - val_mse: 1259.2655 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5120 - mse: 25050365952.0000 - mae: 290.5118 - val_loss: 0.3604 - val_mse: 1259.2649 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3495 - mse: 831.2579 - mae: 0.3495 - val_loss: 0.3602 - val_mse: 1259.2638 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4675 - mse: 25050365952.0000 - mae: 290.4676 - val_loss: 0.3599 - val_mse: 1259.2648 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4944 - mse: 25050365952.0000 - mae: 290.4945 - val_loss: 0.3598 - val_mse: 1259.2644 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3564 - mse: 849.0485 - mae: 0.3564 - val_loss: 0.3595 - val_mse: 1259.2627 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4686 - mse: 1509.1866 - mae: 0.4686 - val_loss: 0.3593 - val_mse: 1259.2627 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0729 - mse: 30060435456.0000 - mae: 387.0728 - val_loss: 0.3592 - val_mse: 1259.2633 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3509 - mse: 1123.4480 - mae: 0.3509 - val_loss: 0.3592 - val_mse: 1259.2639 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1493 - mse: 30060435456.0000 - mae: 387.1493 - val_loss: 0.3590 - val_mse: 1259.2648 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5303 - mse: 25050363904.0000 - mae: 290.5304 - val_loss: 0.3588 - val_mse: 1259.2644 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3743 - mse: 992.2876 - mae: 0.3743 - val_loss: 0.3588 - val_mse: 1259.2627 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5508 - mse: 25050365952.0000 - mae: 290.5509 - val_loss: 0.3586 - val_mse: 1259.2544 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.4460 - mse: 25050365952.0000 - mae: 290.4460 - val_loss: 0.3668 - val_mse: 1259.2931 - val_mae: 0.3668\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3801 - mse: 1096.6594 - mae: 0.3801 - val_loss: 0.3615 - val_mse: 1259.2661 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3716 - mse: 1041.2532 - mae: 0.3716 - val_loss: 0.3608 - val_mse: 1259.2642 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4553 - mse: 25050365952.0000 - mae: 290.4555 - val_loss: 0.3604 - val_mse: 1259.2633 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4758 - mse: 25050363904.0000 - mae: 290.4758 - val_loss: 0.3601 - val_mse: 1259.2646 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2887 - mse: 610.6187 - mae: 0.2887 - val_loss: 0.3599 - val_mse: 1259.2625 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3040 - mse: 635.0432 - mae: 0.3040 - val_loss: 0.3596 - val_mse: 1259.2616 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5587 - mse: 25050365952.0000 - mae: 290.5584 - val_loss: 0.3595 - val_mse: 1259.2638 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 774.0742 - mse: 50100727808.0000 - mae: 774.0741 - val_loss: 0.3593 - val_mse: 1259.2644 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2713 - mse: 540.8110 - mae: 0.2713 - val_loss: 0.3592 - val_mse: 1259.2629 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8418 - mse: 35070509056.0000 - mae: 483.8419 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4104 - mse: 1261.0339 - mae: 0.4104 - val_loss: 0.3590 - val_mse: 1259.2635 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4812 - mse: 25050365952.0000 - mae: 290.4811 - val_loss: 0.3589 - val_mse: 1259.2633 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3627 - mse: 1016.2786 - mae: 0.3627 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3100 - mse: 878.3526 - mae: 0.3100 - val_loss: 0.3586 - val_mse: 1259.2638 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.5441 - mse: 25050365952.0000 - mae: 290.5442 - val_loss: 0.3639 - val_mse: 1259.2974 - val_mae: 0.3639\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2883 - mse: 560.7518 - mae: 0.2883 - val_loss: 0.3614 - val_mse: 1259.2748 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6263 - mse: 40080580608.0000 - mae: 580.6264 - val_loss: 0.3607 - val_mse: 1259.2664 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3152 - mse: 762.9359 - mae: 0.3152 - val_loss: 0.3603 - val_mse: 1259.2657 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2717 - mse: 573.1028 - mae: 0.2717 - val_loss: 0.3601 - val_mse: 1259.2627 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9900 - mse: 35070513152.0000 - mae: 483.9899 - val_loss: 0.3598 - val_mse: 1259.2642 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9461 - mse: 35070509056.0000 - mae: 483.9470 - val_loss: 0.3596 - val_mse: 1259.2633 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3674 - mse: 883.7535 - mae: 0.3674 - val_loss: 0.3594 - val_mse: 1259.2637 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 774.0912 - mse: 50100731904.0000 - mae: 774.0917 - val_loss: 0.3592 - val_mse: 1259.2556 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2783 - mse: 610.1808 - mae: 0.2783 - val_loss: 0.3590 - val_mse: 1259.2638 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2856 - mse: 546.6623 - mae: 0.2856 - val_loss: 0.3590 - val_mse: 1259.2656 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5528 - mse: 25050365952.0000 - mae: 290.5529 - val_loss: 0.3588 - val_mse: 1259.2629 - val_mae: 0.3588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4003 - mse: 1176.3473 - mae: 0.4003 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8219 - mse: 35070509056.0000 - mae: 483.8220 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2894 - mse: 774.4661 - mae: 0.2894 - val_loss: 0.3585 - val_mse: 1259.2620 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4995 - mse: 25050363904.0000 - mae: 290.4994 - val_loss: 0.3665 - val_mse: 1259.2769 - val_mae: 0.3665\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3533 - mse: 989.3565 - mae: 0.3533 - val_loss: 0.3616 - val_mse: 1259.2671 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5179 - mse: 25050363904.0000 - mae: 290.5181 - val_loss: 0.3607 - val_mse: 1259.2646 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3296 - mse: 918.5656 - mae: 0.3296 - val_loss: 0.3603 - val_mse: 1259.2665 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3826 - mse: 1191.4744 - mae: 0.3826 - val_loss: 0.3599 - val_mse: 1259.2617 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4389 - mse: 25050365952.0000 - mae: 290.4389 - val_loss: 0.3597 - val_mse: 1259.2648 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4480 - mse: 25050363904.0000 - mae: 290.4480 - val_loss: 0.3594 - val_mse: 1259.2633 - val_mae: 0.3594\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3888 - mse: 1009.7509 - mae: 0.3888 - val_loss: 0.3593 - val_mse: 1259.2639 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4577 - mse: 25050365952.0000 - mae: 290.4579 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3420 - mse: 918.3677 - mae: 0.3420 - val_loss: 0.3590 - val_mse: 1259.2638 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4017 - mse: 1216.5427 - mae: 0.4017 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4615 - mse: 25050365952.0000 - mae: 290.4615 - val_loss: 0.3589 - val_mse: 1259.2618 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6330 - mse: 40080580608.0000 - mae: 580.6324 - val_loss: 0.3587 - val_mse: 1259.2625 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2949 - mse: 562.7787 - mae: 0.2949 - val_loss: 0.3586 - val_mse: 1259.2622 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3925 - mse: 1107.2997 - mae: 0.3925 - val_loss: 0.3585 - val_mse: 1259.2628 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.4102 - mse: 25050363904.0000 - mae: 290.4102 - val_loss: 0.3675 - val_mse: 1259.3094 - val_mae: 0.3675\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4242 - mse: 1271.4636 - mae: 0.4242 - val_loss: 0.3615 - val_mse: 1259.2664 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3538 - mse: 968.8971 - mae: 0.3538 - val_loss: 0.3608 - val_mse: 1259.2605 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4397 - mse: 25050363904.0000 - mae: 290.4396 - val_loss: 0.3604 - val_mse: 1259.2631 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.6477 - mse: 40080584704.0000 - mae: 580.6480 - val_loss: 0.4000 - val_mse: 1478.2615 - val_mae: 0.4000\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3136 - mse: 758.7874 - mae: 0.3136 - val_loss: 0.3599 - val_mse: 1259.2633 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4181 - mse: 1188.4561 - mae: 0.4181 - val_loss: 0.3598 - val_mse: 1259.2603 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.5583 - mse: 40080580608.0000 - mae: 580.5585 - val_loss: 0.3596 - val_mse: 1259.2635 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3722 - mse: 1035.2745 - mae: 0.3722 - val_loss: 0.3594 - val_mse: 1259.2644 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8803 - mse: 35070509056.0000 - mae: 483.8801 - val_loss: 0.3593 - val_mse: 1259.2643 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4097 - mse: 1212.7422 - mae: 0.4097 - val_loss: 0.3593 - val_mse: 1259.2620 - val_mae: 0.3593\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0737 - mse: 30060435456.0000 - mae: 387.0737 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5024 - mse: 25050365952.0000 - mae: 290.5023 - val_loss: 0.3590 - val_mse: 1259.2639 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3231 - mse: 783.5178 - mae: 0.3231 - val_loss: 0.3588 - val_mse: 1259.2637 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0884 - mse: 30060435456.0000 - mae: 387.0884 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.6226 - mse: 40080580608.0000 - mae: 580.6227 - val_loss: 0.3650 - val_mse: 1259.2740 - val_mae: 0.3650\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3549 - mse: 887.7285 - mae: 0.3549 - val_loss: 0.3614 - val_mse: 1259.2645 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5135 - mse: 50100727808.0000 - mae: 580.5136 - val_loss: 0.3609 - val_mse: 1259.2648 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4185 - mse: 1325.9451 - mae: 0.4185 - val_loss: 0.3604 - val_mse: 1259.2631 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3881 - mse: 1073.8076 - mae: 0.3881 - val_loss: 0.3600 - val_mse: 1259.2637 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4710 - mse: 25050363904.0000 - mae: 290.4709 - val_loss: 0.3599 - val_mse: 1259.2627 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1678 - mse: 30060439552.0000 - mae: 387.1678 - val_loss: 0.3596 - val_mse: 1259.2653 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3580 - mse: 882.6978 - mae: 0.3580 - val_loss: 0.3595 - val_mse: 1259.2631 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1729 - mse: 30060435456.0000 - mae: 387.1726 - val_loss: 0.3593 - val_mse: 1259.2634 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3393 - mse: 1041.9045 - mae: 0.3393 - val_loss: 0.3592 - val_mse: 1259.2612 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9015 - mse: 35070513152.0000 - mae: 483.9014 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3070 - mse: 763.2084 - mae: 0.3070 - val_loss: 0.3589 - val_mse: 1259.2634 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3825 - mse: 1015.9353 - mae: 0.3825 - val_loss: 0.3587 - val_mse: 1259.2649 - val_mae: 0.3587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1851 - mse: 30060435456.0000 - mae: 387.1852 - val_loss: 0.3587 - val_mse: 1259.2612 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3073 - mse: 799.5588 - mae: 0.3073 - val_loss: 0.3586 - val_mse: 1259.2640 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4697 - mse: 1385.0004 - mae: 0.4697 - val_loss: 0.3636 - val_mse: 1259.2793 - val_mae: 0.3636\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.0762 - mse: 30060439552.0000 - mae: 387.0763 - val_loss: 0.3614 - val_mse: 1259.2656 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4147 - mse: 1275.5269 - mae: 0.4147 - val_loss: 0.3609 - val_mse: 1259.2642 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1354 - mse: 30060435456.0000 - mae: 387.1357 - val_loss: 0.3604 - val_mse: 1259.2633 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4220 - mse: 1279.0361 - mae: 0.4220 - val_loss: 0.3601 - val_mse: 1259.2646 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1082 - mse: 30060439552.0000 - mae: 387.1083 - val_loss: 0.3598 - val_mse: 1259.2639 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4126 - mse: 1358.8798 - mae: 0.4126 - val_loss: 0.3597 - val_mse: 1259.2629 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5160 - mse: 40080580608.0000 - mae: 580.5165 - val_loss: 0.3595 - val_mse: 1259.2648 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.9838 - mse: 35070509056.0000 - mae: 483.9836 - val_loss: 0.3594 - val_mse: 1259.2639 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2965 - mse: 646.6230 - mae: 0.2965 - val_loss: 0.3591 - val_mse: 1259.2639 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5777 - mse: 40080580608.0000 - mae: 580.5777 - val_loss: 0.3590 - val_mse: 1259.2605 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3369 - mse: 849.6967 - mae: 0.3369 - val_loss: 0.3589 - val_mse: 1259.2629 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3996 - mse: 25050363904.0000 - mae: 290.3997 - val_loss: 0.3588 - val_mse: 1259.2604 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4869 - mse: 1641.1847 - mae: 0.4869 - val_loss: 0.3587 - val_mse: 1259.2650 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.5593 - mse: 25050365952.0000 - mae: 290.5593 - val_loss: 0.3586 - val_mse: 1259.2627 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.0989 - mse: 30060439552.0000 - mae: 387.0988 - val_loss: 0.3639 - val_mse: 1259.2687 - val_mae: 0.3639\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4377 - mse: 1293.1775 - mae: 0.4377 - val_loss: 0.3615 - val_mse: 1259.2660 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3574 - mse: 968.5605 - mae: 0.3574 - val_loss: 0.3608 - val_mse: 1259.2633 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.9038 - mse: 35070509056.0000 - mae: 483.9038 - val_loss: 0.3605 - val_mse: 1259.2642 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5227 - mse: 25050363904.0000 - mae: 290.5227 - val_loss: 0.3601 - val_mse: 1259.2629 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3224 - mse: 783.3823 - mae: 0.3224 - val_loss: 0.3598 - val_mse: 1259.2648 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3892 - mse: 1220.9758 - mae: 0.3892 - val_loss: 0.3597 - val_mse: 1259.2638 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.6993 - mse: 20040292352.0000 - mae: 193.6993 - val_loss: 0.3596 - val_mse: 1259.2642 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4445 - mse: 1323.0591 - mae: 0.4445 - val_loss: 0.3594 - val_mse: 1259.2645 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8229 - mse: 35070513152.0000 - mae: 483.8229 - val_loss: 0.3592 - val_mse: 1259.2634 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3864 - mse: 1230.1976 - mae: 0.3864 - val_loss: 0.3591 - val_mse: 1259.2631 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5898 - mse: 40080580608.0000 - mae: 580.5898 - val_loss: 0.3590 - val_mse: 1259.2640 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4260 - mse: 1315.3368 - mae: 0.4260 - val_loss: 0.3588 - val_mse: 1259.2638 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1093 - mse: 30060435456.0000 - mae: 387.1092 - val_loss: 0.3587 - val_mse: 1259.2627 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1126 - mse: 30060435456.0000 - mae: 387.1125 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2708 - mse: 426.4224 - mae: 0.2708 - val_loss: 0.3639 - val_mse: 1259.2805 - val_mae: 0.3639\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 774.1483 - mse: 50100727808.0000 - mae: 774.1484 - val_loss: 0.3614 - val_mse: 1259.2664 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3709 - mse: 1049.5944 - mae: 0.3709 - val_loss: 0.3608 - val_mse: 1259.2650 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7783 - mse: 20040292352.0000 - mae: 193.7783 - val_loss: 0.3603 - val_mse: 1259.2650 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4024 - mse: 1187.3025 - mae: 0.4024 - val_loss: 0.3600 - val_mse: 1259.2614 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1534 - mse: 30060435456.0000 - mae: 387.1535 - val_loss: 0.3598 - val_mse: 1259.2643 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.5212 - mse: 40080580608.0000 - mae: 580.5219 - val_loss: 0.3596 - val_mse: 1259.2635 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4335 - mse: 1378.7531 - mae: 0.4335 - val_loss: 0.3594 - val_mse: 1259.2622 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 580.6394 - mse: 40080580608.0000 - mae: 580.6398 - val_loss: 0.3592 - val_mse: 1259.2632 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2927 - mse: 664.7542 - mae: 0.2927 - val_loss: 0.3592 - val_mse: 1259.2612 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1587 - mse: 30060435456.0000 - mae: 387.1588 - val_loss: 0.3590 - val_mse: 1259.2598 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2963 - mse: 745.1987 - mae: 0.2963 - val_loss: 0.3588 - val_mse: 1259.2634 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3204 - mse: 758.1774 - mae: 0.3204 - val_loss: 0.3588 - val_mse: 1259.2598 - val_mae: 0.3588\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2954 - mse: 45090652160.0000 - mae: 677.2953 - val_loss: 0.3586 - val_mse: 1259.2653 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8135 - mse: 35070509056.0000 - mae: 483.8129 - val_loss: 0.3586 - val_mse: 1259.2638 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 580.6489 - mse: 50100727808.0000 - mae: 580.6489 - val_loss: 0.3656 - val_mse: 1259.2778 - val_mae: 0.3656\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3555 - mse: 982.2005 - mae: 0.3555 - val_loss: 0.3614 - val_mse: 1259.2632 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4193 - mse: 1152.6494 - mae: 0.4193 - val_loss: 0.3608 - val_mse: 1259.2639 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8941 - mse: 35070509056.0000 - mae: 483.8945 - val_loss: 0.3605 - val_mse: 1259.2640 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3634 - mse: 966.4426 - mae: 0.3634 - val_loss: 0.3601 - val_mse: 1259.2578 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1079 - mse: 30060439552.0000 - mae: 387.1080 - val_loss: 0.3598 - val_mse: 1259.2633 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7824 - mse: 20040292352.0000 - mae: 193.7824 - val_loss: 0.3596 - val_mse: 1259.2587 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3865 - mse: 1025.8921 - mae: 0.3865 - val_loss: 0.3596 - val_mse: 1259.2631 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3689 - mse: 1107.4421 - mae: 0.3689 - val_loss: 0.3594 - val_mse: 1259.2601 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1964 - mse: 30060435456.0000 - mae: 387.1965 - val_loss: 0.3593 - val_mse: 1259.2632 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8260 - mse: 20040292352.0000 - mae: 193.8261 - val_loss: 0.3591 - val_mse: 1259.2633 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3278 - mse: 846.7942 - mae: 0.3278 - val_loss: 0.3590 - val_mse: 1259.2598 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.7046 - mse: 20040292352.0000 - mae: 193.7045 - val_loss: 0.3590 - val_mse: 1259.2589 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4381 - mse: 1384.8523 - mae: 0.4381 - val_loss: 0.3588 - val_mse: 1259.2621 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2925 - mse: 661.0033 - mae: 0.2925 - val_loss: 0.3587 - val_mse: 1259.2598 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 290.4702 - mse: 25050365952.0000 - mae: 290.4703 - val_loss: 0.3637 - val_mse: 1259.3131 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3698 - mse: 942.0724 - mae: 0.3698 - val_loss: 0.3619 - val_mse: 1259.2935 - val_mae: 0.3619\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1792 - mse: 30060435456.0000 - mae: 387.1790 - val_loss: 0.3609 - val_mse: 1259.2620 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3555 - mse: 1014.6398 - mae: 0.3555 - val_loss: 0.3605 - val_mse: 1259.2644 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2911 - mse: 680.8196 - mae: 0.2911 - val_loss: 0.3602 - val_mse: 1259.2618 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 290.5624 - mse: 25050365952.0000 - mae: 290.5625 - val_loss: 0.3599 - val_mse: 1259.2627 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8959 - mse: 35070513152.0000 - mae: 483.8958 - val_loss: 0.3597 - val_mse: 1259.2596 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3325 - mse: 885.5421 - mae: 0.3325 - val_loss: 0.3595 - val_mse: 1259.2650 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4641 - mse: 1388.9207 - mae: 0.4641 - val_loss: 0.3594 - val_mse: 1259.2635 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 677.2118 - mse: 45090656256.0000 - mae: 677.2120 - val_loss: 0.3593 - val_mse: 1259.2654 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4526 - mse: 25050365952.0000 - mae: 290.4529 - val_loss: 0.3592 - val_mse: 1259.2622 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3658 - mse: 1076.1033 - mae: 0.3658 - val_loss: 0.3590 - val_mse: 1259.2633 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.7549 - mse: 20040292352.0000 - mae: 193.7548 - val_loss: 0.3589 - val_mse: 1259.2589 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3854 - mse: 1126.3585 - mae: 0.3854 - val_loss: 0.3588 - val_mse: 1259.2631 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4399 - mse: 25050365952.0000 - mae: 290.4401 - val_loss: 0.3588 - val_mse: 1259.2609 - val_mae: 0.3588\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 290.4661 - mse: 25050365952.0000 - mae: 290.4662 - val_loss: 0.3715 - val_mse: 1259.2872 - val_mae: 0.3715\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3167 - mse: 753.1110 - mae: 0.3167 - val_loss: 0.3617 - val_mse: 1259.2642 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2275 - mse: 30060439552.0000 - mae: 387.2276 - val_loss: 0.3609 - val_mse: 1259.2638 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3832 - mse: 1099.3185 - mae: 0.3832 - val_loss: 0.3603 - val_mse: 1259.2627 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4013 - mse: 1138.2803 - mae: 0.4013 - val_loss: 0.3600 - val_mse: 1259.2620 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4330 - mse: 25050363904.0000 - mae: 290.4331 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.8048 - mse: 20040290304.0000 - mae: 193.8048 - val_loss: 0.3596 - val_mse: 1259.2603 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3561 - mse: 854.3845 - mae: 0.3561 - val_loss: 0.3595 - val_mse: 1259.2645 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2415 - mse: 30060439552.0000 - mae: 387.2420 - val_loss: 0.3594 - val_mse: 1259.2642 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2886 - mse: 567.2831 - mae: 0.2886 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2524 - mse: 475.4764 - mae: 0.2524 - val_loss: 0.3590 - val_mse: 1259.2645 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.3066 - mse: 30060435456.0000 - mae: 387.3066 - val_loss: 0.3589 - val_mse: 1259.2633 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2751 - mse: 672.6934 - mae: 0.2751 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2331 - mse: 30060435456.0000 - mae: 387.2332 - val_loss: 0.3587 - val_mse: 1259.2653 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4479 - mse: 25050365952.0000 - mae: 290.4479 - val_loss: 0.3586 - val_mse: 1259.2637 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 0.3311 - mse: 811.9411 - mae: 0.3311 - val_loss: 0.3637 - val_mse: 1259.2715 - val_mae: 0.3637\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9336 - mse: 35070509056.0000 - mae: 483.9341 - val_loss: 0.3615 - val_mse: 1259.2650 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3839 - mse: 1212.0643 - mae: 0.3839 - val_loss: 0.3610 - val_mse: 1259.2638 - val_mae: 0.3610\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4159 - mse: 25050365952.0000 - mae: 290.4159 - val_loss: 0.3605 - val_mse: 1259.2650 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3514 - mse: 951.8302 - mae: 0.3514 - val_loss: 0.3601 - val_mse: 1259.2638 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2033 - mse: 30060439552.0000 - mae: 387.2032 - val_loss: 0.3599 - val_mse: 1259.2633 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3093 - mse: 743.0696 - mae: 0.3093 - val_loss: 0.3597 - val_mse: 1259.2620 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 193.7539 - mse: 20040292352.0000 - mae: 193.7539 - val_loss: 0.3596 - val_mse: 1259.2638 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5013 - mse: 25050365952.0000 - mae: 290.5014 - val_loss: 0.3594 - val_mse: 1259.2614 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3366 - mse: 782.8199 - mae: 0.3366 - val_loss: 0.3593 - val_mse: 1259.2651 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3389 - mse: 904.9390 - mae: 0.3389 - val_loss: 0.3592 - val_mse: 1259.2634 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2114 - mse: 30060439552.0000 - mae: 387.2113 - val_loss: 0.3591 - val_mse: 1259.2631 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.6678 - mse: 20040290304.0000 - mae: 193.6678 - val_loss: 0.3590 - val_mse: 1259.2655 - val_mae: 0.3590\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4269 - mse: 1279.1123 - mae: 0.4269 - val_loss: 0.3589 - val_mse: 1259.2632 - val_mae: 0.3589\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3830 - mse: 1110.1039 - mae: 0.3830 - val_loss: 0.3587 - val_mse: 1259.2648 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 15ms/step - loss: 387.0839 - mse: 30060435456.0000 - mae: 387.0841 - val_loss: 0.3626 - val_mse: 1259.2919 - val_mae: 0.3626\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4500 - mse: 1382.5822 - mae: 0.4500 - val_loss: 0.3613 - val_mse: 1259.2651 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2747 - mse: 499.0974 - mae: 0.2747 - val_loss: 0.3606 - val_mse: 1259.2656 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 677.3892 - mse: 45090652160.0000 - mae: 677.3895 - val_loss: 0.3602 - val_mse: 1259.2648 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2649 - mse: 30060435456.0000 - mae: 387.2649 - val_loss: 0.3599 - val_mse: 1259.2614 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2954 - mse: 764.6771 - mae: 0.2954 - val_loss: 0.3596 - val_mse: 1259.2638 - val_mae: 0.3596\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 14ms/step - loss: 0.4009 - mse: 1217.9014 - mae: 0.4009 - val_loss: 0.3594 - val_mse: 1259.2639 - val_mae: 0.3594\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4283 - mse: 25050365952.0000 - mae: 290.4282 - val_loss: 0.3592 - val_mse: 1259.2631 - val_mae: 0.3592\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.2954 - mse: 785.7999 - mae: 0.2954 - val_loss: 0.3591 - val_mse: 1259.2618 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.7930 - mse: 20040290304.0000 - mae: 193.7931 - val_loss: 0.3590 - val_mse: 1259.2606 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1521 - mse: 30060435456.0000 - mae: 387.1521 - val_loss: 0.3588 - val_mse: 1259.2628 - val_mae: 0.3588\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3755 - mse: 1081.0941 - mae: 0.3755 - val_loss: 0.3587 - val_mse: 1259.2595 - val_mae: 0.3587\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3362 - mse: 955.0312 - mae: 0.3362 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4678 - mse: 25050363904.0000 - mae: 290.4678 - val_loss: 0.3584 - val_mse: 1259.2603 - val_mae: 0.3584\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1245 - mse: 30060439552.0000 - mae: 387.1245 - val_loss: 0.3584 - val_mse: 1259.2648 - val_mae: 0.3584\n",
      "Global run /tmp/snapshot/threshold_3/\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3975 - mse: 1130.4891 - mae: 0.3975 - val_loss: 0.3643 - val_mse: 1259.2969 - val_mae: 0.3643\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1730 - mse: 30060435456.0000 - mae: 387.1731 - val_loss: 0.3613 - val_mse: 1259.2650 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2474 - mse: 30060435456.0000 - mae: 387.2474 - val_loss: 0.3607 - val_mse: 1259.2665 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2997 - mse: 834.0411 - mae: 0.2997 - val_loss: 0.3604 - val_mse: 1259.2651 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9054 - mse: 35070509056.0000 - mae: 483.9066 - val_loss: 0.3601 - val_mse: 1259.2640 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3710 - mse: 962.3752 - mae: 0.3710 - val_loss: 0.3598 - val_mse: 1259.2651 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3312 - mse: 940.8632 - mae: 0.3312 - val_loss: 0.3596 - val_mse: 1259.2646 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5263 - mse: 25050365952.0000 - mae: 290.5263 - val_loss: 0.3595 - val_mse: 1259.2625 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4305 - mse: 1265.1741 - mae: 0.4305 - val_loss: 0.3593 - val_mse: 1259.2642 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8199 - mse: 35070509056.0000 - mae: 483.8201 - val_loss: 0.3592 - val_mse: 1259.2644 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3025 - mse: 674.5823 - mae: 0.3025 - val_loss: 0.3590 - val_mse: 1259.2637 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5085 - mse: 25050363904.0000 - mae: 290.5087 - val_loss: 0.3588 - val_mse: 1259.2626 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3409 - mse: 781.1627 - mae: 0.3409 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3395 - mse: 45090652160.0000 - mae: 677.3395 - val_loss: 0.3586 - val_mse: 1259.2621 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3761 - mse: 929.0038 - mae: 0.3761 - val_loss: 0.3586 - val_mse: 1259.2621 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.6112 - mse: 40080580608.0000 - mae: 580.6115 - val_loss: 0.3671 - val_mse: 1259.2760 - val_mae: 0.3671\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3865 - mse: 1028.4658 - mae: 0.3865 - val_loss: 0.3617 - val_mse: 1259.2656 - val_mae: 0.3617\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3834 - mse: 1122.8058 - mae: 0.3834 - val_loss: 0.3609 - val_mse: 1259.2644 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8753 - mse: 35070509056.0000 - mae: 483.8755 - val_loss: 0.3605 - val_mse: 1259.2640 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.2827 - mse: 45090652160.0000 - mae: 677.2828 - val_loss: 0.3602 - val_mse: 1259.2628 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3969 - mse: 1103.6332 - mae: 0.3969 - val_loss: 0.3599 - val_mse: 1259.2633 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4815 - mse: 25050365952.0000 - mae: 290.4814 - val_loss: 0.3596 - val_mse: 1259.2622 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3274 - mse: 981.9157 - mae: 0.3274 - val_loss: 0.3595 - val_mse: 1259.2649 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1810 - mse: 30060439552.0000 - mae: 387.1808 - val_loss: 0.3593 - val_mse: 1259.2650 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3639 - mse: 948.7903 - mae: 0.3639 - val_loss: 0.3591 - val_mse: 1259.2635 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3017 - mse: 779.7828 - mae: 0.3017 - val_loss: 0.3590 - val_mse: 1259.2629 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2049 - mse: 30060435456.0000 - mae: 387.2048 - val_loss: 0.3588 - val_mse: 1259.2598 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9396 - mse: 35070509056.0000 - mae: 483.9395 - val_loss: 0.3587 - val_mse: 1259.2629 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3170 - mse: 697.1531 - mae: 0.3170 - val_loss: 0.3587 - val_mse: 1259.2620 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2372 - mse: 490.2591 - mae: 0.2372 - val_loss: 0.3585 - val_mse: 1259.2621 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3793 - mse: 928.4888 - mae: 0.3793 - val_loss: 0.3695 - val_mse: 1259.2793 - val_mae: 0.3695\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9534 - mse: 35070509056.0000 - mae: 483.9538 - val_loss: 0.3616 - val_mse: 1259.2722 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4841 - mse: 25050365952.0000 - mae: 290.4841 - val_loss: 0.3608 - val_mse: 1259.2628 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3078 - mse: 821.6444 - mae: 0.3078 - val_loss: 0.3603 - val_mse: 1259.2654 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3556 - mse: 1058.6713 - mae: 0.3556 - val_loss: 0.3601 - val_mse: 1259.2625 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1833 - mse: 40080580608.0000 - mae: 387.1834 - val_loss: 0.3598 - val_mse: 1259.2655 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4685 - mse: 25050365952.0000 - mae: 290.4685 - val_loss: 0.3596 - val_mse: 1259.2644 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3444 - mse: 845.1125 - mae: 0.3444 - val_loss: 0.3595 - val_mse: 1259.2643 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8390 - mse: 35070509056.0000 - mae: 483.8394 - val_loss: 0.3593 - val_mse: 1259.2646 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3949 - mse: 1164.1956 - mae: 0.3949 - val_loss: 0.3591 - val_mse: 1259.2645 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5209 - mse: 25050365952.0000 - mae: 290.5211 - val_loss: 0.3590 - val_mse: 1259.2659 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3542 - mse: 916.2979 - mae: 0.3542 - val_loss: 0.3589 - val_mse: 1259.2638 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4043 - mse: 1122.2408 - mae: 0.4043 - val_loss: 0.3587 - val_mse: 1259.2631 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7222 - mse: 20040294400.0000 - mae: 193.7223 - val_loss: 0.3586 - val_mse: 1259.2646 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9515 - mse: 35070509056.0000 - mae: 483.9510 - val_loss: 0.3585 - val_mse: 1259.2620 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2358 - mse: 30060435456.0000 - mae: 387.2357 - val_loss: 0.3644 - val_mse: 1259.2673 - val_mae: 0.3644\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3368 - mse: 829.9406 - mae: 0.3368 - val_loss: 0.3613 - val_mse: 1259.2662 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3585 - mse: 948.4700 - mae: 0.3585 - val_loss: 0.3607 - val_mse: 1259.2657 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8857 - mse: 35070509056.0000 - mae: 483.8859 - val_loss: 0.3603 - val_mse: 1259.2576 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3911 - mse: 1210.8405 - mae: 0.3911 - val_loss: 0.3601 - val_mse: 1259.2659 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8248 - mse: 35070509056.0000 - mae: 483.8252 - val_loss: 0.3598 - val_mse: 1259.2645 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6893 - mse: 20040290304.0000 - mae: 193.6893 - val_loss: 0.3596 - val_mse: 1259.2645 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3728 - mse: 1079.7355 - mae: 0.3728 - val_loss: 0.3594 - val_mse: 1259.2646 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2259 - mse: 30060439552.0000 - mae: 387.2259 - val_loss: 0.3592 - val_mse: 1259.2633 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2481 - mse: 557.0730 - mae: 0.2481 - val_loss: 0.3590 - val_mse: 1259.2633 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4315 - mse: 1316.6681 - mae: 0.4315 - val_loss: 0.3590 - val_mse: 1259.2621 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1157 - mse: 30060435456.0000 - mae: 387.1157 - val_loss: 0.3588 - val_mse: 1259.2633 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1579 - mse: 30060435456.0000 - mae: 387.1579 - val_loss: 0.3586 - val_mse: 1259.2635 - val_mae: 0.3586\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3739 - mse: 975.4783 - mae: 0.3739 - val_loss: 0.3586 - val_mse: 1259.2633 - val_mae: 0.3586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4561 - mse: 25050365952.0000 - mae: 290.4562 - val_loss: 0.3585 - val_mse: 1259.2631 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2493 - mse: 407.0320 - mae: 0.2493 - val_loss: 0.3628 - val_mse: 1259.3077 - val_mae: 0.3628\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8892 - mse: 20040290304.0000 - mae: 193.8892 - val_loss: 0.3615 - val_mse: 1259.2656 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3582 - mse: 928.4095 - mae: 0.3582 - val_loss: 0.3607 - val_mse: 1259.2633 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1970 - mse: 30060435456.0000 - mae: 387.1971 - val_loss: 0.3603 - val_mse: 1259.2640 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4678 - mse: 25050365952.0000 - mae: 290.4678 - val_loss: 0.3601 - val_mse: 1259.2627 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4108 - mse: 1162.2456 - mae: 0.4108 - val_loss: 0.3598 - val_mse: 1259.2635 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0971 - mse: 30060435456.0000 - mae: 387.0973 - val_loss: 0.3596 - val_mse: 1259.2633 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4758 - mse: 1351.1591 - mae: 0.4758 - val_loss: 0.3595 - val_mse: 1259.2635 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3565 - mse: 951.8718 - mae: 0.3565 - val_loss: 0.3593 - val_mse: 1259.2633 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1800 - mse: 30060439552.0000 - mae: 387.1801 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3653 - mse: 1039.2228 - mae: 0.3653 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4462 - mse: 25050363904.0000 - mae: 290.4463 - val_loss: 0.3590 - val_mse: 1259.2616 - val_mae: 0.3590\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8250 - mse: 20040290304.0000 - mae: 193.8251 - val_loss: 0.3589 - val_mse: 1259.2614 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3283 - mse: 995.1995 - mae: 0.3283 - val_loss: 0.3587 - val_mse: 1259.2631 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2740 - mse: 532.8683 - mae: 0.2740 - val_loss: 0.3586 - val_mse: 1259.2623 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3099 - mse: 711.3542 - mae: 0.3099 - val_loss: 0.3641 - val_mse: 1259.3000 - val_mae: 0.3641\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2311 - mse: 30060435456.0000 - mae: 387.2311 - val_loss: 0.3614 - val_mse: 1259.2654 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3456 - mse: 849.4726 - mae: 0.3456 - val_loss: 0.3607 - val_mse: 1259.2655 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9447 - mse: 35070509056.0000 - mae: 483.9452 - val_loss: 0.3603 - val_mse: 1259.2657 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3719 - mse: 998.6789 - mae: 0.3719 - val_loss: 0.3600 - val_mse: 1259.2649 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1800 - mse: 30060435456.0000 - mae: 387.1799 - val_loss: 0.3597 - val_mse: 1259.2633 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1437 - mse: 30060435456.0000 - mae: 387.1440 - val_loss: 0.3596 - val_mse: 1259.2616 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3981 - mse: 1253.5077 - mae: 0.3981 - val_loss: 0.3594 - val_mse: 1259.2620 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4036 - mse: 1289.1893 - mae: 0.4036 - val_loss: 0.3592 - val_mse: 1259.2631 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4083 - mse: 25050365952.0000 - mae: 290.4081 - val_loss: 0.3590 - val_mse: 1259.2635 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5155 - mse: 25050365952.0000 - mae: 290.5154 - val_loss: 0.3589 - val_mse: 1259.2609 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2794 - mse: 509.5589 - mae: 0.2794 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3676 - mse: 1034.6357 - mae: 0.3676 - val_loss: 0.3587 - val_mse: 1259.2635 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4566 - mse: 25050365952.0000 - mae: 290.4567 - val_loss: 0.3587 - val_mse: 1259.2625 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4147 - mse: 25050365952.0000 - mae: 290.4147 - val_loss: 0.3585 - val_mse: 1259.2627 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3074 - mse: 643.6511 - mae: 0.3074 - val_loss: 0.3642 - val_mse: 1259.2921 - val_mae: 0.3642\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.8341 - mse: 20040294400.0000 - mae: 193.8341 - val_loss: 0.3613 - val_mse: 1259.2695 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4466 - mse: 25050363904.0000 - mae: 290.4467 - val_loss: 0.3607 - val_mse: 1259.2665 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3603 - mse: 966.8435 - mae: 0.3603 - val_loss: 0.3602 - val_mse: 1259.2627 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.5673 - mse: 25050363904.0000 - mae: 290.5674 - val_loss: 0.3600 - val_mse: 1259.2640 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2623 - mse: 493.4451 - mae: 0.2623 - val_loss: 0.3597 - val_mse: 1259.2626 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3695 - mse: 25050363904.0000 - mae: 290.3696 - val_loss: 0.3596 - val_mse: 1259.2631 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4062 - mse: 1224.4630 - mae: 0.4062 - val_loss: 0.3593 - val_mse: 1259.2635 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8032 - mse: 35070509056.0000 - mae: 483.8030 - val_loss: 0.3593 - val_mse: 1259.2612 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4531 - mse: 1448.4194 - mae: 0.4531 - val_loss: 0.3591 - val_mse: 1259.2642 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8827 - mse: 35070509056.0000 - mae: 483.8825 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3483 - mse: 1032.9458 - mae: 0.3483 - val_loss: 0.3589 - val_mse: 1259.2635 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4172 - mse: 25050365952.0000 - mae: 290.4168 - val_loss: 0.3588 - val_mse: 1259.2610 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4080 - mse: 1313.1210 - mae: 0.4080 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3445 - mse: 1094.6561 - mae: 0.3445 - val_loss: 0.3587 - val_mse: 1259.2612 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4027 - mse: 25050363904.0000 - mae: 290.4027 - val_loss: 0.3692 - val_mse: 1259.2802 - val_mae: 0.3692\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4254 - mse: 1341.4877 - mae: 0.4254 - val_loss: 0.3615 - val_mse: 1259.2667 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4390 - mse: 1377.6298 - mae: 0.4390 - val_loss: 0.3608 - val_mse: 1259.2616 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3936 - mse: 25050365952.0000 - mae: 290.3935 - val_loss: 0.3603 - val_mse: 1259.2676 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4684 - mse: 25050365952.0000 - mae: 290.4683 - val_loss: 0.3600 - val_mse: 1259.2622 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3939 - mse: 1102.9609 - mae: 0.3939 - val_loss: 0.3599 - val_mse: 1259.2650 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6148 - mse: 40080580608.0000 - mae: 580.6144 - val_loss: 0.3597 - val_mse: 1259.2621 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3131 - mse: 759.0122 - mae: 0.3131 - val_loss: 0.3595 - val_mse: 1259.2633 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2881 - mse: 659.6415 - mae: 0.2881 - val_loss: 0.3594 - val_mse: 1259.2628 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3415 - mse: 45090656256.0000 - mae: 677.3417 - val_loss: 0.3593 - val_mse: 1259.2638 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4668 - mse: 25050365952.0000 - mae: 290.4669 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3604 - mse: 1082.2006 - mae: 0.3604 - val_loss: 0.3589 - val_mse: 1259.2631 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1588 - mse: 30060435456.0000 - mae: 387.1591 - val_loss: 0.3589 - val_mse: 1259.2620 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3313 - mse: 885.1057 - mae: 0.3313 - val_loss: 0.3588 - val_mse: 1259.2604 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9849 - mse: 35070509056.0000 - mae: 483.9856 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3820 - mse: 1109.8750 - mae: 0.3820 - val_loss: 0.3636 - val_mse: 1259.2819 - val_mae: 0.3636\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4663 - mse: 25050365952.0000 - mae: 290.4664 - val_loss: 0.3614 - val_mse: 1259.2633 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4195 - mse: 1281.6451 - mae: 0.4195 - val_loss: 0.3608 - val_mse: 1259.2648 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.5026 - mse: 40080580608.0000 - mae: 580.5029 - val_loss: 0.3604 - val_mse: 1259.2637 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4716 - mse: 25050365952.0000 - mae: 290.4716 - val_loss: 0.3601 - val_mse: 1259.2635 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3611 - mse: 1039.2645 - mae: 0.3611 - val_loss: 0.3598 - val_mse: 1259.2648 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2648 - mse: 537.9726 - mae: 0.2648 - val_loss: 0.3596 - val_mse: 1259.2632 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4891 - mse: 25050365952.0000 - mae: 290.4892 - val_loss: 0.3594 - val_mse: 1259.2578 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8652 - mse: 35070509056.0000 - mae: 483.8651 - val_loss: 0.3592 - val_mse: 1259.2654 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3384 - mse: 904.8787 - mae: 0.3384 - val_loss: 0.3591 - val_mse: 1259.2648 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3644 - mse: 1071.5364 - mae: 0.3644 - val_loss: 0.3590 - val_mse: 1259.2651 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7339 - mse: 20040292352.0000 - mae: 193.7339 - val_loss: 0.3589 - val_mse: 1259.2631 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.3809 - mse: 25050365952.0000 - mae: 290.3810 - val_loss: 0.3588 - val_mse: 1259.2639 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4350 - mse: 1381.9803 - mae: 0.4350 - val_loss: 0.3986 - val_mse: 1478.2644 - val_mae: 0.3986\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3685 - mse: 1145.2507 - mae: 0.3685 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.4484 - mse: 1420.7666 - mae: 0.4484 - val_loss: 0.3629 - val_mse: 1259.2823 - val_mae: 0.3629\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4224 - mse: 25050363904.0000 - mae: 290.4225 - val_loss: 0.3613 - val_mse: 1259.2645 - val_mae: 0.3613\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3107 - mse: 695.0097 - mae: 0.3107 - val_loss: 0.3607 - val_mse: 1259.2638 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2112 - mse: 30060435456.0000 - mae: 387.2112 - val_loss: 0.3604 - val_mse: 1259.2655 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4589 - mse: 25050365952.0000 - mae: 290.4587 - val_loss: 0.3601 - val_mse: 1259.2616 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3338 - mse: 1013.8351 - mae: 0.3338 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7891 - mse: 20040290304.0000 - mae: 193.7891 - val_loss: 0.3596 - val_mse: 1259.2627 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3039 - mse: 822.7805 - mae: 0.3039 - val_loss: 0.3594 - val_mse: 1259.2626 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.5181 - mse: 1579.9036 - mae: 0.5181 - val_loss: 0.3593 - val_mse: 1259.2633 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6829 - mse: 20040290304.0000 - mae: 193.6829 - val_loss: 0.3591 - val_mse: 1259.2631 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3326 - mse: 829.3843 - mae: 0.3326 - val_loss: 0.3590 - val_mse: 1259.2629 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7860 - mse: 20040294400.0000 - mae: 193.7860 - val_loss: 0.3588 - val_mse: 1259.2615 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8622 - mse: 35070509056.0000 - mae: 483.8627 - val_loss: 0.3587 - val_mse: 1259.2623 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3652 - mse: 1037.2264 - mae: 0.3652 - val_loss: 0.3587 - val_mse: 1259.2642 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3599 - mse: 1050.3478 - mae: 0.3599 - val_loss: 0.3585 - val_mse: 1259.2614 - val_mae: 0.3585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.9066 - mse: 20040290304.0000 - mae: 193.9065 - val_loss: 0.3664 - val_mse: 1259.3051 - val_mae: 0.3664\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2876 - mse: 566.3499 - mae: 0.2876 - val_loss: 0.3614 - val_mse: 1259.2684 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2549 - mse: 30060435456.0000 - mae: 387.2549 - val_loss: 0.3606 - val_mse: 1259.2635 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3277 - mse: 774.2752 - mae: 0.3277 - val_loss: 0.3602 - val_mse: 1259.2638 - val_mae: 0.3602\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4547 - mse: 1387.5267 - mae: 0.4547 - val_loss: 0.3599 - val_mse: 1259.2618 - val_mae: 0.3599\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.6830 - mse: 20040290304.0000 - mae: 193.6830 - val_loss: 0.3597 - val_mse: 1259.2642 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6016 - mse: 40080580608.0000 - mae: 580.6016 - val_loss: 0.3595 - val_mse: 1259.2639 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3683 - mse: 1117.9515 - mae: 0.3683 - val_loss: 0.3592 - val_mse: 1259.2632 - val_mae: 0.3592\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.8521 - mse: 35070509056.0000 - mae: 483.8524 - val_loss: 0.3591 - val_mse: 1259.2644 - val_mae: 0.3591\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4142 - mse: 1279.4001 - mae: 0.4142 - val_loss: 0.3590 - val_mse: 1259.2592 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3514 - mse: 1019.7479 - mae: 0.3514 - val_loss: 0.3588 - val_mse: 1259.2642 - val_mae: 0.3588\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7398 - mse: 20040292352.0000 - mae: 193.7398 - val_loss: 0.3588 - val_mse: 1259.2628 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4309 - mse: 25050363904.0000 - mae: 290.4307 - val_loss: 0.3586 - val_mse: 1259.2637 - val_mae: 0.3586\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.4304 - mse: 1221.5281 - mae: 0.4304 - val_loss: 0.3585 - val_mse: 1259.2572 - val_mae: 0.3585\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.7978 - mse: 35070509056.0000 - mae: 483.7978 - val_loss: 0.3585 - val_mse: 1259.2637 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.5003 - mse: 25050365952.0000 - mae: 290.5004 - val_loss: 0.3657 - val_mse: 1259.3132 - val_mae: 0.3657\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3298 - mse: 840.5535 - mae: 0.3298 - val_loss: 0.3616 - val_mse: 1259.2681 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3157 - mse: 851.1665 - mae: 0.3157 - val_loss: 0.3609 - val_mse: 1259.2672 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9142 - mse: 35070513152.0000 - mae: 483.9149 - val_loss: 0.3603 - val_mse: 1259.2639 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3487 - mse: 922.7293 - mae: 0.3487 - val_loss: 0.3600 - val_mse: 1259.2648 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.2160 - mse: 30060435456.0000 - mae: 387.2159 - val_loss: 0.3598 - val_mse: 1259.2631 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2936 - mse: 741.8701 - mae: 0.2936 - val_loss: 0.3597 - val_mse: 1259.2654 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6795 - mse: 40080580608.0000 - mae: 580.6797 - val_loss: 0.3594 - val_mse: 1259.2638 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4323 - mse: 25050365952.0000 - mae: 290.4322 - val_loss: 0.3593 - val_mse: 1259.2655 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3941 - mse: 1158.8582 - mae: 0.3941 - val_loss: 0.3591 - val_mse: 1259.2646 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.2561 - mse: 620.2331 - mae: 0.2561 - val_loss: 0.3590 - val_mse: 1259.2653 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 677.3839 - mse: 45090652160.0000 - mae: 677.3837 - val_loss: 0.3589 - val_mse: 1259.2605 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 193.7664 - mse: 20040290304.0000 - mae: 193.7664 - val_loss: 0.3587 - val_mse: 1259.2623 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3469 - mse: 1038.4481 - mae: 0.3469 - val_loss: 0.3586 - val_mse: 1259.2642 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 580.6666 - mse: 40080580608.0000 - mae: 580.6661 - val_loss: 0.3586 - val_mse: 1259.2631 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 193.7658 - mse: 20040290304.0000 - mae: 193.7658 - val_loss: 0.3692 - val_mse: 1259.3055 - val_mae: 0.3692\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3880 - mse: 1094.5817 - mae: 0.3880 - val_loss: 0.3615 - val_mse: 1259.2782 - val_mae: 0.3615\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4894 - mse: 25050363904.0000 - mae: 290.4894 - val_loss: 0.3608 - val_mse: 1259.2642 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3063 - mse: 728.5093 - mae: 0.3063 - val_loss: 0.3604 - val_mse: 1259.2625 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3706 - mse: 1099.0950 - mae: 0.3706 - val_loss: 0.3602 - val_mse: 1259.2638 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4620 - mse: 25050363904.0000 - mae: 290.4618 - val_loss: 0.3598 - val_mse: 1259.2625 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4755 - mse: 1412.2665 - mae: 0.4755 - val_loss: 0.3596 - val_mse: 1259.2615 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.0475 - mse: 30060439552.0000 - mae: 387.0474 - val_loss: 0.3594 - val_mse: 1259.2627 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3966 - mse: 1283.4036 - mae: 0.3966 - val_loss: 0.3593 - val_mse: 1259.2620 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8703 - mse: 35070509056.0000 - mae: 483.8700 - val_loss: 0.3591 - val_mse: 1259.2643 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.4003 - mse: 1193.1086 - mae: 0.4003 - val_loss: 0.3591 - val_mse: 1259.2626 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 290.4366 - mse: 25050365952.0000 - mae: 290.4366 - val_loss: 0.3589 - val_mse: 1259.2642 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3254 - mse: 924.4550 - mae: 0.3254 - val_loss: 0.3588 - val_mse: 1259.2599 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.5204 - mse: 25050365952.0000 - mae: 290.5205 - val_loss: 0.3587 - val_mse: 1259.2610 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 387.1175 - mse: 30060439552.0000 - mae: 387.1178 - val_loss: 0.3586 - val_mse: 1259.2646 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4087 - mse: 1247.5597 - mae: 0.4087 - val_loss: 0.3635 - val_mse: 1259.2775 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.8260 - mse: 35070509056.0000 - mae: 483.8266 - val_loss: 0.3614 - val_mse: 1259.2665 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2934 - mse: 775.2604 - mae: 0.2934 - val_loss: 0.3608 - val_mse: 1259.2626 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 290.4751 - mse: 25050365952.0000 - mae: 290.4749 - val_loss: 0.3603 - val_mse: 1259.2642 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3898 - mse: 1065.8260 - mae: 0.3898 - val_loss: 0.3600 - val_mse: 1259.2649 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4055 - mse: 25050363904.0000 - mae: 290.4056 - val_loss: 0.3598 - val_mse: 1259.2650 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 290.5353 - mse: 25050365952.0000 - mae: 290.5355 - val_loss: 0.3596 - val_mse: 1259.2655 - val_mae: 0.3596\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3250 - mse: 775.2901 - mae: 0.3250 - val_loss: 0.3595 - val_mse: 1259.2648 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3466 - mse: 900.3578 - mae: 0.3466 - val_loss: 0.3594 - val_mse: 1259.2621 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4754 - mse: 25050363904.0000 - mae: 290.4756 - val_loss: 0.3592 - val_mse: 1259.2611 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1882 - mse: 30060439552.0000 - mae: 387.1881 - val_loss: 0.3590 - val_mse: 1259.2627 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3555 - mse: 1034.8777 - mae: 0.3555 - val_loss: 0.3589 - val_mse: 1259.2629 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 483.9030 - mse: 35070513152.0000 - mae: 483.9030 - val_loss: 0.3587 - val_mse: 1259.2634 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3200 - mse: 758.6515 - mae: 0.3200 - val_loss: 0.3587 - val_mse: 1259.2621 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2971 - mse: 806.9387 - mae: 0.2971 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 11s 16ms/step - loss: 0.4197 - mse: 1226.6033 - mae: 0.4197 - val_loss: 0.3627 - val_mse: 1259.2843 - val_mae: 0.3627\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1452 - mse: 30060435456.0000 - mae: 387.1452 - val_loss: 0.3612 - val_mse: 1259.2644 - val_mae: 0.3612\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3790 - mse: 1030.3254 - mae: 0.3790 - val_loss: 0.3608 - val_mse: 1259.2649 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4632 - mse: 25050365952.0000 - mae: 290.4633 - val_loss: 0.3605 - val_mse: 1259.2662 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3760 - mse: 1062.4526 - mae: 0.3760 - val_loss: 0.3600 - val_mse: 1259.2637 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2454 - mse: 30060439552.0000 - mae: 387.2454 - val_loss: 0.3598 - val_mse: 1259.2638 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8145 - mse: 35070513152.0000 - mae: 483.8145 - val_loss: 0.3598 - val_mse: 1259.2606 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4364 - mse: 1370.5021 - mae: 0.4364 - val_loss: 0.3594 - val_mse: 1259.2649 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.8391 - mse: 20040294400.0000 - mae: 193.8391 - val_loss: 0.3594 - val_mse: 1259.2617 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3355 - mse: 941.1269 - mae: 0.3355 - val_loss: 0.3592 - val_mse: 1259.2581 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.8091 - mse: 20040290304.0000 - mae: 193.8090 - val_loss: 0.3590 - val_mse: 1259.2604 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2615 - mse: 567.1819 - mae: 0.2615 - val_loss: 0.3589 - val_mse: 1259.2640 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3743 - mse: 1007.2458 - mae: 0.3743 - val_loss: 0.3588 - val_mse: 1259.2622 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2308 - mse: 30060435456.0000 - mae: 387.2311 - val_loss: 0.3587 - val_mse: 1259.2616 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 193.7176 - mse: 20040292352.0000 - mae: 193.7175 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3212 - mse: 796.1123 - mae: 0.3212 - val_loss: 0.3671 - val_mse: 1259.2764 - val_mae: 0.3671\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.1863 - mse: 30060435456.0000 - mae: 387.1862 - val_loss: 0.3616 - val_mse: 1259.2655 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3187 - mse: 891.1857 - mae: 0.3187 - val_loss: 0.3609 - val_mse: 1259.2645 - val_mae: 0.3609\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1765 - mse: 30060435456.0000 - mae: 387.1763 - val_loss: 0.3605 - val_mse: 1259.2599 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 7s 10ms/step - loss: 0.3248 - mse: 797.1160 - mae: 0.3248 - val_loss: 0.3601 - val_mse: 1259.2622 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 387.2067 - mse: 30060435456.0000 - mae: 387.2066 - val_loss: 0.3599 - val_mse: 1259.2667 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4554 - mse: 1472.5614 - mae: 0.4554 - val_loss: 0.3597 - val_mse: 1259.2638 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3936 - mse: 25050363904.0000 - mae: 290.3934 - val_loss: 0.3595 - val_mse: 1259.2653 - val_mae: 0.3595\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3821 - mse: 1187.1720 - mae: 0.3821 - val_loss: 0.3594 - val_mse: 1259.2660 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4632 - mse: 25050363904.0000 - mae: 290.4633 - val_loss: 0.3591 - val_mse: 1259.2622 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.5158 - mse: 25050365952.0000 - mae: 290.5158 - val_loss: 0.3591 - val_mse: 1259.2625 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.2980 - mse: 770.5063 - mae: 0.2980 - val_loss: 0.3589 - val_mse: 1259.2629 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3123 - mse: 788.6518 - mae: 0.3123 - val_loss: 0.3588 - val_mse: 1259.2628 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4660 - mse: 25050365952.0000 - mae: 290.4659 - val_loss: 0.3587 - val_mse: 1259.2655 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3922 - mse: 1117.8641 - mae: 0.3922 - val_loss: 0.3586 - val_mse: 1259.2625 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3806 - mse: 1046.9668 - mae: 0.3806 - val_loss: 0.3661 - val_mse: 1259.2684 - val_mae: 0.3661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8774 - mse: 35070513152.0000 - mae: 483.8774 - val_loss: 0.3616 - val_mse: 1259.2582 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.8205 - mse: 20040292352.0000 - mae: 193.8205 - val_loss: 0.3608 - val_mse: 1259.2638 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3478 - mse: 948.0363 - mae: 0.3478 - val_loss: 0.3604 - val_mse: 1259.2614 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.2247 - mse: 30060439552.0000 - mae: 387.2247 - val_loss: 0.3601 - val_mse: 1259.2637 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3467 - mse: 817.7523 - mae: 0.3467 - val_loss: 0.3598 - val_mse: 1259.2656 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3800 - mse: 1103.6720 - mae: 0.3800 - val_loss: 0.3597 - val_mse: 1259.2654 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1795 - mse: 30060435456.0000 - mae: 387.1794 - val_loss: 0.3594 - val_mse: 1259.2650 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4278 - mse: 1218.2976 - mae: 0.4278 - val_loss: 0.3592 - val_mse: 1259.2646 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5251 - mse: 40080580608.0000 - mae: 580.5255 - val_loss: 0.3591 - val_mse: 1259.2627 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4172 - mse: 1171.5739 - mae: 0.4172 - val_loss: 0.3590 - val_mse: 1259.2632 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8471 - mse: 35070513152.0000 - mae: 483.8474 - val_loss: 0.3589 - val_mse: 1259.2609 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4180 - mse: 25050363904.0000 - mae: 290.4178 - val_loss: 0.3587 - val_mse: 1259.2628 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4227 - mse: 1314.5320 - mae: 0.4227 - val_loss: 0.3586 - val_mse: 1259.2627 - val_mae: 0.3586\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4724 - mse: 1486.8909 - mae: 0.4724 - val_loss: 0.3586 - val_mse: 1259.2644 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 677.2653 - mse: 45090652160.0000 - mae: 677.2656 - val_loss: 0.3635 - val_mse: 1259.2723 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 0.3561 - mse: 903.0079 - mae: 0.3561 - val_loss: 0.3614 - val_mse: 1259.2633 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.5184 - mse: 1690.6371 - mae: 0.5184 - val_loss: 0.3608 - val_mse: 1259.2635 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.3278 - mse: 25050365952.0000 - mae: 290.3278 - val_loss: 0.3604 - val_mse: 1259.2625 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7703 - mse: 20040294400.0000 - mae: 193.7703 - val_loss: 0.3602 - val_mse: 1259.2633 - val_mae: 0.3602\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3023 - mse: 748.0215 - mae: 0.3023 - val_loss: 0.3599 - val_mse: 1259.2610 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4332 - mse: 25050363904.0000 - mae: 290.4334 - val_loss: 0.3598 - val_mse: 1259.2612 - val_mae: 0.3598\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4317 - mse: 1191.0818 - mae: 0.4317 - val_loss: 0.3596 - val_mse: 1259.2614 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3695 - mse: 1116.8013 - mae: 0.3695 - val_loss: 0.3594 - val_mse: 1259.2604 - val_mae: 0.3594\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8381 - mse: 35070513152.0000 - mae: 483.8380 - val_loss: 0.3593 - val_mse: 1259.2620 - val_mae: 0.3593\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.1670 - mse: 30060439552.0000 - mae: 387.1671 - val_loss: 0.3591 - val_mse: 1259.2645 - val_mae: 0.3591\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3636 - mse: 1060.2258 - mae: 0.3636 - val_loss: 0.3591 - val_mse: 1259.2655 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 290.4908 - mse: 25050365952.0000 - mae: 290.4905 - val_loss: 0.3589 - val_mse: 1259.2616 - val_mae: 0.3589\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3011 - mse: 702.3336 - mae: 0.3011 - val_loss: 0.3588 - val_mse: 1259.2618 - val_mae: 0.3588\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3544 - mse: 906.0353 - mae: 0.3544 - val_loss: 0.3587 - val_mse: 1259.2643 - val_mae: 0.3587\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.2075 - mse: 30060435456.0000 - mae: 387.2075 - val_loss: 0.3634 - val_mse: 1259.2716 - val_mae: 0.3634\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3543 - mse: 950.8465 - mae: 0.3543 - val_loss: 0.3614 - val_mse: 1259.2687 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4904 - mse: 1543.3469 - mae: 0.4904 - val_loss: 0.3607 - val_mse: 1259.2662 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.0851 - mse: 30060435456.0000 - mae: 387.0852 - val_loss: 0.3604 - val_mse: 1259.2642 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4190 - mse: 1262.2037 - mae: 0.4190 - val_loss: 0.3601 - val_mse: 1259.2627 - val_mae: 0.3601\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 7s 11ms/step - loss: 483.8482 - mse: 35070509056.0000 - mae: 483.8482 - val_loss: 0.3599 - val_mse: 1259.2646 - val_mae: 0.3599\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 387.1537 - mse: 30060439552.0000 - mae: 387.1538 - val_loss: 0.3595 - val_mse: 1259.2635 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3788 - mse: 1018.1166 - mae: 0.3788 - val_loss: 0.3596 - val_mse: 1259.2581 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6799 - mse: 40080580608.0000 - mae: 580.6802 - val_loss: 0.3593 - val_mse: 1259.2625 - val_mae: 0.3593\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3016 - mse: 704.4804 - mae: 0.3016 - val_loss: 0.3592 - val_mse: 1259.2649 - val_mae: 0.3592\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3285 - mse: 903.1818 - mae: 0.3285 - val_loss: 0.3590 - val_mse: 1259.2646 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 677.2817 - mse: 45090656256.0000 - mae: 677.2815 - val_loss: 0.3589 - val_mse: 1259.2632 - val_mae: 0.3589\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3854 - mse: 1051.3805 - mae: 0.3854 - val_loss: 0.3588 - val_mse: 1259.2612 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 483.8429 - mse: 35070509056.0000 - mae: 483.8430 - val_loss: 0.3587 - val_mse: 1259.2667 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3675 - mse: 1012.0540 - mae: 0.3675 - val_loss: 0.3586 - val_mse: 1259.2610 - val_mae: 0.3586\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.5146 - mse: 25050365952.0000 - mae: 290.5145 - val_loss: 0.3635 - val_mse: 1259.2935 - val_mae: 0.3635\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3165 - mse: 659.9402 - mae: 0.3165 - val_loss: 0.3615 - val_mse: 1259.2678 - val_mae: 0.3615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.2699 - mse: 647.1606 - mae: 0.2699 - val_loss: 0.3607 - val_mse: 1259.2635 - val_mae: 0.3607\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 193.8160 - mse: 20040292352.0000 - mae: 193.8161 - val_loss: 0.3603 - val_mse: 1259.2633 - val_mae: 0.3603\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.4444 - mse: 1442.1787 - mae: 0.4444 - val_loss: 0.3600 - val_mse: 1259.2640 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.0398 - mse: 30060435456.0000 - mae: 387.0395 - val_loss: 0.3597 - val_mse: 1259.2639 - val_mae: 0.3597\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5403 - mse: 40080580608.0000 - mae: 580.5406 - val_loss: 0.3595 - val_mse: 1259.2627 - val_mae: 0.3595\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3863 - mse: 1149.4390 - mae: 0.3863 - val_loss: 0.3593 - val_mse: 1259.2615 - val_mae: 0.3593\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 580.6391 - mse: 40080580608.0000 - mae: 580.6396 - val_loss: 0.3592 - val_mse: 1259.2618 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3510 - mse: 1008.3138 - mae: 0.3510 - val_loss: 0.3590 - val_mse: 1259.2618 - val_mae: 0.3590\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 387.2328 - mse: 30060435456.0000 - mae: 387.2328 - val_loss: 0.3589 - val_mse: 1259.2626 - val_mae: 0.3589\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 0.3426 - mse: 809.2787 - mae: 0.3426 - val_loss: 0.3588 - val_mse: 1259.2610 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3961 - mse: 1204.0896 - mae: 0.3961 - val_loss: 0.3587 - val_mse: 1259.2633 - val_mae: 0.3587\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 580.5536 - mse: 40080580608.0000 - mae: 580.5539 - val_loss: 0.3585 - val_mse: 1259.2642 - val_mae: 0.3585\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 11ms/step - loss: 290.4597 - mse: 25050363904.0000 - mae: 290.4596 - val_loss: 0.3584 - val_mse: 1259.2639 - val_mae: 0.3584\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 0.3474 - mse: 840.2151 - mae: 0.3474 - val_loss: 0.3675 - val_mse: 1259.2699 - val_mae: 0.3675\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 193.7779 - mse: 20040292352.0000 - mae: 193.7779 - val_loss: 0.3616 - val_mse: 1259.2639 - val_mae: 0.3616\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4347 - mse: 25050365952.0000 - mae: 290.4346 - val_loss: 0.3616 - val_mse: 1259.3043 - val_mae: 0.3616\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.4002 - mse: 1249.7070 - mae: 0.4002 - val_loss: 0.3605 - val_mse: 1259.2587 - val_mae: 0.3605\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1714 - mse: 30060439552.0000 - mae: 387.1713 - val_loss: 0.3603 - val_mse: 1259.2646 - val_mae: 0.3603\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.3570 - mse: 1008.6675 - mae: 0.3570 - val_loss: 0.3600 - val_mse: 1259.2650 - val_mae: 0.3600\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4444 - mse: 25050363904.0000 - mae: 290.4442 - val_loss: 0.3599 - val_mse: 1259.2649 - val_mae: 0.3599\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3379 - mse: 982.9872 - mae: 0.3379 - val_loss: 0.3596 - val_mse: 1259.2625 - val_mae: 0.3596\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1545 - mse: 30060435456.0000 - mae: 387.1545 - val_loss: 0.3596 - val_mse: 1259.2631 - val_mae: 0.3596\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3621 - mse: 993.4495 - mae: 0.3621 - val_loss: 0.3595 - val_mse: 1259.2645 - val_mae: 0.3595\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9046 - mse: 35070513152.0000 - mae: 483.9044 - val_loss: 0.3592 - val_mse: 1259.2644 - val_mae: 0.3592\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3159 - mse: 774.2482 - mae: 0.3159 - val_loss: 0.3591 - val_mse: 1259.2657 - val_mae: 0.3591\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 290.4425 - mse: 25050365952.0000 - mae: 290.4426 - val_loss: 0.3591 - val_mse: 1259.2629 - val_mae: 0.3591\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3663 - mse: 1092.9120 - mae: 0.3663 - val_loss: 0.3589 - val_mse: 1259.2640 - val_mae: 0.3589\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.4065 - mse: 1126.5309 - mae: 0.4065 - val_loss: 0.3589 - val_mse: 1259.2653 - val_mae: 0.3589\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 15ms/step - loss: 290.5229 - mse: 25050363904.0000 - mae: 290.5231 - val_loss: 0.3687 - val_mse: 1259.2798 - val_mae: 0.3687\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3274 - mse: 803.2875 - mae: 0.3274 - val_loss: 0.3614 - val_mse: 1259.2804 - val_mae: 0.3614\n",
      "Epoch 3/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.8335 - mse: 35070509056.0000 - mae: 483.8335 - val_loss: 0.3606 - val_mse: 1259.2635 - val_mae: 0.3606\n",
      "Epoch 4/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3921 - mse: 1114.5187 - mae: 0.3921 - val_loss: 0.3604 - val_mse: 1259.2635 - val_mae: 0.3604\n",
      "Epoch 5/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 0.4346 - mse: 1287.8042 - mae: 0.4346 - val_loss: 0.3600 - val_mse: 1259.2655 - val_mae: 0.3600\n",
      "Epoch 6/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1017 - mse: 30060435456.0000 - mae: 387.1013 - val_loss: 0.3598 - val_mse: 1259.2621 - val_mae: 0.3598\n",
      "Epoch 7/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 387.1977 - mse: 30060435456.0000 - mae: 387.1979 - val_loss: 0.3597 - val_mse: 1259.2648 - val_mae: 0.3597\n",
      "Epoch 8/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.2701 - mse: 601.9779 - mae: 0.2701 - val_loss: 0.3594 - val_mse: 1259.2584 - val_mae: 0.3594\n",
      "Epoch 9/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3710 - mse: 1020.0999 - mae: 0.3710 - val_loss: 0.3592 - val_mse: 1259.2605 - val_mae: 0.3592\n",
      "Epoch 10/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1636 - mse: 30060435456.0000 - mae: 387.1636 - val_loss: 0.3591 - val_mse: 1259.2682 - val_mae: 0.3591\n",
      "Epoch 11/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 483.9139 - mse: 35070509056.0000 - mae: 483.9141 - val_loss: 0.3590 - val_mse: 1259.2649 - val_mae: 0.3590\n",
      "Epoch 12/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3528 - mse: 1005.4169 - mae: 0.3528 - val_loss: 0.3588 - val_mse: 1259.2661 - val_mae: 0.3588\n",
      "Epoch 13/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3987 - mse: 1097.1699 - mae: 0.3987 - val_loss: 0.3588 - val_mse: 1259.2653 - val_mae: 0.3588\n",
      "Epoch 14/20\n",
      "690/690 [==============================] - 9s 12ms/step - loss: 387.1844 - mse: 30060435456.0000 - mae: 387.1844 - val_loss: 0.3587 - val_mse: 1259.2638 - val_mae: 0.3587\n",
      "Epoch 15/20\n",
      "690/690 [==============================] - 8s 12ms/step - loss: 0.3933 - mse: 1165.8595 - mae: 0.3933 - val_loss: 0.3585 - val_mse: 1259.2661 - val_mae: 0.3585\n",
      "Train for 690 steps, validate for 230 steps\n",
      "Epoch 1/20\n",
      "690/690 [==============================] - 10s 14ms/step - loss: 387.2180 - mse: 30060439552.0000 - mae: 387.2182 - val_loss: 0.3644 - val_mse: 1259.2789 - val_mae: 0.3644\n",
      "Epoch 2/20\n",
      "690/690 [==============================] - 9s 13ms/step - loss: 0.3786 - mse: 948.9041 - mae: 0.3786 - val_loss: 0.3616 - val_mse: 1259.2653 - val_mae: 0.3616\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690/690 [==============================] - 9s 13ms/step - loss: 483.9548 - mse: 35070509056.0000 - mae: 483.9547 - val_loss: 0.3608 - val_mse: 1259.2625 - val_mae: 0.3608\n",
      "Epoch 4/20\n",
      "368/690 [===============>..............] - ETA: 2s - loss: 0.5223 - mse: 1547.0660 - mae: 0.5223"
     ]
    }
   ],
   "source": [
    "th_dirs = ['/tmp/snapshot/threshold_{}/'.format(i) for i in range(10)]\n",
    "\n",
    "steps = [5, 10, 20, 50, 100, 200]\n",
    "\n",
    "for th_dir in th_dirs:\n",
    "    print('Global run', th_dir)\n",
    "    for s in steps:\n",
    "        run_dir = th_dir + '{}/'.format(s)\n",
    "        run_snapshot(run_dir, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
