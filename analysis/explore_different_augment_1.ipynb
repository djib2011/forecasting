{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import networks\n",
    "import metrics\n",
    "import evaluate\n",
    "from datasets import seq2seq_generator, seq2seq_generator_with_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = seq2seq_generator('../data/yearly_24_validation.pkl', overlap=8, augmentation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = metrics.build_reconstruction_loss(overlap=8)\n",
    "\n",
    "metric_functions = ['mse', 'mae', reconstruction_loss]\n",
    "\n",
    "hparams = {\n",
    "    'input_seq_length': 18,\n",
    "    'output_seq_length': 14,\n",
    "    'bottleneck_size': 700,\n",
    "    'bottleneck_activation': 'relu',\n",
    "    'loss_function': 'mae',\n",
    "}\n",
    "\n",
    "model = networks.convolutional_ae_4_layer(hparams, metric_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 51s 73ms/step - loss: 193.8048 - mse: 20040290304.0000 - mae: 193.8048 - reconstruction_loss: 0.0076 - val_loss: 0.3804 - val_mse: 1259.2601 - val_mae: 0.3804 - val_reconstruction_loss: 0.0013\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 50s 72ms/step - loss: 193.7811 - mse: 20040290304.0000 - mae: 193.7811 - reconstruction_loss: 4.2354e-04 - val_loss: 0.3640 - val_mse: 1259.2681 - val_mae: 0.3640 - val_reconstruction_loss: 2.3333e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 50s 72ms/step - loss: 193.7802 - mse: 20040290304.0000 - mae: 193.7802 - reconstruction_loss: 3.9135e-04 - val_loss: 0.3653 - val_mse: 1259.2533 - val_mae: 0.3653 - val_reconstruction_loss: 2.9697e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 49s 70ms/step - loss: 193.7782 - mse: 20040292352.0000 - mae: 193.7782 - reconstruction_loss: 2.9111e-04 - val_loss: 0.3616 - val_mse: 1259.2476 - val_mae: 0.3616 - val_reconstruction_loss: 1.3281e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 50s 73ms/step - loss: 193.7767 - mse: 20040290304.0000 - mae: 193.7767 - reconstruction_loss: 2.3744e-04 - val_loss: 0.3611 - val_mse: 1259.2540 - val_mae: 0.3611 - val_reconstruction_loss: 1.1756e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 49s 71ms/step - loss: 193.7759 - mse: 20040290304.0000 - mae: 193.7758 - reconstruction_loss: 2.1855e-04 - val_loss: 0.3659 - val_mse: 1259.2538 - val_mae: 0.3659 - val_reconstruction_loss: 3.5389e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 49s 70ms/step - loss: 193.7750 - mse: 20040290304.0000 - mae: 193.7750 - reconstruction_loss: 2.0058e-04 - val_loss: 0.3617 - val_mse: 1259.2522 - val_mae: 0.3617 - val_reconstruction_loss: 1.5367e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 49s 71ms/step - loss: 193.7741 - mse: 20040290304.0000 - mae: 193.7742 - reconstruction_loss: 1.9309e-04 - val_loss: 0.3618 - val_mse: 1259.2638 - val_mae: 0.3618 - val_reconstruction_loss: 1.6497e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 47s 68ms/step - loss: 193.7729 - mse: 20040292352.0000 - mae: 193.7729 - reconstruction_loss: 1.6737e-04 - val_loss: 0.3615 - val_mse: 1259.2742 - val_mae: 0.3615 - val_reconstruction_loss: 1.6909e-04\n",
      "Train for 690 steps, validate for 230 steps\n",
      "690/690 [==============================] - 46s 66ms/step - loss: 193.7725 - mse: 20040290304.0000 - mae: 193.7725 - reconstruction_loss: 1.7620e-04 - val_loss: 0.3669 - val_mse: 1259.2773 - val_mae: 0.3669 - val_reconstruction_loss: 4.3055e-04\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "\n",
    "    train_set = seq2seq_generator_with_aug('../data/yearly_24_train.pkl',\n",
    "                                           '../data/yearly_24_train_aug.pkl',\n",
    "                                           overlap=8)\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
    "                    '../experimental/results/custom_aug_1/best_weights_{}.h5'.format(e),\n",
    "                save_best_only=True)]\n",
    "\n",
    "    model.fit(train_set, epochs=1, steps_per_epoch=len(train_set)//256+1,\n",
    "                  validation_steps=len(test_set)//256+1, validation_data=test_set,\n",
    "                  callbacks=callbacks)\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "train_path = Path('../data/Yearly-train.csv')\n",
    "test_path = Path('../data/Yearly-test.csv')\n",
    "\n",
    "train = pd.read_csv(train_path).drop('V1', axis=1)\n",
    "test = pd.read_csv(test_path).drop('V1', axis=1)\n",
    "\n",
    "X_test = np.array([evaluate.get_last_N(ser[1], N=18) for ser in train.iterrows()])\n",
    "y_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    model_dir = '../experimental/results/custom_aug_1/best_weights_{}.h5'.format(i)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_dir, custom_objects={'reconstruction_loss': reconstruction_loss})\n",
    "\n",
    "    preds = evaluate.get_predictions(model, X_test)\n",
    "    \n",
    "    all_preds.append(preds)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.170303749685267\n",
      "13.352349858736359\n",
      "13.321846794206998\n",
      "13.198059962825095\n",
      "13.231100107162078\n",
      "13.361803744681916\n",
      "13.401830929786858\n",
      "13.430831158900618\n",
      "13.451569477888137\n",
      "13.464930270744931\n",
      "13.146571540612008\n"
     ]
    }
   ],
   "source": [
    "for p in all_preds:\n",
    "    print(np.nanmean(metrics.SMAPE(y_test, p[:, -6:])))\n",
    "\n",
    "ensemble_preds = np.median(np.array(all_preds), axis=0)\n",
    "print(np.nanmean(metrics.SMAPE(y_test, ensemble_preds[:, -6:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsu",
   "language": "python",
   "name": "fsu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
